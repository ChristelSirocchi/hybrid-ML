{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "028fe9dc-4544-4b4c-b49f-b86ae086a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "6b710e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             roc_auc_score, matthews_corrcoef, confusion_matrix, make_scorer)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "1bdf2aca-af05-4d1c-8293-de0e12cd23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "fe3cf592-85ac-40cc-b05e-6943d4873ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap,ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "0687636d-8229-48ad-816a-2f36446148da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "2ea5f9d5-ca43-4369-9ddc-d6b9dc1074cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.random_seed import set_seed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pathlib import Path\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "ce06f092-4c38-4f8c-a99d-c56eee385474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "a89d9267-fd5f-45f3-ad1d-de6cb5eda261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "c7567e6d-bfd4-42aa-92ef-3affb03c1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "0e62ef71-1833-4276-8cb0-2b3374d0ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "03e010e1-e03d-4e69-907d-be5d13e0221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psyke==0.8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "593a61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psyke import Extractor, Clustering, EvaluableModel\n",
    "from psyke.extraction.hypercubic.strategy import AdaptiveStrategy\n",
    "from psyke.extraction.hypercubic import Grid, FeatureRanker\n",
    "from psyke.tuning.orchid import OrCHiD\n",
    "from psyke.tuning.crash import CRASH\n",
    "from psyke.utils.logic import pretty_theory\n",
    "from psyke.utils import Target\n",
    "from psyke.schema import LessThan, GreaterThan, Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "74fa44ee-7869-430c-b3ef-6742f6f52d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "446ffd32-5400-4da0-94da-d1f38595f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psyki.logic import Theory\n",
    "from psyki.logic.prolog import TuProlog\n",
    "from psyki.ski import Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "ef689819-fb3c-4704-be36-09ca29cde53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "e553a611-56c8-473b-83d7-63746dcb6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse rules from theories\n",
    "def parse_rules(rule_string):\n",
    "    opposite_signs = {\n",
    "        '<': '>',\n",
    "        '>': '<',\n",
    "        '<=': '>=',\n",
    "        '>=': '<=',\n",
    "        '=<': '=>',\n",
    "        '=>': '=<',\n",
    "    }\n",
    "    rules = []\n",
    "    # predicate with rules\n",
    "    rule_pattern = re.compile(r\"'Outcome'\\((.*?)\\)\\s:-\\s*(.*?)\\.($|\\s)\")\n",
    "    # final predicate with no rules\n",
    "    rule_pattern_end = re.compile(r\"'Outcome'\\((.*?)\\)\\.\")\n",
    "    # rule condition\n",
    "    condition_pattern = re.compile(r'([a-zA-Z]+)\\s*([=<>]+)\\s*([0-9.-]+)')\n",
    "    # rule interval\n",
    "    interval_pattern = re.compile(r\"([a-zA-Z]+)\\s+in\\s+\\[([-+]?\\d*\\.?\\d+),\\s*([-+]?\\d*\\.?\\d+)\\]\")\n",
    "    for match in rule_pattern.finditer(rule_string):\n",
    "        outcome = match.group(1).strip().split()[-1]\n",
    "        conditions_str = match.group(2).strip()\n",
    "        conditions = []\n",
    "        # condition with less than / greater than\n",
    "        for condition_match in condition_pattern.finditer(conditions_str):\n",
    "            variable = condition_match.group(1)\n",
    "            operation = condition_match.group(2)\n",
    "            threshold = float(condition_match.group(3))\n",
    "            conditions.append({\n",
    "                \"variable\": variable,\n",
    "                \"operation\": operation,\n",
    "                \"threshold\": threshold\n",
    "            })\n",
    "        # condition with interval\n",
    "        for condition_match in interval_pattern.finditer(conditions_str):\n",
    "            variable = condition_match.group(1)\n",
    "            lower_bound = float(condition_match.group(2))\n",
    "            upper_bound = float(condition_match.group(3))\n",
    "            conditions.extend([\n",
    "                {\"variable\": variable,\n",
    "                \"operation\": \">=\",\n",
    "                \"threshold\": lower_bound},\n",
    "                {\"variable\": variable,\n",
    "                \"operation\": \"<=\",\n",
    "                \"threshold\": upper_bound}           \n",
    "            ]) \n",
    "        rules.append({\n",
    "            \"conditions\": conditions,\n",
    "            \"outcome\": outcome\n",
    "        })\n",
    "    # rule with no conditions\n",
    "    for match in rule_pattern_end.finditer(rule_string):\n",
    "        outcome = match.group(1).strip().split()[-1]\n",
    "        rules.append({\n",
    "            \"conditions\": [],\n",
    "            \"outcome\": outcome\n",
    "        })\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "f4059c3f-995f-41bd-b225-8fc50a34592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rules from the knowledge base\n",
    "def get_kb_rules():\n",
    "    return [ {\"conditions\" : [{\"variable\" : \"BMI\",\n",
    "                                      \"operation\" : \"<=\",\n",
    "                                      \"threshold\" : 25},\n",
    "                                     {\"variable\" : \"Glucose\",\n",
    "                                      \"operation\" : \"<=\",\n",
    "                                      \"threshold\" : 100}],\n",
    "                     \"outcome\" : \"healthy\"},\n",
    "                    {\"conditions\" : [{\"variable\" : \"BMI\",\n",
    "                                      \"operation\" : \">=\",\n",
    "                                      \"threshold\" : 30},\n",
    "                                     {\"variable\" : \"Glucose\",\n",
    "                                      \"operation\" : \">=\",\n",
    "                                      \"threshold\" : 126}],\n",
    "                     \"outcome\" : \"diabetes\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ed03770d-3f04-4a72-bbe2-202d7adbd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(sample, rules): \n",
    "    outcome = np.nan\n",
    "    for rule in rules:\n",
    "        conditions_met = all(apply_condition(cond[\"operation\"], sample[cond[\"variable\"]],cond[\"threshold\"]) for cond in rule['conditions'])\n",
    "        if conditions_met:\n",
    "            outcome = rule[\"outcome\"]\n",
    "            break\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "827897dc-516e-4c82-899d-048f30c6a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule(rules, sample): \n",
    "    outcome = np.nan\n",
    "    for id, rule in enumerate(rules):\n",
    "        conditions_met = all(apply_condition(cond[\"operation\"], sample[cond[\"variable\"]],cond[\"threshold\"]) for cond in rule['conditions'])\n",
    "        if conditions_met:\n",
    "            outcome = rule[\"outcome\"]\n",
    "            break\n",
    "    return id, outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "be7f9ed4-e37d-4c0d-a87c-aabdb786b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_condition(operation, value, threshold):\n",
    "    if operation == \"<=\":\n",
    "        return value <= threshold\n",
    "    if operation == \"=<\":\n",
    "        return value <= threshold\n",
    "    elif operation == \"<\":\n",
    "        return value < threshold\n",
    "    if operation == \">=\":\n",
    "        return value >= threshold\n",
    "    if operation == \"=>\":\n",
    "        return value >= threshold\n",
    "    elif operation == \">\":\n",
    "        return value > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "0e3a33bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# functions to print scores for the generated rules\n",
    "def print_scores(scores):\n",
    "    print(f'Classification accuracy = {scores[EvaluableModel.ClassificationScore.ACCURACY][0]:.2f} (data), '\n",
    "          f'{scores[EvaluableModel.ClassificationScore.ACCURACY][1]:.2f} (BB)\\n'\n",
    "          f'F1 = {scores[EvaluableModel.ClassificationScore.F1][0]:.2f} (data), '\n",
    "          f'{scores[EvaluableModel.ClassificationScore.F1][1]:.2f} (BB)')\n",
    "\n",
    "def get_scores(extractor, test, predictor):\n",
    "    return extractor.score(test, predictor, True, True, False, task=EvaluableModel.Task.CLASSIFICATION,\n",
    "                           scoring_function=[EvaluableModel.ClassificationScore.ACCURACY,\n",
    "                                             EvaluableModel.ClassificationScore.F1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "27089367-3604-46fd-8356-8738ed5cb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute performance metrics\n",
    "def get_results(y_pred, y_test):\n",
    "    a   = accuracy_score(y_test, y_pred)\n",
    "    ba  = balanced_accuracy_score(y_test, y_pred)\n",
    "    p   = precision_score(y_test, y_pred)\n",
    "    r   = recall_score(y_test, y_pred)\n",
    "    sp  = recall_score(y_test, y_pred, pos_label=0)\n",
    "    f1  = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    return [a, ba, p, r, sp, f1, roc, mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "a5c74272-ecfb-443f-8e67-48e0ab15d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute accuracy with respect to a rule-based system\n",
    "def get_relative_accuracy(y_test, y_rule, y_pred):\n",
    "    return sum((y_test == y_rule) & (y_rule == y_pred.round())) / sum(y_test == y_rule)\n",
    " \n",
    "def get_relative_sensitivity(y_test, y_rule, y_pred):\n",
    "    return sum((y_test == y_rule) & (y_test == 1) & (y_rule == y_pred.round())) / sum((y_test == y_rule) & (y_test == 1))\n",
    " \n",
    "def get_relative_specificity(y_test, y_rule, y_pred):\n",
    "    return sum((y_test == y_rule) & (y_test == 0) & (y_rule == y_pred.round())) / sum((y_test == y_rule) & (y_test == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "066ba207-c104-4d80-bd11-fbe61d326acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate a summary table\n",
    "def get_results_table(scores_ml, scores_kbml, n_1, n_train, n_test):\n",
    "    res = pd.DataFrame(index = scores_ml.columns, columns = [\"ML_mean\",\"ML_std\",\"KB-ML_mean\",\"KB-ML_std\"])\n",
    "    res[\"ML_mean\"] = scores_ml.mean().round(3)\n",
    "    res[\"ML_std\"] = scores_ml.std().round(3)\n",
    "    res[\"KB-ML_mean\"] = scores_kbml.mean().round(3)\n",
    "    res[\"KB-ML_std\"] = scores_kbml.std().round(3)\n",
    "    res[\"p-value\"] = np.nan\n",
    "    res[\"corr_p-value\"] = np.nan\n",
    "    for c in res.index:\n",
    "        difference = scores_ml[c].values - scores_kbml[c].values\n",
    "        # uncorrected paired t-test p-value\n",
    "        t_stat_uncorrected = np.mean(difference) / np.sqrt(np.var(difference, ddof=1) / (n_1+1))\n",
    "        p_val_uncorrected = t.sf(np.abs(t_stat_uncorrected), n_1)\n",
    "        res.loc[c,\"p-value\"] = p_val_uncorrected.round(4)\n",
    "        # corrected paired t-test p-value\n",
    "        t_stat, p_val = compute_corrected_ttest(difference, n_1, n_train, n_test)\n",
    "        res.loc[c,\"corr_p-value\"] = p_val.round(4)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "4a93195a-b75d-4103-aeef-59ace62b0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to correct the standard deviation using Nadeau and Bengio's approach.\n",
    "def corrected_std(differences, n_train, n_test):\n",
    "    # kr = k times r, r times repeated k-fold crossvalidation,\n",
    "    # kr equals the number of times the model was evaluated\n",
    "    kr = len(differences)\n",
    "    corrected_var = np.var(differences, ddof=1) * (1 / kr + n_test / n_train)\n",
    "    corrected_std = np.sqrt(corrected_var)\n",
    "    return corrected_std\n",
    "\n",
    "# function to compute right-tailed paired t-test with corrected variance.\n",
    "def compute_corrected_ttest(differences, df, n_train, n_test):\n",
    "    mean = np.mean(differences)\n",
    "    std = corrected_std(differences, n_train, n_test)\n",
    "    t_stat = mean / std\n",
    "    p_val = t.sf(np.abs(t_stat), df)  # right-tailed t-test\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "805b2edc-64c5-4eb8-a29b-c19561171b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_components(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    tn_rate = tn / total\n",
    "    fp_rate = fp / total\n",
    "    fn_rate = fn / total\n",
    "    tp_rate = tp / total\n",
    "    return {'tn_rate': tn_rate, 'fp_rate': fp_rate, 'fn_rate': fn_rate, 'tp_rate': tp_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "03959f3c-f921-440f-b1b3-aca1e05d8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_in_condition(input_text):\n",
    "    # Define the regex pattern to match \"feature in [lower, upper]\"\n",
    "    pattern = re.compile(r'(\\w+) in \\[(\\d+\\.?\\d*), (\\d+\\.?\\d*)\\]')\n",
    "    \n",
    "    # Define the replacement function\n",
    "    def replacement(match):\n",
    "        feature = match.group(1)\n",
    "        lower = match.group(2)\n",
    "        upper = match.group(3)\n",
    "        return f'{feature} > {lower}, {feature} =< {upper}'\n",
    "    \n",
    "    # Replace all occurrences in the input_text\n",
    "    transformed_text = pattern.sub(replacement, input_text)\n",
    "    \n",
    "    return transformed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "7c73fde8-c93d-4688-b2f9-ee114fad95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorWrapper(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, threshold=0.5):\n",
    "        super(PredictorWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Use the existing model to make predictions\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        # Convert probabilities to class labels based on the threshold\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            # Model returns probabilities or one-hot encoded outputs\n",
    "            # Assuming probabilities are returned\n",
    "            predictions = (predictions >= self.threshold).astype(int)\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        else:\n",
    "            # Model returns single probability for binary classification\n",
    "            predictions = (predictions >= self.threshold).astype(int)\n",
    "        \n",
    "        # Ensure predictions are flat (1D array)\n",
    "        predictions = predictions.flatten()\n",
    "        \n",
    "        # Map the numeric predictions to the desired string labels\n",
    "        label_map = {0: 'healthy', 1: 'diabetes'}\n",
    "        string_predictions = np.array([label_map[pred] for pred in predictions])\n",
    "        \n",
    "        return string_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cd470-b3b8-4d92-96a9-195e6a54e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(experiment, X_train, y_train):\n",
    "    if experiment == \"oversampling\":\n",
    "        return RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    elif experiment == \"undersampling\":\n",
    "        return RandomUnderSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "4dd55252-4329-40b5-b43d-08b685ce41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_components(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    tn_rate = tn / total\n",
    "    fp_rate = fp / total\n",
    "    fn_rate = fn / total\n",
    "    tp_rate = tp / total\n",
    "    return {'tn_rate': tn_rate, 'fp_rate': fp_rate, 'fn_rate': fn_rate, 'tp_rate': tp_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "fe04dad9-72ed-4e45-9117-1c4fed611b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(results, model_name, y_test, y_pred, y_rule):\n",
    "    results[model_name]['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results[model_name]['precision'].append(precision_score(y_test, y_pred))\n",
    "    results[model_name]['recall'].append(recall_score(y_test, y_pred))\n",
    "    results[model_name]['f1'].append(f1_score(y_test, y_pred))\n",
    "    results[model_name]['balanced_accuracy'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "    results[model_name]['mcc'].append(matthews_corrcoef(y_test, y_pred))\n",
    "    cm = confusion_matrix_components(y_test, y_pred)\n",
    "    results[model_name]['tn_rate'].append(cm['tn_rate'])\n",
    "    results[model_name]['fp_rate'].append(cm['fp_rate'])\n",
    "    results[model_name]['fn_rate'].append(cm['fn_rate'])\n",
    "    results[model_name]['tp_rate'].append(cm['tp_rate'])\n",
    "    results[model_name]['relative_accuracy'].append(get_relative_accuracy(y_test, y_rule, y_pred))\n",
    "    results[model_name]['relative_recall'].append(get_relative_sensitivity(y_test, y_rule, y_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "3696dd05-8860-41ad-933d-378c4b94437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uneducated_predictor(\n",
    "    input_shape: tuple,\n",
    "    outputs: int,\n",
    "    neurons_per_hidden_layer: list[int],\n",
    "    activation: str = \"relu\",\n",
    "    last_activation: str = \"softmax\",\n",
    "    ) -> Model:\n",
    "    predictor_input = Input(input_shape)\n",
    "    x = predictor_input\n",
    "    for neurons in neurons_per_hidden_layer:\n",
    "        x = Dense(neurons, activation=activation)(x)\n",
    "    x = Dense(outputs, activation=last_activation)(x)\n",
    "    return Model(predictor_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "336d62b7-5937-42a4-a846-339c33bdd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_predictor(neurons_per_hidden_layer=[12, 8], activation=\"relu\", last_activation=\"sigmoid\"):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_per_hidden_layer[0], input_dim=X_train.shape[1], activation=activation))\n",
    "    for neurons in neurons_per_hidden_layer[1:]:\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation=last_activation))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31844eae-5d07-4dfb-b4e0-21b2fbefa4de",
   "metadata": {},
   "source": [
    "## TRADITIONAL MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "d69c3799-889d-4915-8046-b38d97b64204",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "882ef1cb-87cf-4017-9af4-5960152f4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "# read rules\n",
    "dataset_rules = dataset.copy()\n",
    "dataset_rules[\"Rules\"] = np.nan\n",
    "dataset_rules.loc[(dataset_rules[\"BMI\"] >= 30) & (dataset_rules[\"Glucose\"] >= 126), \"Rules\"] = 1\n",
    "dataset_rules.loc[(dataset_rules[\"BMI\"] <= 25) & (dataset_rules[\"Glucose\"] <= 100), \"Rules\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "889fa3fa-9c13-4ea2-a55e-5230f2da60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter grid for each model\n",
    "param_grids = {\n",
    "    'DecisionTree': {\n",
    "        'max_depth': [None, 10, 15, 20],\n",
    "        'min_samples_split': [5, 10, 15, 20],\n",
    "        'min_samples_leaf': [5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    },\n",
    "    'XGBoost' : {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'eta': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [None, 10, 15, 20],\n",
    "        #'subsample': [0.6, 0.8, 1.0],\n",
    "        #'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    'MultiLayerPerceptron': {\n",
    "        'hidden_layer_sizes': [(10,), (12, 8), (16, 8), (32, 16), (32, 16, 8)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        #'learning_rate': ['constant', 'adaptive']\n",
    "    },\n",
    "    'NeuralNetwork': {  # parameters for the Keras model\n",
    "        #'neurons_per_hidden_layer': [[10], [12, 8], [16, 8], [32, 16], [32, 16, 8]],\n",
    "        'epochs': [40, 60, 80, 100]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 15, 20],\n",
    "        'min_samples_split': [5, 10, 15, 20],\n",
    "        'min_samples_leaf': [5, 10]\n",
    "    },\n",
    "    'KNearestNeighbor': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'SupportVector' :{\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        'dual': [False]\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "1339e28d-2724-424e-9338-969e3e500994",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "1362f24a-c16c-4fbf-9221-c573cae8050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models\n",
    "models = {\n",
    "    #'NeuralNetwork': KerasClassifier(build_fn=create_nn_predictor, verbose=0),\n",
    "    'LogisticRegression': LogisticRegression(random_state=123, max_iter=1000),\n",
    "    'SupportVector': LinearSVC(random_state=123, max_iter=1000),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=123),\n",
    "    'RandomForest': RandomForestClassifier(random_state=123),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=123),\n",
    "    #'XGBoost': xgb.XGBClassifier(random_state=123)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "ac4ae969-2606-4a27-ba28-a2fa9eed4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform nested cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# initialize a dictionary to store results\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in list(models.keys()) + [\"NeuralNetwork\"]}\n",
    "all_pred = {model: [] for model in list(models.keys()) + [\"NeuralNetwork\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "73477938-f9f0-4b64-9019-fbb822a75224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'DecisionTree'\n",
    "# model = DecisionTreeClassifier(random_state=123)\n",
    "# search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], scoring=\"accuracy\", cv=inner_cv, n_jobs=-1)\n",
    "# search.fit(X, y)\n",
    "# search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14451a-793b-46d4-b98c-159e97bcb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform nested cross-validation for all models except NN\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    for train_idx, test_idx in outer_cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "        \n",
    "        # Scale data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Compute sample weights\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "        clf = GridSearchCV(estimator=model, param_grid=param_grids[model_name], scoring=\"accuracy\", cv=inner_cv, \n",
    "                                                       n_jobs=-1).fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        \n",
    "        # Predict and compute scores\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "        all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a155c7b9-25cc-41fc-91c8-99f405bf72fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 0.7819 - accuracy: 0.4228 - val_loss: 0.7062 - val_accuracy: 0.5507\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.4534 - val_loss: 0.6877 - val_accuracy: 0.5797\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.4871 - val_loss: 0.6735 - val_accuracy: 0.5797\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5322 - val_loss: 0.6609 - val_accuracy: 0.6232\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.5756 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.6350 - val_loss: 0.6405 - val_accuracy: 0.6812\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6736 - val_loss: 0.6280 - val_accuracy: 0.7246\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6913 - val_loss: 0.6154 - val_accuracy: 0.7536\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7090 - val_loss: 0.6020 - val_accuracy: 0.7536\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7186 - val_loss: 0.5897 - val_accuracy: 0.7536\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7267 - val_loss: 0.5757 - val_accuracy: 0.7536\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7267 - val_loss: 0.5621 - val_accuracy: 0.7681\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7363 - val_loss: 0.5496 - val_accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7428 - val_loss: 0.5364 - val_accuracy: 0.7681\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7476 - val_loss: 0.5254 - val_accuracy: 0.7681\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7428 - val_loss: 0.5143 - val_accuracy: 0.7391\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7476 - val_loss: 0.5095 - val_accuracy: 0.7536\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7508 - val_loss: 0.5012 - val_accuracy: 0.7681\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7556 - val_loss: 0.4956 - val_accuracy: 0.7826\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7572 - val_loss: 0.4920 - val_accuracy: 0.7826\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7572 - val_loss: 0.4883 - val_accuracy: 0.7826\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7621 - val_loss: 0.4867 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7669 - val_loss: 0.4859 - val_accuracy: 0.7681\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7653 - val_loss: 0.4849 - val_accuracy: 0.7681\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7669 - val_loss: 0.4824 - val_accuracy: 0.7681\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7669 - val_loss: 0.4809 - val_accuracy: 0.7681\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7685 - val_loss: 0.4798 - val_accuracy: 0.7536\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7685 - val_loss: 0.4768 - val_accuracy: 0.7391\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7701 - val_loss: 0.4762 - val_accuracy: 0.7391\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7717 - val_loss: 0.4740 - val_accuracy: 0.7391\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7781 - val_loss: 0.4729 - val_accuracy: 0.7391\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7765 - val_loss: 0.4755 - val_accuracy: 0.7391\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7749 - val_loss: 0.4753 - val_accuracy: 0.7391\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7749 - val_loss: 0.4720 - val_accuracy: 0.7536\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7749 - val_loss: 0.4699 - val_accuracy: 0.7536\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7733 - val_loss: 0.4719 - val_accuracy: 0.7536\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7749 - val_loss: 0.4702 - val_accuracy: 0.7536\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7749 - val_loss: 0.4696 - val_accuracy: 0.7536\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7749 - val_loss: 0.4681 - val_accuracy: 0.7536\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7749 - val_loss: 0.4686 - val_accuracy: 0.7536\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7781 - val_loss: 0.4675 - val_accuracy: 0.7536\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7733 - val_loss: 0.4692 - val_accuracy: 0.7536\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7733 - val_loss: 0.4677 - val_accuracy: 0.7536\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7749 - val_loss: 0.4672 - val_accuracy: 0.7536\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7733 - val_loss: 0.4692 - val_accuracy: 0.7536\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7717 - val_loss: 0.4694 - val_accuracy: 0.7536\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7797 - val_loss: 0.4672 - val_accuracy: 0.7681\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7781 - val_loss: 0.4653 - val_accuracy: 0.7681\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7749 - val_loss: 0.4708 - val_accuracy: 0.7681\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7749 - val_loss: 0.4703 - val_accuracy: 0.7681\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7749 - val_loss: 0.4674 - val_accuracy: 0.7681\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7749 - val_loss: 0.4698 - val_accuracy: 0.7536\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7749 - val_loss: 0.4713 - val_accuracy: 0.7536\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 0.7630 - accuracy: 0.3826 - val_loss: 0.7673 - val_accuracy: 0.3043\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.4550 - val_loss: 0.7430 - val_accuracy: 0.3623\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.4920 - val_loss: 0.7252 - val_accuracy: 0.4058\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.5418 - val_loss: 0.7132 - val_accuracy: 0.4638\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5836 - val_loss: 0.7014 - val_accuracy: 0.4928\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6045 - val_loss: 0.6901 - val_accuracy: 0.5507\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6158 - val_loss: 0.6795 - val_accuracy: 0.5797\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6334 - val_loss: 0.6679 - val_accuracy: 0.5942\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6592 - val_loss: 0.6538 - val_accuracy: 0.6377\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6624 - val_loss: 0.6393 - val_accuracy: 0.6377\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6768 - val_loss: 0.6237 - val_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6849 - val_loss: 0.6103 - val_accuracy: 0.6522\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.6913 - val_loss: 0.5970 - val_accuracy: 0.6957\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.6929 - val_loss: 0.5843 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7010 - val_loss: 0.5717 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7074 - val_loss: 0.5589 - val_accuracy: 0.7101\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7074 - val_loss: 0.5507 - val_accuracy: 0.7246\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7170 - val_loss: 0.5434 - val_accuracy: 0.7246\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7299 - val_loss: 0.5346 - val_accuracy: 0.7391\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7347 - val_loss: 0.5274 - val_accuracy: 0.7391\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7395 - val_loss: 0.5231 - val_accuracy: 0.7536\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7412 - val_loss: 0.5194 - val_accuracy: 0.7536\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7363 - val_loss: 0.5165 - val_accuracy: 0.7536\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7379 - val_loss: 0.5135 - val_accuracy: 0.7681\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7460 - val_loss: 0.5087 - val_accuracy: 0.7826\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7476 - val_loss: 0.5116 - val_accuracy: 0.7681\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7492 - val_loss: 0.5067 - val_accuracy: 0.7681\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7540 - val_loss: 0.5042 - val_accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7556 - val_loss: 0.5055 - val_accuracy: 0.7681\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7572 - val_loss: 0.5001 - val_accuracy: 0.7826\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7524 - val_loss: 0.5000 - val_accuracy: 0.7826\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7540 - val_loss: 0.4989 - val_accuracy: 0.7826\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7524 - val_loss: 0.4963 - val_accuracy: 0.7681\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7540 - val_loss: 0.4942 - val_accuracy: 0.7681\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7556 - val_loss: 0.4939 - val_accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7572 - val_loss: 0.4923 - val_accuracy: 0.7826\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7556 - val_loss: 0.4914 - val_accuracy: 0.7826\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7605 - val_loss: 0.4889 - val_accuracy: 0.7826\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7524 - val_loss: 0.4906 - val_accuracy: 0.7826\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7556 - val_loss: 0.4879 - val_accuracy: 0.7826\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7508 - val_loss: 0.4891 - val_accuracy: 0.7826\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7508 - val_loss: 0.4882 - val_accuracy: 0.7826\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7524 - val_loss: 0.4887 - val_accuracy: 0.7826\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7540 - val_loss: 0.4874 - val_accuracy: 0.7826\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7572 - val_loss: 0.4861 - val_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7588 - val_loss: 0.4859 - val_accuracy: 0.7826\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7588 - val_loss: 0.4861 - val_accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7572 - val_loss: 0.4859 - val_accuracy: 0.7826\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7556 - val_loss: 0.4854 - val_accuracy: 0.7826\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7572 - val_loss: 0.4885 - val_accuracy: 0.7681\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7588 - val_loss: 0.4856 - val_accuracy: 0.7681\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7588 - val_loss: 0.4865 - val_accuracy: 0.7681\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7588 - val_loss: 0.4861 - val_accuracy: 0.7681\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7605 - val_loss: 0.4865 - val_accuracy: 0.7681\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 23ms/step - loss: 0.6903 - accuracy: 0.3473 - val_loss: 0.6969 - val_accuracy: 0.4203\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.4003 - val_loss: 0.6790 - val_accuracy: 0.4493\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.4936 - val_loss: 0.6660 - val_accuracy: 0.5797\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.5595 - val_loss: 0.6548 - val_accuracy: 0.6377\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.5852 - val_loss: 0.6457 - val_accuracy: 0.6232\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6334 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6592 - val_loss: 0.6256 - val_accuracy: 0.7101\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6752 - val_loss: 0.6143 - val_accuracy: 0.7246\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6881 - val_loss: 0.6034 - val_accuracy: 0.7246\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7026 - val_loss: 0.5892 - val_accuracy: 0.7391\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7235 - val_loss: 0.5746 - val_accuracy: 0.7536\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7363 - val_loss: 0.5602 - val_accuracy: 0.7681\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7428 - val_loss: 0.5467 - val_accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7444 - val_loss: 0.5329 - val_accuracy: 0.7536\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7428 - val_loss: 0.5216 - val_accuracy: 0.7536\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.5096 - val_accuracy: 0.7536\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7508 - val_loss: 0.5007 - val_accuracy: 0.7536\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7540 - val_loss: 0.4911 - val_accuracy: 0.7536\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7556 - val_loss: 0.4860 - val_accuracy: 0.7536\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7572 - val_loss: 0.4798 - val_accuracy: 0.7391\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7605 - val_loss: 0.4745 - val_accuracy: 0.7391\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7524 - val_loss: 0.4711 - val_accuracy: 0.7391\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7621 - val_loss: 0.4675 - val_accuracy: 0.7391\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7621 - val_loss: 0.4641 - val_accuracy: 0.7536\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7605 - val_loss: 0.4613 - val_accuracy: 0.7536\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7605 - val_loss: 0.4588 - val_accuracy: 0.7536\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7669 - val_loss: 0.4559 - val_accuracy: 0.7681\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7637 - val_loss: 0.4550 - val_accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7653 - val_loss: 0.4536 - val_accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7637 - val_loss: 0.4519 - val_accuracy: 0.7826\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7669 - val_loss: 0.4504 - val_accuracy: 0.7971\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7653 - val_loss: 0.4491 - val_accuracy: 0.7971\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7669 - val_loss: 0.4484 - val_accuracy: 0.7971\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7717 - val_loss: 0.4477 - val_accuracy: 0.7826\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7765 - val_loss: 0.4475 - val_accuracy: 0.7971\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7717 - val_loss: 0.4474 - val_accuracy: 0.7971\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7717 - val_loss: 0.4460 - val_accuracy: 0.7971\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7733 - val_loss: 0.4451 - val_accuracy: 0.7971\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7717 - val_loss: 0.4440 - val_accuracy: 0.7971\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7749 - val_loss: 0.4447 - val_accuracy: 0.7971\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7749 - val_loss: 0.4438 - val_accuracy: 0.7971\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7781 - val_loss: 0.4426 - val_accuracy: 0.7826\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7765 - val_loss: 0.4438 - val_accuracy: 0.7971\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7797 - val_loss: 0.4420 - val_accuracy: 0.7826\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7846 - val_loss: 0.4433 - val_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7862 - val_loss: 0.4430 - val_accuracy: 0.7826\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4417 - val_accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7814 - val_loss: 0.4425 - val_accuracy: 0.7826\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7862 - val_loss: 0.4417 - val_accuracy: 0.7826\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7846 - val_loss: 0.4413 - val_accuracy: 0.7826\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7846 - val_loss: 0.4408 - val_accuracy: 0.7826\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7878 - val_loss: 0.4402 - val_accuracy: 0.7826\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7862 - val_loss: 0.4400 - val_accuracy: 0.7826\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7846 - val_loss: 0.4395 - val_accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.4393 - val_accuracy: 0.7826\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7862 - val_loss: 0.4391 - val_accuracy: 0.7826\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.4389 - val_accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7797 - val_loss: 0.4383 - val_accuracy: 0.7826\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4388 - val_accuracy: 0.7971\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7814 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4393 - val_accuracy: 0.7826\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7878 - val_loss: 0.4384 - val_accuracy: 0.7826\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7878 - val_loss: 0.4379 - val_accuracy: 0.7826\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7862 - val_loss: 0.4383 - val_accuracy: 0.7826\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7862 - val_loss: 0.4377 - val_accuracy: 0.7826\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7846 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7846 - val_loss: 0.4379 - val_accuracy: 0.7826\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7862 - val_loss: 0.4369 - val_accuracy: 0.7826\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7846 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4380 - val_accuracy: 0.7826\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.4389 - val_accuracy: 0.7826\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.4383 - val_accuracy: 0.7826\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7878 - val_loss: 0.4368 - val_accuracy: 0.7826\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7910 - val_loss: 0.4386 - val_accuracy: 0.7826\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7862 - val_loss: 0.4389 - val_accuracy: 0.7826\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7878 - val_loss: 0.4388 - val_accuracy: 0.7971\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7846 - val_loss: 0.4384 - val_accuracy: 0.7971\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7846 - val_loss: 0.4388 - val_accuracy: 0.7971\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 0.6706 - accuracy: 0.6720 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7074 - val_loss: 0.5820 - val_accuracy: 0.7246\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7170 - val_loss: 0.5668 - val_accuracy: 0.7101\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7251 - val_loss: 0.5555 - val_accuracy: 0.7391\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7219 - val_loss: 0.5445 - val_accuracy: 0.7246\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7235 - val_loss: 0.5330 - val_accuracy: 0.7101\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7203 - val_loss: 0.5216 - val_accuracy: 0.7246\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7235 - val_loss: 0.5167 - val_accuracy: 0.7536\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7283 - val_loss: 0.5073 - val_accuracy: 0.7536\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7363 - val_loss: 0.4969 - val_accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7283 - val_loss: 0.4880 - val_accuracy: 0.7971\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7283 - val_loss: 0.4835 - val_accuracy: 0.7971\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7331 - val_loss: 0.4778 - val_accuracy: 0.7971\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7347 - val_loss: 0.4762 - val_accuracy: 0.7971\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7347 - val_loss: 0.4713 - val_accuracy: 0.7826\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7412 - val_loss: 0.4677 - val_accuracy: 0.7826\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7363 - val_loss: 0.4718 - val_accuracy: 0.7681\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7363 - val_loss: 0.4678 - val_accuracy: 0.7681\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7444 - val_loss: 0.4634 - val_accuracy: 0.7826\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7476 - val_loss: 0.4625 - val_accuracy: 0.7826\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7460 - val_loss: 0.4600 - val_accuracy: 0.7681\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7476 - val_loss: 0.4581 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7476 - val_loss: 0.4565 - val_accuracy: 0.7826\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7524 - val_loss: 0.4558 - val_accuracy: 0.7536\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7524 - val_loss: 0.4593 - val_accuracy: 0.7536\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7524 - val_loss: 0.4568 - val_accuracy: 0.7681\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7476 - val_loss: 0.4553 - val_accuracy: 0.7681\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7556 - val_loss: 0.4490 - val_accuracy: 0.7536\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7588 - val_loss: 0.4547 - val_accuracy: 0.7536\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7637 - val_loss: 0.4556 - val_accuracy: 0.7536\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7621 - val_loss: 0.4511 - val_accuracy: 0.7681\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7637 - val_loss: 0.4481 - val_accuracy: 0.7681\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7605 - val_loss: 0.4530 - val_accuracy: 0.7536\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7637 - val_loss: 0.4506 - val_accuracy: 0.7681\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7637 - val_loss: 0.4455 - val_accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7637 - val_loss: 0.4490 - val_accuracy: 0.7681\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7605 - val_loss: 0.4492 - val_accuracy: 0.7681\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7605 - val_loss: 0.4476 - val_accuracy: 0.7681\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7669 - val_loss: 0.4452 - val_accuracy: 0.7681\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7701 - val_loss: 0.4465 - val_accuracy: 0.7681\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7701 - val_loss: 0.4442 - val_accuracy: 0.7681\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7669 - val_loss: 0.4468 - val_accuracy: 0.7681\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7637 - val_loss: 0.4461 - val_accuracy: 0.7681\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7797 - val_loss: 0.4394 - val_accuracy: 0.7681\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7765 - val_loss: 0.4485 - val_accuracy: 0.7681\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7765 - val_loss: 0.4406 - val_accuracy: 0.7681\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7733 - val_loss: 0.4460 - val_accuracy: 0.7536\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7765 - val_loss: 0.4415 - val_accuracy: 0.7681\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7814 - val_loss: 0.4399 - val_accuracy: 0.7681\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 0.8688 - accuracy: 0.6543 - val_loss: 0.7359 - val_accuracy: 0.6232\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8057 - accuracy: 0.6543 - val_loss: 0.7101 - val_accuracy: 0.6232\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.6543 - val_loss: 0.6907 - val_accuracy: 0.6232\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.6576 - val_loss: 0.6754 - val_accuracy: 0.6377\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.6656 - val_loss: 0.6604 - val_accuracy: 0.6232\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6720 - val_loss: 0.6463 - val_accuracy: 0.6232\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6881 - val_loss: 0.6303 - val_accuracy: 0.6522\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6897 - val_loss: 0.6154 - val_accuracy: 0.6232\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7026 - val_loss: 0.5998 - val_accuracy: 0.6232\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7315 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7412 - val_loss: 0.5706 - val_accuracy: 0.6812\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7508 - val_loss: 0.5601 - val_accuracy: 0.6812\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7524 - val_loss: 0.5474 - val_accuracy: 0.7246\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7428 - val_loss: 0.5399 - val_accuracy: 0.7391\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7460 - val_loss: 0.5312 - val_accuracy: 0.7391\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7444 - val_loss: 0.5253 - val_accuracy: 0.7246\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7460 - val_loss: 0.5176 - val_accuracy: 0.7246\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7524 - val_loss: 0.5115 - val_accuracy: 0.7391\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7524 - val_loss: 0.5056 - val_accuracy: 0.7391\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7492 - val_loss: 0.5023 - val_accuracy: 0.7246\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7556 - val_loss: 0.4964 - val_accuracy: 0.7391\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7556 - val_loss: 0.4913 - val_accuracy: 0.7536\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7588 - val_loss: 0.4891 - val_accuracy: 0.7681\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7637 - val_loss: 0.4854 - val_accuracy: 0.7681\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7653 - val_loss: 0.4846 - val_accuracy: 0.7681\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7669 - val_loss: 0.4830 - val_accuracy: 0.7826\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7685 - val_loss: 0.4812 - val_accuracy: 0.7826\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7685 - val_loss: 0.4779 - val_accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7701 - val_loss: 0.4750 - val_accuracy: 0.7971\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7749 - val_loss: 0.4743 - val_accuracy: 0.7971\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7749 - val_loss: 0.4707 - val_accuracy: 0.7971\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7749 - val_loss: 0.4715 - val_accuracy: 0.7971\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7781 - val_loss: 0.4714 - val_accuracy: 0.7971\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7781 - val_loss: 0.4677 - val_accuracy: 0.7826\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7797 - val_loss: 0.4709 - val_accuracy: 0.7826\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7797 - val_loss: 0.4701 - val_accuracy: 0.7826\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.4690 - val_accuracy: 0.7826\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4686 - val_accuracy: 0.7826\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7814 - val_loss: 0.4684 - val_accuracy: 0.7826\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.8051 - accuracy: 0.3328 - val_loss: 0.8364 - val_accuracy: 0.3623\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.3376 - val_loss: 0.7824 - val_accuracy: 0.3623\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7214 - accuracy: 0.3457 - val_loss: 0.7467 - val_accuracy: 0.3478\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.3842 - val_loss: 0.7230 - val_accuracy: 0.4058\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.4293 - val_loss: 0.7070 - val_accuracy: 0.4493\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.4887 - val_loss: 0.6936 - val_accuracy: 0.5217\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.5434 - val_loss: 0.6820 - val_accuracy: 0.5797\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6158 - val_loss: 0.6704 - val_accuracy: 0.6087\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6399 - val_loss: 0.6587 - val_accuracy: 0.6522\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6704 - val_loss: 0.6453 - val_accuracy: 0.6522\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6849 - val_loss: 0.6292 - val_accuracy: 0.6377\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6961 - val_loss: 0.6081 - val_accuracy: 0.6377\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7090 - val_loss: 0.5882 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7363 - val_loss: 0.5687 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7412 - val_loss: 0.5519 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7444 - val_loss: 0.5357 - val_accuracy: 0.7246\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7460 - val_loss: 0.5257 - val_accuracy: 0.7246\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7508 - val_loss: 0.5152 - val_accuracy: 0.7246\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7508 - val_loss: 0.5085 - val_accuracy: 0.7246\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7572 - val_loss: 0.5004 - val_accuracy: 0.7391\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7588 - val_loss: 0.4954 - val_accuracy: 0.7681\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7556 - val_loss: 0.4949 - val_accuracy: 0.7536\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7588 - val_loss: 0.4895 - val_accuracy: 0.7826\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7540 - val_loss: 0.4870 - val_accuracy: 0.7681\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7572 - val_loss: 0.4891 - val_accuracy: 0.7826\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7588 - val_loss: 0.4883 - val_accuracy: 0.7681\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7556 - val_loss: 0.4916 - val_accuracy: 0.7681\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7621 - val_loss: 0.4901 - val_accuracy: 0.7681\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7605 - val_loss: 0.4887 - val_accuracy: 0.7826\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 0.6902 - accuracy: 0.5048 - val_loss: 0.6688 - val_accuracy: 0.6232\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5691 - val_loss: 0.6458 - val_accuracy: 0.7246\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6286 - val_loss: 0.6249 - val_accuracy: 0.7391\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6463 - val_loss: 0.6069 - val_accuracy: 0.7681\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6720 - val_loss: 0.5889 - val_accuracy: 0.7536\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6881 - val_loss: 0.5722 - val_accuracy: 0.7536\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6897 - val_loss: 0.5593 - val_accuracy: 0.7246\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7010 - val_loss: 0.5452 - val_accuracy: 0.7246\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7074 - val_loss: 0.5345 - val_accuracy: 0.7391\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7154 - val_loss: 0.5232 - val_accuracy: 0.7391\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7203 - val_loss: 0.5150 - val_accuracy: 0.7391\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7154 - val_loss: 0.5085 - val_accuracy: 0.7681\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7170 - val_loss: 0.5015 - val_accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7203 - val_loss: 0.4972 - val_accuracy: 0.7536\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7219 - val_loss: 0.4913 - val_accuracy: 0.7536\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7267 - val_loss: 0.4879 - val_accuracy: 0.7536\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7315 - val_loss: 0.4837 - val_accuracy: 0.7536\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7363 - val_loss: 0.4796 - val_accuracy: 0.7681\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7444 - val_loss: 0.4804 - val_accuracy: 0.7681\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7444 - val_loss: 0.4787 - val_accuracy: 0.7826\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7460 - val_loss: 0.4719 - val_accuracy: 0.7826\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7460 - val_loss: 0.4753 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7508 - val_loss: 0.4733 - val_accuracy: 0.7971\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7508 - val_loss: 0.4714 - val_accuracy: 0.7971\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7540 - val_loss: 0.4709 - val_accuracy: 0.7971\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7540 - val_loss: 0.4754 - val_accuracy: 0.7971\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7621 - val_loss: 0.4727 - val_accuracy: 0.7971\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7572 - val_loss: 0.4761 - val_accuracy: 0.7971\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7701 - val_loss: 0.4761 - val_accuracy: 0.7971\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7717 - val_loss: 0.4755 - val_accuracy: 0.7971\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.8722 - accuracy: 0.5852 - val_loss: 0.7913 - val_accuracy: 0.4928\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.5514 - val_loss: 0.7513 - val_accuracy: 0.4783\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.5450 - val_loss: 0.7220 - val_accuracy: 0.4638\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.5675 - val_loss: 0.6970 - val_accuracy: 0.4638\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5852 - val_loss: 0.6767 - val_accuracy: 0.5507\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6415 - val_loss: 0.6590 - val_accuracy: 0.5942\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6688 - val_loss: 0.6438 - val_accuracy: 0.6377\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7026 - val_loss: 0.6279 - val_accuracy: 0.6812\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7154 - val_loss: 0.6103 - val_accuracy: 0.6957\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7251 - val_loss: 0.5952 - val_accuracy: 0.6957\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7363 - val_loss: 0.5810 - val_accuracy: 0.6957\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7379 - val_loss: 0.5673 - val_accuracy: 0.7391\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7444 - val_loss: 0.5540 - val_accuracy: 0.7246\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7492 - val_loss: 0.5440 - val_accuracy: 0.7101\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7492 - val_loss: 0.5339 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7508 - val_loss: 0.5257 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7540 - val_loss: 0.5181 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7556 - val_loss: 0.5109 - val_accuracy: 0.7101\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7605 - val_loss: 0.5085 - val_accuracy: 0.7101\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7621 - val_loss: 0.5032 - val_accuracy: 0.7246\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7653 - val_loss: 0.4961 - val_accuracy: 0.7246\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7637 - val_loss: 0.4956 - val_accuracy: 0.7391\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7669 - val_loss: 0.4909 - val_accuracy: 0.7391\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7653 - val_loss: 0.4901 - val_accuracy: 0.7246\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7637 - val_loss: 0.4904 - val_accuracy: 0.7246\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7653 - val_loss: 0.4910 - val_accuracy: 0.7101\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7685 - val_loss: 0.4891 - val_accuracy: 0.7101\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7685 - val_loss: 0.4851 - val_accuracy: 0.7101\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7717 - val_loss: 0.4880 - val_accuracy: 0.7101\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7733 - val_loss: 0.4868 - val_accuracy: 0.7101\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7749 - val_loss: 0.4854 - val_accuracy: 0.7246\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7765 - val_loss: 0.4875 - val_accuracy: 0.7101\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7733 - val_loss: 0.4845 - val_accuracy: 0.7101\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7733 - val_loss: 0.4848 - val_accuracy: 0.7246\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7814 - val_loss: 0.4837 - val_accuracy: 0.7246\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7846 - val_loss: 0.4845 - val_accuracy: 0.7391\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7246\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7391\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7814 - val_loss: 0.4863 - val_accuracy: 0.7246\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7814 - val_loss: 0.4850 - val_accuracy: 0.7246\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 9ms/step - loss: 0.7057 - accuracy: 0.4703 - val_loss: 0.6788 - val_accuracy: 0.6232\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5730 - val_loss: 0.6644 - val_accuracy: 0.7246\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6613 - val_loss: 0.6482 - val_accuracy: 0.7391\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6934 - val_loss: 0.6300 - val_accuracy: 0.7681\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.7063 - val_loss: 0.6092 - val_accuracy: 0.7101\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7159 - val_loss: 0.5876 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7239 - val_loss: 0.5678 - val_accuracy: 0.7101\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7239 - val_loss: 0.5495 - val_accuracy: 0.7246\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7255 - val_loss: 0.5319 - val_accuracy: 0.7391\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7271 - val_loss: 0.5202 - val_accuracy: 0.7681\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7223 - val_loss: 0.5108 - val_accuracy: 0.7681\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7271 - val_loss: 0.5000 - val_accuracy: 0.7681\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7384 - val_loss: 0.4908 - val_accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7368 - val_loss: 0.4882 - val_accuracy: 0.7681\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7464 - val_loss: 0.4817 - val_accuracy: 0.7826\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7528 - val_loss: 0.4776 - val_accuracy: 0.7826\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7560 - val_loss: 0.4787 - val_accuracy: 0.7971\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7576 - val_loss: 0.4733 - val_accuracy: 0.7971\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7592 - val_loss: 0.4733 - val_accuracy: 0.7971\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7560 - val_loss: 0.4714 - val_accuracy: 0.8116\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7608 - val_loss: 0.4703 - val_accuracy: 0.8116\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7657 - val_loss: 0.4646 - val_accuracy: 0.8116\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7657 - val_loss: 0.4668 - val_accuracy: 0.8116\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7657 - val_loss: 0.4647 - val_accuracy: 0.8116\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7640 - val_loss: 0.4640 - val_accuracy: 0.8116\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7640 - val_loss: 0.4622 - val_accuracy: 0.8116\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7673 - val_loss: 0.4642 - val_accuracy: 0.8116\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7640 - val_loss: 0.4630 - val_accuracy: 0.8116\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7657 - val_loss: 0.4601 - val_accuracy: 0.8116\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7657 - val_loss: 0.4622 - val_accuracy: 0.7971\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7624 - val_loss: 0.4651 - val_accuracy: 0.8116\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7640 - val_loss: 0.4644 - val_accuracy: 0.7826\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7673 - val_loss: 0.4646 - val_accuracy: 0.8116\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7657 - val_loss: 0.4643 - val_accuracy: 0.7971\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "iteration\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 21ms/step - loss: 0.6818 - accuracy: 0.5554 - val_loss: 0.6993 - val_accuracy: 0.4783\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5875 - val_loss: 0.6874 - val_accuracy: 0.5217\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6051 - val_loss: 0.6785 - val_accuracy: 0.5507\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6324 - val_loss: 0.6702 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6613 - val_loss: 0.6601 - val_accuracy: 0.5507\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6774 - val_loss: 0.6492 - val_accuracy: 0.5942\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6886 - val_loss: 0.6364 - val_accuracy: 0.5942\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6918 - val_loss: 0.6219 - val_accuracy: 0.5942\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.6998 - val_loss: 0.6110 - val_accuracy: 0.6087\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7014 - val_loss: 0.5972 - val_accuracy: 0.6232\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7047 - val_loss: 0.5832 - val_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7095 - val_loss: 0.5755 - val_accuracy: 0.6812\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7111 - val_loss: 0.5689 - val_accuracy: 0.6812\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7127 - val_loss: 0.5587 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7175 - val_loss: 0.5528 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7207 - val_loss: 0.5485 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7271 - val_loss: 0.5434 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7303 - val_loss: 0.5370 - val_accuracy: 0.6957\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7319 - val_loss: 0.5350 - val_accuracy: 0.6812\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7303 - val_loss: 0.5281 - val_accuracy: 0.6812\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7400 - val_loss: 0.5203 - val_accuracy: 0.6812\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7432 - val_loss: 0.5176 - val_accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7432 - val_loss: 0.5114 - val_accuracy: 0.6957\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7448 - val_loss: 0.5084 - val_accuracy: 0.6957\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7528 - val_loss: 0.5013 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7576 - val_loss: 0.4992 - val_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7576 - val_loss: 0.4980 - val_accuracy: 0.6812\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7657 - val_loss: 0.4922 - val_accuracy: 0.7246\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7705 - val_loss: 0.4943 - val_accuracy: 0.7101\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7721 - val_loss: 0.4920 - val_accuracy: 0.7246\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7737 - val_loss: 0.4890 - val_accuracy: 0.7536\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7769 - val_loss: 0.4922 - val_accuracy: 0.7391\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7721 - val_loss: 0.4897 - val_accuracy: 0.7536\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7785 - val_loss: 0.4859 - val_accuracy: 0.7681\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7801 - val_loss: 0.4849 - val_accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7817 - val_loss: 0.4889 - val_accuracy: 0.7391\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7801 - val_loss: 0.4840 - val_accuracy: 0.7681\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7801 - val_loss: 0.4907 - val_accuracy: 0.7536\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7769 - val_loss: 0.4857 - val_accuracy: 0.7536\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7769 - val_loss: 0.4848 - val_accuracy: 0.7681\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7801 - val_loss: 0.4876 - val_accuracy: 0.7536\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7849 - val_loss: 0.4846 - val_accuracy: 0.7681\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# perform nested cross-validation for NN\n",
    "model_name = \"NeuralNetwork\"\n",
    "for train_idx, test_idx in outer_cv.split(X, y):\n",
    "    print(\"iteration\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "\n",
    "    # validation for early stopping\n",
    "    val_split = 0.1\n",
    "    num_val = int(len(X_train) * val_split)\n",
    "    X_train, X_val = X_train[:-num_val], X_train[-num_val:]\n",
    "    y_train, y_val = y_train[:-num_val], y_train[-num_val:]\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    cw = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    weights = {0:cw[0], 1:cw[1]}\n",
    "\n",
    "    # Train and score uneducated\n",
    "    model_name = \"NeuralNetwork\"\n",
    "    uneducated = create_uneducated_predictor(X_train.shape[1], 1, [12, 8], \"relu\", \"sigmoid\")\n",
    "    uneducated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "    history_uneducated = uneducated.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
    "                                        class_weight=weights, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    #_, acc = uneducated.evaluate(X_test, y_test) #print(f'test set accuracy of the uneducated predictor: {acc*100:.2f}%')\n",
    "    y_pred = uneducated.predict(X_test).flatten().round().astype(\"int\")\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e4e2a555-4931-4272-9252-2c3972a1d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "test_indices = np.concatenate([test_idx for _, test_idx in outer_cv.split(X, y)])\n",
    "res_df = pd.DataFrame(all_pred, index = test_indices).sort_index()\n",
    "#res_df.to_csv(\"goodit_cv_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(\"goodit_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "b5f217ed-4019-4e53-8c36-5fb2a7a1c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset and results\n",
    "dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "df = pd.read_csv(\"goodit_cv_results.csv\", index_col = 0)\n",
    "res_df = pd.read_csv(\"goodit_cv_predictions.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "4b62ae71-6c9d-4ad3-acd2-491a78d3ef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SupportVector</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric              accuracy  balanced_accuracy     f1    mcc  precision  \\\n",
       "model                                                                      \n",
       "NeuralNetwork          0.738              0.742  0.670  0.472      0.612   \n",
       "DecisionTree           0.738              0.741  0.667  0.468      0.604   \n",
       "RandomForest           0.772              0.768  0.697  0.522      0.652   \n",
       "GradientBoosting       0.756              0.754  0.681  0.499      0.637   \n",
       "SupportVector          0.762              0.751  0.678  0.497      0.651   \n",
       "LogisticRegression     0.751              0.742  0.666  0.477      0.636   \n",
       "\n",
       "metric              recall  relative_accuracy  relative_recall  tn_rate  \\\n",
       "model                                                                     \n",
       "NeuralNetwork        0.754              0.982            0.976    0.475   \n",
       "DecisionTree         0.753              0.934            0.913    0.475   \n",
       "RandomForest         0.753              0.950            0.932    0.509   \n",
       "GradientBoosting     0.746              0.958            0.941    0.496   \n",
       "SupportVector        0.717              0.958            0.944    0.512   \n",
       "LogisticRegression   0.709              0.954            0.938    0.504   \n",
       "\n",
       "metric              tp_rate  fn_rate  fp_rate  \n",
       "model                                          \n",
       "NeuralNetwork         0.263    0.086    0.176  \n",
       "DecisionTree          0.263    0.086    0.176  \n",
       "RandomForest          0.263    0.086    0.142  \n",
       "GradientBoosting      0.260    0.089    0.155  \n",
       "SupportVector         0.250    0.099    0.140  \n",
       "LogisticRegression    0.247    0.102    0.147  "
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(\n",
    "    by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "ef9c0bd5-13e3-4ebc-9c98-5522c6463c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_order = list(means_df.index)\n",
    "res_df[\"pred_mean\"] = res_df[models_order].mean(axis = 1)\n",
    "res_df[\"Outcome\"] = dataset[\"Outcome\"]\n",
    "res_df[\"ClinicalProtocol\"] = dataset_rules[\"Rules\"]\n",
    "res_df[\"EQ\"] = res_df[\"Outcome\"]==res_df[\"ClinicalProtocol\"]\n",
    "res_df = res_df.fillna(-1)\n",
    "res_df = res_df[['Outcome', 'ClinicalProtocol', 'EQ', 'pred_mean'] + models_order]\n",
    "res_df = res_df.sort_values(['Outcome','ClinicalProtocol','EQ','pred_mean'], ascending=[False]*4)\n",
    "res_df_index = res_df.index\n",
    "res_df = res_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "0ccbcaa3-9a1f-4ccc-9015-a719b2bdfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in res_df[\"Outcome\"].unique():\n",
    "    for c in res_df[\"ClinicalProtocol\"].unique():\n",
    "        idx = res_df[(res_df[\"Outcome\"]==o) & (res_df[\"ClinicalProtocol\"]==c)].index\n",
    "        for col in res_df.columns[-6:]:\n",
    "            res_df.loc[idx,col] = list(res_df.loc[idx,col].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "f7c155ea-4361-4512-8286-808b33b748da",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_col = \"navy\"\n",
    "healthy_col = \"hotpink\"#\"steelblue\"\n",
    "# diabetes_col = \"gold\"#\"gold\"\n",
    "# healthy_col = \"lightseagreen\"#\"deepskyblue\"#\"light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "d5659301-f6c0-4796-a8f9-ff9e43ab263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['patch.edgecolor'] = 'none'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(9, 3.2))\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('rg', [ \"lightgray\", healthy_col, diabetes_col], N=256) \n",
    "sns.heatmap(res_df.drop(columns = [\"EQ\",\"pred_mean\"]).T, cmap=cmap, cbar=False, alpha=0.7, xticklabels = 100, \n",
    "            linewidths=0.0, ax=axes, rasterized=True)\n",
    "axes.set_yticklabels(['Outcome', 'Clinical Protocol', 'Neural Network', 'Decision Tree', 'Random Forest', 'Gradient Boosting', \n",
    "                      'Support Vector', 'Logistic Regression'])\n",
    "axes.tick_params(axis='both', which='major', labelsize=11)\n",
    "colors = axes.collections[0].get_facecolors()\n",
    "axes.collections[0].set_edgecolors(colors)\n",
    "\n",
    "for r in range(1,len(res_df.columns)-1):\n",
    "    axes.add_patch(Rectangle((0, 0),  len(res_df), r, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), len(res_df), 8, fill=False, edgecolor=\"black\", lw=1, clip_on=False))\n",
    "\n",
    "n1 = len(res_df[(res_df[\"Outcome\"]==1) & (res_df[\"ClinicalProtocol\"]==1)])\n",
    "n2 = len(res_df[(res_df[\"Outcome\"]==1)])\n",
    "n3 = len(res_df[(res_df[\"Outcome\"]==1)]) + len(res_df[(res_df[\"Outcome\"]==0) & (res_df[\"ClinicalProtocol\"]==1)])\n",
    "n4 = len(res_df) - len(res_df[(res_df[\"Outcome\"]==0) & (res_df[\"ClinicalProtocol\"]==-1)])\n",
    "n5 = len(res_df)\n",
    "\n",
    "axes.add_patch(Rectangle((0, 0), n1, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n2, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n3, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n4, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "axes.add_patch(Rectangle((n1, 1), n2-n1, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 1), n2-n1, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 1), n5-n4, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 1), n5-n4, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "axes.add_patch(Rectangle((0, 0), n5, 8, fill=False, edgecolor=\"black\", lw=1, clip_on=False))\n",
    "\n",
    "plt.text(n1/2,     -0.2, \"1\", size=11)\n",
    "plt.text((n1+n2)/2,-0.2, \"2\", size=11)\n",
    "plt.text((n2+n3)/2,-0.2, \"3\", size=11)\n",
    "plt.text((n3+n4)/2,-0.2, \"4\", size=11)\n",
    "plt.text((n4+n5)/2,-0.2, \"5\", size=11)\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=diabetes_col, edgecolor=\"dimgray\", label=\"Diabetic\", alpha= 0.7),\n",
    "    Patch(facecolor=\"lightgray\", edgecolor=\"dimgray\", label=\"N/A\", hatch=\"xx\"),\n",
    "    Patch(facecolor=healthy_col, edgecolor=\"dimgray\", label=\"Healthy\", alpha= 0.7)\n",
    "]\n",
    "\n",
    "legend = axes.legend(handles=legend_elements, loc=\"upper center\", bbox_to_anchor=(0.5, 1.25), ncol=3, fontsize=11)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "legend.get_frame().set_facecolor('none')\n",
    "legend.get_frame().set_edgecolor('none')\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"ml_models2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a67598-44ed-4399-860f-2db713890968",
   "metadata": {},
   "source": [
    "## KNOWEDGE INJECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fdff8-2363-48f9-a28f-ff86178c6936",
   "metadata": {},
   "source": [
    "### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "88cc8193-19a1-45bb-91bc-ba45028da596",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"inj_nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "bdbc791e-39bb-4685-bfbe-6ddaf1043a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "X = dataset.iloc[:, :-1].values.astype(\"float32\")\n",
    "y = dataset.iloc[:, -1].values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "2ddb759b-ae85-4861-bf6f-d0f1f1510e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "95ee3052-660f-462d-9eca-244fa210983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes.pl\")\n",
    "theory = Theory(knowledge, dataset)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "190c2d82-f18b-435a-965e-577f6f2623b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.7830 - accuracy: 0.4316 - val_loss: 0.7527 - val_accuracy: 0.4857\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.4960 - val_loss: 0.6719 - val_accuracy: 0.5571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.5733 - val_loss: 0.6253 - val_accuracy: 0.6143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6425 - val_loss: 0.5923 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.6667 - val_loss: 0.5717 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6795 - val_loss: 0.5548 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7101 - val_loss: 0.5403 - val_accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7166 - val_loss: 0.5285 - val_accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7182 - val_loss: 0.5203 - val_accuracy: 0.7286\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7262 - val_loss: 0.5100 - val_accuracy: 0.7286\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7279 - val_loss: 0.5012 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7343 - val_loss: 0.4917 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7391 - val_loss: 0.4862 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7391 - val_loss: 0.4797 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7424 - val_loss: 0.4757 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7391 - val_loss: 0.4775 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7456 - val_loss: 0.4696 - val_accuracy: 0.7429\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7456 - val_loss: 0.4705 - val_accuracy: 0.7286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7536 - val_loss: 0.4672 - val_accuracy: 0.7286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7568 - val_loss: 0.4615 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7585 - val_loss: 0.4619 - val_accuracy: 0.7286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7552 - val_loss: 0.4619 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7585 - val_loss: 0.4581 - val_accuracy: 0.7429\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7601 - val_loss: 0.4588 - val_accuracy: 0.7429\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7536 - val_loss: 0.4624 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7585 - val_loss: 0.4578 - val_accuracy: 0.7429\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7568 - val_loss: 0.4589 - val_accuracy: 0.7429\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7568 - val_loss: 0.4632 - val_accuracy: 0.7286\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7536 - val_loss: 0.4624 - val_accuracy: 0.7286\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7552 - val_loss: 0.4621 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7601 - val_loss: 0.4604 - val_accuracy: 0.7571\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 12ms/step - loss: 0.7498 - accuracy: 0.4928 - val_loss: 0.7545 - val_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5926 - val_loss: 0.6928 - val_accuracy: 0.5857\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6135 - val_loss: 0.6524 - val_accuracy: 0.6571\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6377 - val_loss: 0.6141 - val_accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6554 - val_loss: 0.5800 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6763 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.6973 - val_loss: 0.5353 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7037 - val_loss: 0.5216 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7101 - val_loss: 0.5089 - val_accuracy: 0.7429\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7198 - val_loss: 0.4966 - val_accuracy: 0.7571\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7279 - val_loss: 0.4867 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7391 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7407 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7440 - val_loss: 0.4616 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7407 - val_loss: 0.4556 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7424 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7504 - val_loss: 0.4512 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7601 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7585 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7617 - val_loss: 0.4406 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7681 - val_loss: 0.4418 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7617 - val_loss: 0.4420 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7697 - val_loss: 0.4381 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7681 - val_loss: 0.4409 - val_accuracy: 0.7714\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7697 - val_loss: 0.4444 - val_accuracy: 0.7714\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7713 - val_loss: 0.4362 - val_accuracy: 0.7714\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7762 - val_loss: 0.4397 - val_accuracy: 0.7714\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7681 - val_loss: 0.4436 - val_accuracy: 0.7714\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7681 - val_loss: 0.4413 - val_accuracy: 0.7714\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7681 - val_loss: 0.4399 - val_accuracy: 0.7714\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7681 - val_loss: 0.4358 - val_accuracy: 0.7714\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7729 - val_loss: 0.4340 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7681 - val_loss: 0.4436 - val_accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7681 - val_loss: 0.4432 - val_accuracy: 0.7714\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.4370 - val_accuracy: 0.7714\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7762 - val_loss: 0.4386 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7746 - val_loss: 0.4453 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 21ms/step - loss: 0.7655 - accuracy: 0.3961 - val_loss: 0.7778 - val_accuracy: 0.3714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6998 - accuracy: 0.4718 - val_loss: 0.6941 - val_accuracy: 0.5286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6006 - val_loss: 0.6362 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6940 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7214 - val_loss: 0.5553 - val_accuracy: 0.7286\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.7166 - val_loss: 0.5327 - val_accuracy: 0.7286\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7295 - val_loss: 0.5150 - val_accuracy: 0.7571\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7407 - val_loss: 0.5049 - val_accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7472 - val_loss: 0.4996 - val_accuracy: 0.7571\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7472 - val_loss: 0.4884 - val_accuracy: 0.7571\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7472 - val_loss: 0.4825 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7520 - val_loss: 0.4772 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7520 - val_loss: 0.4732 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7536 - val_loss: 0.4684 - val_accuracy: 0.7714\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7585 - val_loss: 0.4709 - val_accuracy: 0.7714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7552 - val_loss: 0.4780 - val_accuracy: 0.7714\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7585 - val_loss: 0.4709 - val_accuracy: 0.7714\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7601 - val_loss: 0.4736 - val_accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7601 - val_loss: 0.4708 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 1\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 9ms/step - loss: 0.7600 - accuracy: 0.3156 - val_loss: 0.8083 - val_accuracy: 0.3143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.3639 - val_loss: 0.7706 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.4106 - val_loss: 0.7477 - val_accuracy: 0.3857\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.5040 - val_loss: 0.7204 - val_accuracy: 0.4857\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.5990 - val_loss: 0.6963 - val_accuracy: 0.5857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6651 - val_loss: 0.6742 - val_accuracy: 0.6571\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.6989 - val_loss: 0.6549 - val_accuracy: 0.7429\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7214 - val_loss: 0.6363 - val_accuracy: 0.7714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.6142 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7536 - val_loss: 0.5984 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7617 - val_loss: 0.5795 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7585 - val_loss: 0.5611 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7633 - val_loss: 0.5499 - val_accuracy: 0.7714\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7697 - val_loss: 0.5361 - val_accuracy: 0.7714\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7665 - val_loss: 0.5282 - val_accuracy: 0.7714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7665 - val_loss: 0.5243 - val_accuracy: 0.7714\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7649 - val_loss: 0.5103 - val_accuracy: 0.7714\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7633 - val_loss: 0.5056 - val_accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7665 - val_loss: 0.4994 - val_accuracy: 0.7714\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7665 - val_loss: 0.4930 - val_accuracy: 0.7714\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7729 - val_loss: 0.4867 - val_accuracy: 0.7714\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7713 - val_loss: 0.4821 - val_accuracy: 0.7857\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7729 - val_loss: 0.4781 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7746 - val_loss: 0.4736 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7697 - val_loss: 0.4749 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7681 - val_loss: 0.4713 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7697 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7729 - val_loss: 0.4667 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7713 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7762 - val_loss: 0.4666 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7794 - val_loss: 0.4573 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7826 - val_loss: 0.4533 - val_accuracy: 0.8143\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7858 - val_loss: 0.4588 - val_accuracy: 0.8143\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7890 - val_loss: 0.4608 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7923 - val_loss: 0.4512 - val_accuracy: 0.8143\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7874 - val_loss: 0.4504 - val_accuracy: 0.8143\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7923 - val_loss: 0.4506 - val_accuracy: 0.8143\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7939 - val_loss: 0.4482 - val_accuracy: 0.8143\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7923 - val_loss: 0.4460 - val_accuracy: 0.8143\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7939 - val_loss: 0.4514 - val_accuracy: 0.8286\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7955 - val_loss: 0.4528 - val_accuracy: 0.8286\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7971 - val_loss: 0.4427 - val_accuracy: 0.8143\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7987 - val_loss: 0.4399 - val_accuracy: 0.8143\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8019 - val_loss: 0.4433 - val_accuracy: 0.8286\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7971 - val_loss: 0.4442 - val_accuracy: 0.8286\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8003 - val_loss: 0.4419 - val_accuracy: 0.8286\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7939 - val_loss: 0.4442 - val_accuracy: 0.8286\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7939 - val_loss: 0.4389 - val_accuracy: 0.8286\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7955 - val_loss: 0.4347 - val_accuracy: 0.8286\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7987 - val_loss: 0.4342 - val_accuracy: 0.8286\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7955 - val_loss: 0.4335 - val_accuracy: 0.8286\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7939 - val_loss: 0.4314 - val_accuracy: 0.8286\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7907 - val_loss: 0.4317 - val_accuracy: 0.8286\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7907 - val_loss: 0.4353 - val_accuracy: 0.8286\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7987 - val_loss: 0.4293 - val_accuracy: 0.8286\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7923 - val_loss: 0.4334 - val_accuracy: 0.8286\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7907 - val_loss: 0.4326 - val_accuracy: 0.8286\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7890 - val_loss: 0.4314 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7939 - val_loss: 0.4312 - val_accuracy: 0.8429\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7907 - val_loss: 0.4293 - val_accuracy: 0.8429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 17ms/step - loss: 0.6434 - accuracy: 0.6989 - val_loss: 0.5769 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6989 - val_loss: 0.5544 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6989 - val_loss: 0.5430 - val_accuracy: 0.7286\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7166 - val_loss: 0.5240 - val_accuracy: 0.7429\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7214 - val_loss: 0.5086 - val_accuracy: 0.7857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7311 - val_loss: 0.5023 - val_accuracy: 0.8143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7327 - val_loss: 0.4911 - val_accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7359 - val_loss: 0.4878 - val_accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7407 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7424 - val_loss: 0.4782 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7440 - val_loss: 0.4741 - val_accuracy: 0.8143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7440 - val_loss: 0.4667 - val_accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7456 - val_loss: 0.4634 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7440 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7456 - val_loss: 0.4607 - val_accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7407 - val_loss: 0.4653 - val_accuracy: 0.8286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7504 - val_loss: 0.4540 - val_accuracy: 0.8143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7488 - val_loss: 0.4533 - val_accuracy: 0.8143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7504 - val_loss: 0.4532 - val_accuracy: 0.8143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7520 - val_loss: 0.4480 - val_accuracy: 0.8286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7568 - val_loss: 0.4480 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7568 - val_loss: 0.4484 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7601 - val_loss: 0.4451 - val_accuracy: 0.8286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7649 - val_loss: 0.4463 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7568 - val_loss: 0.4462 - val_accuracy: 0.8286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7617 - val_loss: 0.4466 - val_accuracy: 0.8286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7649 - val_loss: 0.4449 - val_accuracy: 0.8286\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7633 - val_loss: 0.4449 - val_accuracy: 0.8286\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7665 - val_loss: 0.4436 - val_accuracy: 0.8286\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7536 - val_loss: 0.4516 - val_accuracy: 0.8286\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7568 - val_loss: 0.4390 - val_accuracy: 0.8286\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7746 - val_loss: 0.4370 - val_accuracy: 0.8286\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7697 - val_loss: 0.4459 - val_accuracy: 0.8286\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7617 - val_loss: 0.4499 - val_accuracy: 0.8286\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7665 - val_loss: 0.4374 - val_accuracy: 0.8286\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7713 - val_loss: 0.4422 - val_accuracy: 0.8286\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7681 - val_loss: 0.4396 - val_accuracy: 0.8286\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 38ms/step - loss: 0.6307 - accuracy: 0.6924 - val_loss: 0.5876 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7118 - val_loss: 0.5523 - val_accuracy: 0.7286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7005 - val_loss: 0.5294 - val_accuracy: 0.7429\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7182 - val_loss: 0.5102 - val_accuracy: 0.7571\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7246 - val_loss: 0.4916 - val_accuracy: 0.7714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7343 - val_loss: 0.4811 - val_accuracy: 0.7714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7456 - val_loss: 0.4697 - val_accuracy: 0.7714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7440 - val_loss: 0.4645 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7359 - val_loss: 0.4580 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7391 - val_loss: 0.4538 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7440 - val_loss: 0.4477 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7520 - val_loss: 0.4407 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7536 - val_loss: 0.4395 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7585 - val_loss: 0.4359 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7552 - val_loss: 0.4351 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7536 - val_loss: 0.4349 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7552 - val_loss: 0.4308 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7552 - val_loss: 0.4266 - val_accuracy: 0.8286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7601 - val_loss: 0.4258 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7649 - val_loss: 0.4204 - val_accuracy: 0.8143\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7601 - val_loss: 0.4211 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7601 - val_loss: 0.4234 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7617 - val_loss: 0.4176 - val_accuracy: 0.8429\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7665 - val_loss: 0.4172 - val_accuracy: 0.8429\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7681 - val_loss: 0.4165 - val_accuracy: 0.8429\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7681 - val_loss: 0.4153 - val_accuracy: 0.8286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7681 - val_loss: 0.4146 - val_accuracy: 0.8429\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7713 - val_loss: 0.4127 - val_accuracy: 0.8429\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7713 - val_loss: 0.4126 - val_accuracy: 0.8429\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7729 - val_loss: 0.4168 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.4081 - val_accuracy: 0.8429\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.4066 - val_accuracy: 0.8429\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7810 - val_loss: 0.4096 - val_accuracy: 0.8429\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7713 - val_loss: 0.4135 - val_accuracy: 0.8429\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7762 - val_loss: 0.4060 - val_accuracy: 0.8429\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7762 - val_loss: 0.4096 - val_accuracy: 0.8429\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7826 - val_loss: 0.4047 - val_accuracy: 0.8429\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7810 - val_loss: 0.4080 - val_accuracy: 0.8429\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.4054 - val_accuracy: 0.8429\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7810 - val_loss: 0.4066 - val_accuracy: 0.8429\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7810 - val_loss: 0.4108 - val_accuracy: 0.8286\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7794 - val_loss: 0.4071 - val_accuracy: 0.8429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 2\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 9ms/step - loss: 0.7957 - accuracy: 0.4992 - val_loss: 0.7144 - val_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.5282 - val_loss: 0.6738 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5636 - val_loss: 0.6386 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.5942 - val_loss: 0.6067 - val_accuracy: 0.6857\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6409 - val_loss: 0.5780 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6634 - val_loss: 0.5536 - val_accuracy: 0.7286\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6892 - val_loss: 0.5324 - val_accuracy: 0.6857\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6892 - val_loss: 0.5179 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.6924 - val_loss: 0.5028 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.6876 - val_loss: 0.4931 - val_accuracy: 0.7286\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.6908 - val_loss: 0.4840 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.6957 - val_loss: 0.4768 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.6924 - val_loss: 0.4701 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.6957 - val_loss: 0.4660 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7005 - val_loss: 0.4630 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7021 - val_loss: 0.4604 - val_accuracy: 0.7571\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7021 - val_loss: 0.4556 - val_accuracy: 0.7571\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7053 - val_loss: 0.4536 - val_accuracy: 0.7571\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7118 - val_loss: 0.4504 - val_accuracy: 0.7571\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7166 - val_loss: 0.4466 - val_accuracy: 0.7571\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7198 - val_loss: 0.4461 - val_accuracy: 0.7714\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7214 - val_loss: 0.4448 - val_accuracy: 0.7714\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7295 - val_loss: 0.4430 - val_accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7279 - val_loss: 0.4439 - val_accuracy: 0.7714\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7311 - val_loss: 0.4414 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7391 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7456 - val_loss: 0.4415 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7456 - val_loss: 0.4422 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7472 - val_loss: 0.4418 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7552 - val_loss: 0.4431 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7568 - val_loss: 0.4438 - val_accuracy: 0.8000\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 37ms/step - loss: 0.8131 - accuracy: 0.4605 - val_loss: 0.7604 - val_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.5233 - val_loss: 0.6838 - val_accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6216 - val_loss: 0.6330 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.6876 - val_loss: 0.5898 - val_accuracy: 0.7571\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.7101 - val_loss: 0.5551 - val_accuracy: 0.7714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7182 - val_loss: 0.5286 - val_accuracy: 0.7714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7295 - val_loss: 0.5076 - val_accuracy: 0.7571\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7343 - val_loss: 0.4923 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7391 - val_loss: 0.4804 - val_accuracy: 0.7714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7456 - val_loss: 0.4733 - val_accuracy: 0.7571\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7472 - val_loss: 0.4669 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7488 - val_loss: 0.4616 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7488 - val_loss: 0.4565 - val_accuracy: 0.7286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7472 - val_loss: 0.4535 - val_accuracy: 0.7286\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7472 - val_loss: 0.4537 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7440 - val_loss: 0.4546 - val_accuracy: 0.7429\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7472 - val_loss: 0.4511 - val_accuracy: 0.7429\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7472 - val_loss: 0.4528 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7472 - val_loss: 0.4523 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7488 - val_loss: 0.4491 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7520 - val_loss: 0.4526 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7568 - val_loss: 0.4525 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7552 - val_loss: 0.4503 - val_accuracy: 0.7429\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7585 - val_loss: 0.4562 - val_accuracy: 0.7571\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7585 - val_loss: 0.4560 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 36ms/step - loss: 0.8386 - accuracy: 0.3510 - val_loss: 0.7659 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7613 - accuracy: 0.4332 - val_loss: 0.7015 - val_accuracy: 0.5143\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.5137 - val_loss: 0.6555 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6103 - val_loss: 0.6126 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6860 - val_loss: 0.5756 - val_accuracy: 0.8143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.7134 - val_loss: 0.5473 - val_accuracy: 0.8286\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7198 - val_loss: 0.5226 - val_accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7424 - val_loss: 0.5037 - val_accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7407 - val_loss: 0.4893 - val_accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7407 - val_loss: 0.4777 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7440 - val_loss: 0.4687 - val_accuracy: 0.8143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7424 - val_loss: 0.4601 - val_accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7407 - val_loss: 0.4527 - val_accuracy: 0.8286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7440 - val_loss: 0.4484 - val_accuracy: 0.8286\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7440 - val_loss: 0.4465 - val_accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7424 - val_loss: 0.4457 - val_accuracy: 0.8143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7391 - val_loss: 0.4414 - val_accuracy: 0.8143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7424 - val_loss: 0.4404 - val_accuracy: 0.8143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7424 - val_loss: 0.4380 - val_accuracy: 0.8143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7456 - val_loss: 0.4339 - val_accuracy: 0.8143\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7488 - val_loss: 0.4363 - val_accuracy: 0.8143\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7488 - val_loss: 0.4366 - val_accuracy: 0.8143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7488 - val_loss: 0.4338 - val_accuracy: 0.8143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7520 - val_loss: 0.4415 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7552 - val_loss: 0.4384 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7536 - val_loss: 0.4373 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7552 - val_loss: 0.4387 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7536 - val_loss: 0.4416 - val_accuracy: 0.8000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 3\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.7563 - accuracy: 0.5056 - val_loss: 0.7033 - val_accuracy: 0.5429\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.5298 - val_loss: 0.6834 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5636 - val_loss: 0.6676 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5974 - val_loss: 0.6520 - val_accuracy: 0.6571\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6345 - val_loss: 0.6369 - val_accuracy: 0.6286\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6425 - val_loss: 0.6200 - val_accuracy: 0.6571\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6634 - val_loss: 0.6039 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6828 - val_loss: 0.5901 - val_accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6957 - val_loss: 0.5767 - val_accuracy: 0.7286\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7053 - val_loss: 0.5671 - val_accuracy: 0.7429\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7069 - val_loss: 0.5551 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7134 - val_loss: 0.5461 - val_accuracy: 0.7286\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7150 - val_loss: 0.5376 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7166 - val_loss: 0.5290 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7230 - val_loss: 0.5251 - val_accuracy: 0.7286\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7246 - val_loss: 0.5242 - val_accuracy: 0.7143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7230 - val_loss: 0.5177 - val_accuracy: 0.7286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7214 - val_loss: 0.5175 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7246 - val_loss: 0.5124 - val_accuracy: 0.7571\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7311 - val_loss: 0.5085 - val_accuracy: 0.7571\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7343 - val_loss: 0.5086 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7343 - val_loss: 0.5077 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7375 - val_loss: 0.5049 - val_accuracy: 0.7429\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7407 - val_loss: 0.5046 - val_accuracy: 0.7429\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7424 - val_loss: 0.5066 - val_accuracy: 0.7429\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7407 - val_loss: 0.5068 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7472 - val_loss: 0.5095 - val_accuracy: 0.7714\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7456 - val_loss: 0.5103 - val_accuracy: 0.7429\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7488 - val_loss: 0.5107 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 37ms/step - loss: 0.7123 - accuracy: 0.5217 - val_loss: 0.7120 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.5942 - val_loss: 0.6523 - val_accuracy: 0.6714\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6490 - val_loss: 0.6138 - val_accuracy: 0.6857\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.6924 - val_loss: 0.5846 - val_accuracy: 0.7143\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7182 - val_loss: 0.5622 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7262 - val_loss: 0.5493 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7295 - val_loss: 0.5384 - val_accuracy: 0.7571\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7311 - val_loss: 0.5316 - val_accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7311 - val_loss: 0.5274 - val_accuracy: 0.7286\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7391 - val_loss: 0.5262 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7375 - val_loss: 0.5208 - val_accuracy: 0.7286\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7440 - val_loss: 0.5172 - val_accuracy: 0.7286\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7440 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7456 - val_loss: 0.5126 - val_accuracy: 0.7571\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7456 - val_loss: 0.5151 - val_accuracy: 0.7714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7407 - val_loss: 0.5194 - val_accuracy: 0.7429\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7375 - val_loss: 0.5139 - val_accuracy: 0.7571\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7391 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7407 - val_loss: 0.5141 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 36ms/step - loss: 0.6828 - accuracy: 0.4879 - val_loss: 0.7029 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.5942 - val_loss: 0.6465 - val_accuracy: 0.6286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6377 - val_loss: 0.6187 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.6651 - val_loss: 0.5935 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.6715 - val_loss: 0.5743 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.6876 - val_loss: 0.5633 - val_accuracy: 0.6571\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.6973 - val_loss: 0.5534 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7021 - val_loss: 0.5460 - val_accuracy: 0.6714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7069 - val_loss: 0.5439 - val_accuracy: 0.6714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7037 - val_loss: 0.5434 - val_accuracy: 0.6714\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7069 - val_loss: 0.5338 - val_accuracy: 0.6714\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7134 - val_loss: 0.5287 - val_accuracy: 0.6714\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7166 - val_loss: 0.5234 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7182 - val_loss: 0.5188 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7279 - val_loss: 0.5211 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7295 - val_loss: 0.5246 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7343 - val_loss: 0.5168 - val_accuracy: 0.7429\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7327 - val_loss: 0.5206 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7391 - val_loss: 0.5172 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7407 - val_loss: 0.5117 - val_accuracy: 0.7571\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7488 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7488 - val_loss: 0.5192 - val_accuracy: 0.7286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7552 - val_loss: 0.5109 - val_accuracy: 0.7571\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7552 - val_loss: 0.5138 - val_accuracy: 0.7571\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7601 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7601 - val_loss: 0.5139 - val_accuracy: 0.7571\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7601 - val_loss: 0.5198 - val_accuracy: 0.7286\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7601 - val_loss: 0.5182 - val_accuracy: 0.7143\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 4\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 12ms/step - loss: 0.6929 - accuracy: 0.5620 - val_loss: 0.6823 - val_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.6441 - val_loss: 0.6579 - val_accuracy: 0.6286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6957 - val_loss: 0.6388 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7134 - val_loss: 0.6179 - val_accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7311 - val_loss: 0.5978 - val_accuracy: 0.6857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7520 - val_loss: 0.5779 - val_accuracy: 0.6857\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7617 - val_loss: 0.5627 - val_accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7681 - val_loss: 0.5499 - val_accuracy: 0.7429\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7649 - val_loss: 0.5405 - val_accuracy: 0.7571\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7633 - val_loss: 0.5361 - val_accuracy: 0.7571\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7665 - val_loss: 0.5340 - val_accuracy: 0.7571\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7617 - val_loss: 0.5309 - val_accuracy: 0.7571\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7601 - val_loss: 0.5341 - val_accuracy: 0.7571\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7568 - val_loss: 0.5348 - val_accuracy: 0.7571\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7633 - val_loss: 0.5376 - val_accuracy: 0.7714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7649 - val_loss: 0.5422 - val_accuracy: 0.7714\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7601 - val_loss: 0.5421 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 39ms/step - loss: 0.8799 - accuracy: 0.3575 - val_loss: 0.7695 - val_accuracy: 0.4143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.3833 - val_loss: 0.7355 - val_accuracy: 0.4429\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7558 - accuracy: 0.4074 - val_loss: 0.7181 - val_accuracy: 0.4714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7204 - accuracy: 0.4396 - val_loss: 0.7003 - val_accuracy: 0.4857\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.4863 - val_loss: 0.6846 - val_accuracy: 0.5143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5282 - val_loss: 0.6701 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.5588 - val_loss: 0.6577 - val_accuracy: 0.6143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.5717 - val_loss: 0.6469 - val_accuracy: 0.6429\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6103 - val_loss: 0.6374 - val_accuracy: 0.6714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6296 - val_loss: 0.6293 - val_accuracy: 0.6429\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6554 - val_loss: 0.6203 - val_accuracy: 0.6714\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6634 - val_loss: 0.6096 - val_accuracy: 0.6714\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.6779 - val_loss: 0.6042 - val_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6924 - val_loss: 0.5967 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7118 - val_loss: 0.5911 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7246 - val_loss: 0.5908 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7424 - val_loss: 0.5845 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7456 - val_loss: 0.5819 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7504 - val_loss: 0.5765 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7552 - val_loss: 0.5727 - val_accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7601 - val_loss: 0.5718 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7633 - val_loss: 0.5672 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7633 - val_loss: 0.5648 - val_accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7633 - val_loss: 0.5643 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7617 - val_loss: 0.5628 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7681 - val_loss: 0.5611 - val_accuracy: 0.7143\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7665 - val_loss: 0.5613 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7681 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7697 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7697 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7697 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7697 - val_loss: 0.5564 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7729 - val_loss: 0.5550 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7729 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7665 - val_loss: 0.5542 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7649 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7681 - val_loss: 0.5542 - val_accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7681 - val_loss: 0.5529 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7697 - val_loss: 0.5525 - val_accuracy: 0.7286\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7681 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7649 - val_loss: 0.5553 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7681 - val_loss: 0.5544 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7729 - val_loss: 0.5518 - val_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7746 - val_loss: 0.5533 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7778 - val_loss: 0.5558 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7762 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7729 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7858 - val_loss: 0.5551 - val_accuracy: 0.7000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 36ms/step - loss: 0.7534 - accuracy: 0.4686 - val_loss: 0.6704 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.5411 - val_loss: 0.6607 - val_accuracy: 0.5571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.5894 - val_loss: 0.6544 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6377 - val_loss: 0.6393 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6844 - val_loss: 0.6268 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7101 - val_loss: 0.6157 - val_accuracy: 0.6857\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7230 - val_loss: 0.6046 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7327 - val_loss: 0.5943 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7359 - val_loss: 0.5875 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7375 - val_loss: 0.5814 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7424 - val_loss: 0.5737 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7456 - val_loss: 0.5622 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7440 - val_loss: 0.5614 - val_accuracy: 0.7286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7520 - val_loss: 0.5533 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7585 - val_loss: 0.5512 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7552 - val_loss: 0.5502 - val_accuracy: 0.7429\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7585 - val_loss: 0.5434 - val_accuracy: 0.7429\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7568 - val_loss: 0.5430 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7681 - val_loss: 0.5385 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7681 - val_loss: 0.5335 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7697 - val_loss: 0.5315 - val_accuracy: 0.7571\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7697 - val_loss: 0.5301 - val_accuracy: 0.7714\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7681 - val_loss: 0.5247 - val_accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7713 - val_loss: 0.5236 - val_accuracy: 0.7571\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7713 - val_loss: 0.5223 - val_accuracy: 0.7571\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7713 - val_loss: 0.5220 - val_accuracy: 0.7571\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7681 - val_loss: 0.5209 - val_accuracy: 0.7571\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7633 - val_loss: 0.5213 - val_accuracy: 0.7571\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7633 - val_loss: 0.5185 - val_accuracy: 0.7571\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7617 - val_loss: 0.5205 - val_accuracy: 0.7571\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7617 - val_loss: 0.5166 - val_accuracy: 0.7571\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7601 - val_loss: 0.5153 - val_accuracy: 0.7571\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7617 - val_loss: 0.5142 - val_accuracy: 0.7571\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7601 - val_loss: 0.5150 - val_accuracy: 0.7571\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7665 - val_loss: 0.5117 - val_accuracy: 0.7571\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7665 - val_loss: 0.5135 - val_accuracy: 0.7571\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7681 - val_loss: 0.5141 - val_accuracy: 0.7571\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7633 - val_loss: 0.5104 - val_accuracy: 0.7571\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7665 - val_loss: 0.5103 - val_accuracy: 0.7714\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7681 - val_loss: 0.5148 - val_accuracy: 0.7714\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7665 - val_loss: 0.5130 - val_accuracy: 0.7714\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7697 - val_loss: 0.5128 - val_accuracy: 0.7714\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7729 - val_loss: 0.5080 - val_accuracy: 0.7714\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7762 - val_loss: 0.5108 - val_accuracy: 0.7714\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7713 - val_loss: 0.5145 - val_accuracy: 0.7714\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7729 - val_loss: 0.5135 - val_accuracy: 0.7571\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7697 - val_loss: 0.5207 - val_accuracy: 0.7429\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7762 - val_loss: 0.5156 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 5\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 0.7216 - accuracy: 0.6216 - val_loss: 0.6953 - val_accuracy: 0.6143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6329 - val_loss: 0.6824 - val_accuracy: 0.6429\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6602 - val_loss: 0.6710 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6860 - val_loss: 0.6591 - val_accuracy: 0.7143\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6989 - val_loss: 0.6448 - val_accuracy: 0.6571\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7118 - val_loss: 0.6284 - val_accuracy: 0.6714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7182 - val_loss: 0.6104 - val_accuracy: 0.6857\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7134 - val_loss: 0.5958 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7182 - val_loss: 0.5839 - val_accuracy: 0.7286\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7214 - val_loss: 0.5768 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7295 - val_loss: 0.5708 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7375 - val_loss: 0.5638 - val_accuracy: 0.7286\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.5588 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7456 - val_loss: 0.5521 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7504 - val_loss: 0.5505 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7520 - val_loss: 0.5490 - val_accuracy: 0.7571\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7536 - val_loss: 0.5432 - val_accuracy: 0.7571\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7504 - val_loss: 0.5440 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7504 - val_loss: 0.5385 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7504 - val_loss: 0.5356 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7504 - val_loss: 0.5324 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7552 - val_loss: 0.5305 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7568 - val_loss: 0.5264 - val_accuracy: 0.7286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7617 - val_loss: 0.5263 - val_accuracy: 0.7286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7665 - val_loss: 0.5240 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7681 - val_loss: 0.5212 - val_accuracy: 0.7143\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7665 - val_loss: 0.5218 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7681 - val_loss: 0.5198 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7665 - val_loss: 0.5196 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7681 - val_loss: 0.5189 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7681 - val_loss: 0.5163 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.5104 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7762 - val_loss: 0.5107 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7746 - val_loss: 0.5122 - val_accuracy: 0.7000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7794 - val_loss: 0.5051 - val_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7794 - val_loss: 0.5065 - val_accuracy: 0.7000\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7729 - val_loss: 0.5063 - val_accuracy: 0.6857\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7729 - val_loss: 0.5052 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7762 - val_loss: 0.5023 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7697 - val_loss: 0.5021 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7729 - val_loss: 0.4993 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7713 - val_loss: 0.5033 - val_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7762 - val_loss: 0.4954 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7762 - val_loss: 0.4930 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7762 - val_loss: 0.4993 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7762 - val_loss: 0.4942 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7286\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7286\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7810 - val_loss: 0.4906 - val_accuracy: 0.7286\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7826 - val_loss: 0.4871 - val_accuracy: 0.7286\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7842 - val_loss: 0.4894 - val_accuracy: 0.7286\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7842 - val_loss: 0.4918 - val_accuracy: 0.7429\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7858 - val_loss: 0.4862 - val_accuracy: 0.7429\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7890 - val_loss: 0.4856 - val_accuracy: 0.7286\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7907 - val_loss: 0.4847 - val_accuracy: 0.7429\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7890 - val_loss: 0.4871 - val_accuracy: 0.7429\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7907 - val_loss: 0.4839 - val_accuracy: 0.7429\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7858 - val_loss: 0.4867 - val_accuracy: 0.7429\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7874 - val_loss: 0.4867 - val_accuracy: 0.7429\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7858 - val_loss: 0.4888 - val_accuracy: 0.7429\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7939 - val_loss: 0.4842 - val_accuracy: 0.7429\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7923 - val_loss: 0.4858 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 19ms/step - loss: 0.8814 - accuracy: 0.4654 - val_loss: 0.8970 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.5137 - val_loss: 0.8365 - val_accuracy: 0.4571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5636 - val_loss: 0.7970 - val_accuracy: 0.5143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6103 - val_loss: 0.7556 - val_accuracy: 0.5857\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6441 - val_loss: 0.7211 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6699 - val_loss: 0.6929 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6828 - val_loss: 0.6691 - val_accuracy: 0.6143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7005 - val_loss: 0.6443 - val_accuracy: 0.6714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7118 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7279 - val_loss: 0.6139 - val_accuracy: 0.7286\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7327 - val_loss: 0.6006 - val_accuracy: 0.7286\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7440 - val_loss: 0.5874 - val_accuracy: 0.7286\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7488 - val_loss: 0.5796 - val_accuracy: 0.7286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7536 - val_loss: 0.5712 - val_accuracy: 0.7286\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7601 - val_loss: 0.5698 - val_accuracy: 0.7286\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7585 - val_loss: 0.5679 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7617 - val_loss: 0.5599 - val_accuracy: 0.7286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7617 - val_loss: 0.5609 - val_accuracy: 0.7286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7681 - val_loss: 0.5546 - val_accuracy: 0.7286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7617 - val_loss: 0.5524 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7681 - val_loss: 0.5498 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7697 - val_loss: 0.5435 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7762 - val_loss: 0.5394 - val_accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7729 - val_loss: 0.5420 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7794 - val_loss: 0.5361 - val_accuracy: 0.6857\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.5322 - val_accuracy: 0.6857\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7746 - val_loss: 0.5377 - val_accuracy: 0.7000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7746 - val_loss: 0.5346 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7762 - val_loss: 0.5356 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7746 - val_loss: 0.5360 - val_accuracy: 0.7143\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7746 - val_loss: 0.5298 - val_accuracy: 0.6857\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7810 - val_loss: 0.5244 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7826 - val_loss: 0.5252 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7794 - val_loss: 0.5299 - val_accuracy: 0.6857\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7826 - val_loss: 0.5169 - val_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7826 - val_loss: 0.5221 - val_accuracy: 0.6857\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7794 - val_loss: 0.5222 - val_accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7794 - val_loss: 0.5192 - val_accuracy: 0.7000\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7826 - val_loss: 0.5112 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7890 - val_loss: 0.5169 - val_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7810 - val_loss: 0.5180 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7858 - val_loss: 0.5140 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7874 - val_loss: 0.5102 - val_accuracy: 0.7000\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7890 - val_loss: 0.5091 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7907 - val_loss: 0.5128 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7842 - val_loss: 0.5194 - val_accuracy: 0.7286\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7810 - val_loss: 0.5247 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7955 - val_loss: 0.5120 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7939 - val_loss: 0.5135 - val_accuracy: 0.7143\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 40ms/step - loss: 0.9745 - accuracy: 0.5556 - val_loss: 0.8073 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8234 - accuracy: 0.5588 - val_loss: 0.7496 - val_accuracy: 0.5429\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7348 - accuracy: 0.5733 - val_loss: 0.7189 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6071 - val_loss: 0.6941 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6361 - val_loss: 0.6684 - val_accuracy: 0.6143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6586 - val_loss: 0.6460 - val_accuracy: 0.6714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.6763 - val_loss: 0.6237 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6957 - val_loss: 0.6035 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7069 - val_loss: 0.5866 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7214 - val_loss: 0.5725 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7246 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7295 - val_loss: 0.5473 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7311 - val_loss: 0.5394 - val_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7407 - val_loss: 0.5303 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7424 - val_loss: 0.5286 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7424 - val_loss: 0.5257 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7440 - val_loss: 0.5178 - val_accuracy: 0.7286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7440 - val_loss: 0.5212 - val_accuracy: 0.7286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7472 - val_loss: 0.5108 - val_accuracy: 0.7286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7536 - val_loss: 0.5032 - val_accuracy: 0.7286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7536 - val_loss: 0.4990 - val_accuracy: 0.7286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7601 - val_loss: 0.4957 - val_accuracy: 0.7286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7585 - val_loss: 0.4966 - val_accuracy: 0.7286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7585 - val_loss: 0.4940 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7617 - val_loss: 0.4883 - val_accuracy: 0.7286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7617 - val_loss: 0.4894 - val_accuracy: 0.7286\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7649 - val_loss: 0.4871 - val_accuracy: 0.7286\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7601 - val_loss: 0.4868 - val_accuracy: 0.7286\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7617 - val_loss: 0.4914 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7617 - val_loss: 0.4850 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7665 - val_loss: 0.4763 - val_accuracy: 0.7429\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7729 - val_loss: 0.4725 - val_accuracy: 0.7571\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7697 - val_loss: 0.4800 - val_accuracy: 0.7286\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7729 - val_loss: 0.4675 - val_accuracy: 0.7571\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7794 - val_loss: 0.4720 - val_accuracy: 0.7429\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7697 - val_loss: 0.4739 - val_accuracy: 0.7429\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7681 - val_loss: 0.4713 - val_accuracy: 0.7429\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.4639 - val_accuracy: 0.7714\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7762 - val_loss: 0.4687 - val_accuracy: 0.7714\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7681 - val_loss: 0.4693 - val_accuracy: 0.7714\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7697 - val_loss: 0.4680 - val_accuracy: 0.7714\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7810 - val_loss: 0.4609 - val_accuracy: 0.7714\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7826 - val_loss: 0.4606 - val_accuracy: 0.7571\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7826 - val_loss: 0.4650 - val_accuracy: 0.7714\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7746 - val_loss: 0.4707 - val_accuracy: 0.7714\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7729 - val_loss: 0.4761 - val_accuracy: 0.7571\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7794 - val_loss: 0.4645 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7842 - val_loss: 0.4608 - val_accuracy: 0.7857\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 6\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.6881 - accuracy: 0.4461 - val_loss: 0.6997 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5427 - val_loss: 0.6741 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6135 - val_loss: 0.6518 - val_accuracy: 0.6571\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6570 - val_loss: 0.6243 - val_accuracy: 0.7571\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6763 - val_loss: 0.5981 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6908 - val_loss: 0.5725 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7118 - val_loss: 0.5480 - val_accuracy: 0.8286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7295 - val_loss: 0.5297 - val_accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7279 - val_loss: 0.5124 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7311 - val_loss: 0.4982 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7359 - val_loss: 0.4880 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7424 - val_loss: 0.4771 - val_accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7440 - val_loss: 0.4705 - val_accuracy: 0.8143\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7456 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7488 - val_loss: 0.4622 - val_accuracy: 0.7857\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7488 - val_loss: 0.4594 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7488 - val_loss: 0.4534 - val_accuracy: 0.7714\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7504 - val_loss: 0.4523 - val_accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7520 - val_loss: 0.4488 - val_accuracy: 0.7714\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7504 - val_loss: 0.4460 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7568 - val_loss: 0.4431 - val_accuracy: 0.7714\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7536 - val_loss: 0.4423 - val_accuracy: 0.7857\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7552 - val_loss: 0.4397 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7552 - val_loss: 0.4376 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7585 - val_loss: 0.4384 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7552 - val_loss: 0.4362 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7568 - val_loss: 0.4364 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7601 - val_loss: 0.4354 - val_accuracy: 0.8143\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7585 - val_loss: 0.4351 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7585 - val_loss: 0.4369 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7585 - val_loss: 0.4336 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7633 - val_loss: 0.4313 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7697 - val_loss: 0.4303 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7649 - val_loss: 0.4316 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7778 - val_loss: 0.4286 - val_accuracy: 0.8143\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.4299 - val_accuracy: 0.8143\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7762 - val_loss: 0.4275 - val_accuracy: 0.8143\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7778 - val_loss: 0.4281 - val_accuracy: 0.8143\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7746 - val_loss: 0.4281 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4283 - val_accuracy: 0.8143\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7746 - val_loss: 0.4299 - val_accuracy: 0.8143\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7746 - val_loss: 0.4292 - val_accuracy: 0.8000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 42ms/step - loss: 0.7251 - accuracy: 0.6329 - val_loss: 0.5555 - val_accuracy: 0.6714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6409 - val_loss: 0.5303 - val_accuracy: 0.6714\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6522 - val_loss: 0.5113 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.6747 - val_loss: 0.4915 - val_accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7118 - val_loss: 0.4781 - val_accuracy: 0.7857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7246 - val_loss: 0.4684 - val_accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7391 - val_loss: 0.4584 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7440 - val_loss: 0.4525 - val_accuracy: 0.8286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7456 - val_loss: 0.4446 - val_accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7440 - val_loss: 0.4377 - val_accuracy: 0.8429\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7488 - val_loss: 0.4340 - val_accuracy: 0.8429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7488 - val_loss: 0.4289 - val_accuracy: 0.8429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7520 - val_loss: 0.4215 - val_accuracy: 0.8286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7601 - val_loss: 0.4178 - val_accuracy: 0.8286\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7681 - val_loss: 0.4168 - val_accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7681 - val_loss: 0.4154 - val_accuracy: 0.8143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7697 - val_loss: 0.4081 - val_accuracy: 0.8286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7729 - val_loss: 0.4092 - val_accuracy: 0.8286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7746 - val_loss: 0.4082 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7746 - val_loss: 0.4056 - val_accuracy: 0.8286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7778 - val_loss: 0.4053 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7794 - val_loss: 0.4079 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7858 - val_loss: 0.4035 - val_accuracy: 0.8286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7858 - val_loss: 0.4049 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7907 - val_loss: 0.4089 - val_accuracy: 0.8286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7858 - val_loss: 0.4088 - val_accuracy: 0.8286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7874 - val_loss: 0.4091 - val_accuracy: 0.8286\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7858 - val_loss: 0.4105 - val_accuracy: 0.8286\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 35ms/step - loss: 0.8346 - accuracy: 0.4348 - val_loss: 0.8444 - val_accuracy: 0.4429\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7673 - accuracy: 0.4992 - val_loss: 0.7860 - val_accuracy: 0.4857\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.5556 - val_loss: 0.7392 - val_accuracy: 0.5857\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.6393 - val_loss: 0.6985 - val_accuracy: 0.6286\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6699 - val_loss: 0.6612 - val_accuracy: 0.6857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7134 - val_loss: 0.6233 - val_accuracy: 0.7429\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7279 - val_loss: 0.5807 - val_accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7327 - val_loss: 0.5431 - val_accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7391 - val_loss: 0.5064 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7424 - val_loss: 0.4818 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7440 - val_loss: 0.4618 - val_accuracy: 0.8143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7552 - val_loss: 0.4483 - val_accuracy: 0.8286\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7601 - val_loss: 0.4389 - val_accuracy: 0.8286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7617 - val_loss: 0.4310 - val_accuracy: 0.8429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7585 - val_loss: 0.4268 - val_accuracy: 0.8286\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7633 - val_loss: 0.4240 - val_accuracy: 0.8286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7649 - val_loss: 0.4186 - val_accuracy: 0.8286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7633 - val_loss: 0.4188 - val_accuracy: 0.8286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7665 - val_loss: 0.4178 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7697 - val_loss: 0.4162 - val_accuracy: 0.8286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7681 - val_loss: 0.4169 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7649 - val_loss: 0.4199 - val_accuracy: 0.8143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7729 - val_loss: 0.4191 - val_accuracy: 0.8143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7746 - val_loss: 0.4206 - val_accuracy: 0.8143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7729 - val_loss: 0.4257 - val_accuracy: 0.8143\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 7\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.7596 - accuracy: 0.3913 - val_loss: 0.6889 - val_accuracy: 0.5429\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.4686 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.5250 - val_loss: 0.6596 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5942 - val_loss: 0.6416 - val_accuracy: 0.6143\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6345 - val_loss: 0.6222 - val_accuracy: 0.6286\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6457 - val_loss: 0.6074 - val_accuracy: 0.6429\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6554 - val_loss: 0.5917 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6860 - val_loss: 0.5800 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7037 - val_loss: 0.5731 - val_accuracy: 0.6857\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7150 - val_loss: 0.5651 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7246 - val_loss: 0.5576 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7311 - val_loss: 0.5507 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7343 - val_loss: 0.5451 - val_accuracy: 0.7286\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7391 - val_loss: 0.5414 - val_accuracy: 0.7429\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7391 - val_loss: 0.5339 - val_accuracy: 0.7429\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7440 - val_loss: 0.5324 - val_accuracy: 0.7429\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7424 - val_loss: 0.5278 - val_accuracy: 0.7429\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7456 - val_loss: 0.5238 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7488 - val_loss: 0.5189 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7520 - val_loss: 0.5152 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7520 - val_loss: 0.5118 - val_accuracy: 0.7286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7504 - val_loss: 0.5087 - val_accuracy: 0.7286\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7504 - val_loss: 0.5050 - val_accuracy: 0.7286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7536 - val_loss: 0.5012 - val_accuracy: 0.7429\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7552 - val_loss: 0.4961 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7536 - val_loss: 0.4954 - val_accuracy: 0.7429\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7520 - val_loss: 0.4979 - val_accuracy: 0.7429\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7504 - val_loss: 0.4969 - val_accuracy: 0.7286\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7520 - val_loss: 0.4933 - val_accuracy: 0.7286\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7520 - val_loss: 0.4956 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7536 - val_loss: 0.4952 - val_accuracy: 0.7286\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7536 - val_loss: 0.4903 - val_accuracy: 0.7429\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7568 - val_loss: 0.4900 - val_accuracy: 0.7571\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7568 - val_loss: 0.4925 - val_accuracy: 0.7571\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7617 - val_loss: 0.4908 - val_accuracy: 0.7571\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7665 - val_loss: 0.4894 - val_accuracy: 0.7571\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7681 - val_loss: 0.4893 - val_accuracy: 0.7571\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7681 - val_loss: 0.4917 - val_accuracy: 0.7571\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7681 - val_loss: 0.4923 - val_accuracy: 0.7571\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7729 - val_loss: 0.4919 - val_accuracy: 0.7571\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7617 - val_loss: 0.4964 - val_accuracy: 0.7429\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7697 - val_loss: 0.4923 - val_accuracy: 0.7571\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 40ms/step - loss: 0.8872 - accuracy: 0.3977 - val_loss: 0.7645 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.5153 - val_loss: 0.6839 - val_accuracy: 0.5286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6490 - val_loss: 0.6295 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.7053 - val_loss: 0.5894 - val_accuracy: 0.7571\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7295 - val_loss: 0.5631 - val_accuracy: 0.7429\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7311 - val_loss: 0.5512 - val_accuracy: 0.7286\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7359 - val_loss: 0.5432 - val_accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7391 - val_loss: 0.5371 - val_accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7391 - val_loss: 0.5373 - val_accuracy: 0.7286\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7407 - val_loss: 0.5340 - val_accuracy: 0.7286\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7375 - val_loss: 0.5315 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7375 - val_loss: 0.5324 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7391 - val_loss: 0.5273 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7375 - val_loss: 0.5276 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7391 - val_loss: 0.5233 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7375 - val_loss: 0.5288 - val_accuracy: 0.7143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7375 - val_loss: 0.5255 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7407 - val_loss: 0.5252 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7440 - val_loss: 0.5231 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7504 - val_loss: 0.5197 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7520 - val_loss: 0.5200 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7504 - val_loss: 0.5197 - val_accuracy: 0.7571\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7520 - val_loss: 0.5160 - val_accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7536 - val_loss: 0.5152 - val_accuracy: 0.7714\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7568 - val_loss: 0.5113 - val_accuracy: 0.7857\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7601 - val_loss: 0.5083 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7617 - val_loss: 0.5100 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7601 - val_loss: 0.5081 - val_accuracy: 0.7714\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7633 - val_loss: 0.5058 - val_accuracy: 0.7714\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7617 - val_loss: 0.5085 - val_accuracy: 0.7714\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7649 - val_loss: 0.5041 - val_accuracy: 0.7714\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7665 - val_loss: 0.4944 - val_accuracy: 0.7714\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7697 - val_loss: 0.4980 - val_accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7713 - val_loss: 0.4979 - val_accuracy: 0.7714\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7713 - val_loss: 0.4924 - val_accuracy: 0.7714\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7746 - val_loss: 0.4904 - val_accuracy: 0.7714\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7729 - val_loss: 0.4937 - val_accuracy: 0.7714\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7713 - val_loss: 0.4943 - val_accuracy: 0.7714\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7697 - val_loss: 0.4905 - val_accuracy: 0.7714\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7729 - val_loss: 0.4888 - val_accuracy: 0.7714\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7697 - val_loss: 0.4943 - val_accuracy: 0.7571\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7714\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7810 - val_loss: 0.4871 - val_accuracy: 0.7714\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7810 - val_loss: 0.4863 - val_accuracy: 0.7714\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7794 - val_loss: 0.4888 - val_accuracy: 0.7714\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7810 - val_loss: 0.4918 - val_accuracy: 0.7571\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7890 - val_loss: 0.4975 - val_accuracy: 0.7571\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7842 - val_loss: 0.4888 - val_accuracy: 0.7714\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7874 - val_loss: 0.4881 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 3s 40ms/step - loss: 0.6359 - accuracy: 0.6103 - val_loss: 0.6252 - val_accuracy: 0.6143\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6473 - val_loss: 0.6020 - val_accuracy: 0.6429\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5668 - accuracy: 0.6490 - val_loss: 0.5894 - val_accuracy: 0.6571\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.6683 - val_loss: 0.5769 - val_accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.6763 - val_loss: 0.5672 - val_accuracy: 0.6857\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.6860 - val_loss: 0.5581 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.6989 - val_loss: 0.5503 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7166 - val_loss: 0.5426 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7182 - val_loss: 0.5386 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7198 - val_loss: 0.5342 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7182 - val_loss: 0.5289 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7262 - val_loss: 0.5233 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7311 - val_loss: 0.5201 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7327 - val_loss: 0.5166 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7359 - val_loss: 0.5096 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7424 - val_loss: 0.5134 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7440 - val_loss: 0.5091 - val_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7472 - val_loss: 0.5092 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7488 - val_loss: 0.5052 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7520 - val_loss: 0.5006 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7552 - val_loss: 0.5021 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7601 - val_loss: 0.5007 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7633 - val_loss: 0.4955 - val_accuracy: 0.7286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7649 - val_loss: 0.4957 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7681 - val_loss: 0.4936 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7681 - val_loss: 0.4903 - val_accuracy: 0.7286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7697 - val_loss: 0.4912 - val_accuracy: 0.7286\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7713 - val_loss: 0.4928 - val_accuracy: 0.7286\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7729 - val_loss: 0.4883 - val_accuracy: 0.7286\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7729 - val_loss: 0.4915 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7729 - val_loss: 0.4906 - val_accuracy: 0.7286\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7762 - val_loss: 0.4866 - val_accuracy: 0.7286\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7762 - val_loss: 0.4879 - val_accuracy: 0.7286\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7746 - val_loss: 0.4881 - val_accuracy: 0.7429\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7746 - val_loss: 0.4852 - val_accuracy: 0.7429\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7762 - val_loss: 0.4840 - val_accuracy: 0.7429\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7794 - val_loss: 0.4857 - val_accuracy: 0.7429\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7826 - val_loss: 0.4886 - val_accuracy: 0.7429\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7794 - val_loss: 0.4839 - val_accuracy: 0.7429\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7810 - val_loss: 0.4828 - val_accuracy: 0.7286\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7697 - val_loss: 0.4849 - val_accuracy: 0.7286\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7842 - val_loss: 0.4836 - val_accuracy: 0.7429\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7794 - val_loss: 0.4817 - val_accuracy: 0.7429\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7810 - val_loss: 0.4805 - val_accuracy: 0.7429\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7810 - val_loss: 0.4811 - val_accuracy: 0.7429\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7794 - val_loss: 0.4818 - val_accuracy: 0.7286\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7794 - val_loss: 0.4894 - val_accuracy: 0.7286\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7810 - val_loss: 0.4797 - val_accuracy: 0.7429\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7842 - val_loss: 0.4804 - val_accuracy: 0.7286\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7858 - val_loss: 0.4811 - val_accuracy: 0.7286\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7842 - val_loss: 0.4804 - val_accuracy: 0.7286\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7907 - val_loss: 0.4788 - val_accuracy: 0.7286\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7955 - val_loss: 0.4820 - val_accuracy: 0.7286\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7907 - val_loss: 0.4839 - val_accuracy: 0.7286\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7923 - val_loss: 0.4806 - val_accuracy: 0.7286\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7874 - val_loss: 0.4888 - val_accuracy: 0.7286\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7907 - val_loss: 0.4840 - val_accuracy: 0.7286\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 8\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 12ms/step - loss: 0.7866 - accuracy: 0.3505 - val_loss: 0.7642 - val_accuracy: 0.3571\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.3633 - val_loss: 0.7194 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.3842 - val_loss: 0.6907 - val_accuracy: 0.4714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.4260 - val_loss: 0.6703 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.4855 - val_loss: 0.6548 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5177 - val_loss: 0.6424 - val_accuracy: 0.6143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.5627 - val_loss: 0.6291 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.5965 - val_loss: 0.6172 - val_accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6318 - val_loss: 0.6009 - val_accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6704 - val_loss: 0.5839 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6945 - val_loss: 0.5635 - val_accuracy: 0.8286\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7026 - val_loss: 0.5372 - val_accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7090 - val_loss: 0.5118 - val_accuracy: 0.8143\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7251 - val_loss: 0.4884 - val_accuracy: 0.8143\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7315 - val_loss: 0.4644 - val_accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7315 - val_loss: 0.4455 - val_accuracy: 0.8143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7363 - val_loss: 0.4317 - val_accuracy: 0.8143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7315 - val_loss: 0.4181 - val_accuracy: 0.8143\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7315 - val_loss: 0.4103 - val_accuracy: 0.8143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7395 - val_loss: 0.4018 - val_accuracy: 0.8286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7444 - val_loss: 0.3976 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7460 - val_loss: 0.3938 - val_accuracy: 0.8143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7508 - val_loss: 0.3891 - val_accuracy: 0.8143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7476 - val_loss: 0.3851 - val_accuracy: 0.8143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7508 - val_loss: 0.3832 - val_accuracy: 0.8143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7556 - val_loss: 0.3811 - val_accuracy: 0.8143\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7524 - val_loss: 0.3795 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7540 - val_loss: 0.3785 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7556 - val_loss: 0.3786 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7572 - val_loss: 0.3772 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7588 - val_loss: 0.3768 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7556 - val_loss: 0.3771 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7556 - val_loss: 0.3765 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7588 - val_loss: 0.3781 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7621 - val_loss: 0.3780 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7653 - val_loss: 0.3787 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7701 - val_loss: 0.3784 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7685 - val_loss: 0.3780 - val_accuracy: 0.7714\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 38ms/step - loss: 0.7267 - accuracy: 0.4952 - val_loss: 0.6868 - val_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5643 - val_loss: 0.6358 - val_accuracy: 0.6286\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6174 - val_loss: 0.6050 - val_accuracy: 0.6571\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6479 - val_loss: 0.5791 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.6672 - val_loss: 0.5633 - val_accuracy: 0.7286\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6720 - val_loss: 0.5491 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6977 - val_loss: 0.5338 - val_accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7058 - val_loss: 0.5245 - val_accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7090 - val_loss: 0.5144 - val_accuracy: 0.7429\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7186 - val_loss: 0.5085 - val_accuracy: 0.7429\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7235 - val_loss: 0.5021 - val_accuracy: 0.7429\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7315 - val_loss: 0.4935 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7315 - val_loss: 0.4890 - val_accuracy: 0.7429\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7283 - val_loss: 0.4843 - val_accuracy: 0.7571\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7299 - val_loss: 0.4792 - val_accuracy: 0.7571\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7315 - val_loss: 0.4750 - val_accuracy: 0.7571\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7347 - val_loss: 0.4728 - val_accuracy: 0.7571\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7363 - val_loss: 0.4676 - val_accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7347 - val_loss: 0.4666 - val_accuracy: 0.7714\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7379 - val_loss: 0.4625 - val_accuracy: 0.7714\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7363 - val_loss: 0.4602 - val_accuracy: 0.7857\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7412 - val_loss: 0.4576 - val_accuracy: 0.7857\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7460 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7428 - val_loss: 0.4503 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7444 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7444 - val_loss: 0.4452 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7492 - val_loss: 0.4430 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7524 - val_loss: 0.4417 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7556 - val_loss: 0.4388 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7637 - val_loss: 0.4368 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7621 - val_loss: 0.4349 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7621 - val_loss: 0.4336 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7653 - val_loss: 0.4330 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7637 - val_loss: 0.4314 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7669 - val_loss: 0.4300 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7733 - val_loss: 0.4282 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7781 - val_loss: 0.4273 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7749 - val_loss: 0.4242 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7765 - val_loss: 0.4234 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7717 - val_loss: 0.4194 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7717 - val_loss: 0.4199 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7749 - val_loss: 0.4190 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7749 - val_loss: 0.4176 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7765 - val_loss: 0.4175 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7765 - val_loss: 0.4162 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7733 - val_loss: 0.4146 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7814 - val_loss: 0.4122 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7765 - val_loss: 0.4113 - val_accuracy: 0.7714\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7765 - val_loss: 0.4106 - val_accuracy: 0.7714\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7781 - val_loss: 0.4110 - val_accuracy: 0.7714\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7765 - val_loss: 0.4073 - val_accuracy: 0.7714\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7797 - val_loss: 0.4075 - val_accuracy: 0.7714\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7814 - val_loss: 0.4054 - val_accuracy: 0.7714\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7814 - val_loss: 0.4072 - val_accuracy: 0.7714\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7846 - val_loss: 0.4098 - val_accuracy: 0.7714\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7846 - val_loss: 0.4076 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.4086 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.4095 - val_accuracy: 0.7857\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 39ms/step - loss: 0.6377 - accuracy: 0.6656 - val_loss: 0.5498 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.7170 - val_loss: 0.5089 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7412 - val_loss: 0.4839 - val_accuracy: 0.8143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7556 - val_loss: 0.4620 - val_accuracy: 0.8286\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7540 - val_loss: 0.4480 - val_accuracy: 0.8286\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7524 - val_loss: 0.4415 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7540 - val_loss: 0.4292 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7540 - val_loss: 0.4269 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7572 - val_loss: 0.4214 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7605 - val_loss: 0.4194 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7621 - val_loss: 0.4155 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7605 - val_loss: 0.4100 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7605 - val_loss: 0.4089 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7717 - val_loss: 0.4102 - val_accuracy: 0.7714\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7717 - val_loss: 0.4047 - val_accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7765 - val_loss: 0.4053 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7653 - val_loss: 0.4083 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7717 - val_loss: 0.4023 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7701 - val_loss: 0.4039 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7701 - val_loss: 0.4030 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7669 - val_loss: 0.4044 - val_accuracy: 0.7857\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7669 - val_loss: 0.4024 - val_accuracy: 0.7714\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7749 - val_loss: 0.4021 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7669 - val_loss: 0.4022 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7653 - val_loss: 0.4013 - val_accuracy: 0.7857\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7701 - val_loss: 0.4000 - val_accuracy: 0.7714\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7637 - val_loss: 0.4024 - val_accuracy: 0.7714\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7717 - val_loss: 0.4016 - val_accuracy: 0.7714\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7669 - val_loss: 0.4035 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7653 - val_loss: 0.4039 - val_accuracy: 0.7714\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7637 - val_loss: 0.4048 - val_accuracy: 0.7857\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Iteration 9\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 10ms/step - loss: 0.6688 - accuracy: 0.5900 - val_loss: 0.6873 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6141 - val_loss: 0.6799 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6367 - val_loss: 0.6709 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6559 - val_loss: 0.6602 - val_accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6640 - val_loss: 0.6499 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6720 - val_loss: 0.6404 - val_accuracy: 0.6714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6929 - val_loss: 0.6297 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6977 - val_loss: 0.6202 - val_accuracy: 0.6714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.6994 - val_loss: 0.6094 - val_accuracy: 0.6714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7090 - val_loss: 0.6018 - val_accuracy: 0.6857\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7219 - val_loss: 0.5945 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7219 - val_loss: 0.5882 - val_accuracy: 0.6857\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7219 - val_loss: 0.5822 - val_accuracy: 0.6857\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7267 - val_loss: 0.5786 - val_accuracy: 0.6857\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7267 - val_loss: 0.5736 - val_accuracy: 0.6857\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7235 - val_loss: 0.5699 - val_accuracy: 0.6857\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7267 - val_loss: 0.5671 - val_accuracy: 0.6857\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7251 - val_loss: 0.5626 - val_accuracy: 0.6857\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7251 - val_loss: 0.5605 - val_accuracy: 0.6857\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7267 - val_loss: 0.5561 - val_accuracy: 0.6857\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7299 - val_loss: 0.5533 - val_accuracy: 0.6857\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7347 - val_loss: 0.5522 - val_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7315 - val_loss: 0.5474 - val_accuracy: 0.6714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7395 - val_loss: 0.5444 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7508 - val_loss: 0.5417 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7540 - val_loss: 0.5383 - val_accuracy: 0.7143\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7605 - val_loss: 0.5380 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7621 - val_loss: 0.5336 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7637 - val_loss: 0.5316 - val_accuracy: 0.7143\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7653 - val_loss: 0.5326 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7669 - val_loss: 0.5292 - val_accuracy: 0.7286\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7685 - val_loss: 0.5240 - val_accuracy: 0.7286\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7717 - val_loss: 0.5228 - val_accuracy: 0.7286\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7733 - val_loss: 0.5218 - val_accuracy: 0.7429\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7701 - val_loss: 0.5207 - val_accuracy: 0.7429\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7781 - val_loss: 0.5193 - val_accuracy: 0.7429\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7781 - val_loss: 0.5191 - val_accuracy: 0.7286\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7781 - val_loss: 0.5175 - val_accuracy: 0.7429\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7781 - val_loss: 0.5173 - val_accuracy: 0.7286\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7749 - val_loss: 0.5173 - val_accuracy: 0.7286\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7781 - val_loss: 0.5152 - val_accuracy: 0.7286\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7797 - val_loss: 0.5161 - val_accuracy: 0.7286\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7781 - val_loss: 0.5167 - val_accuracy: 0.7286\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7765 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7765 - val_loss: 0.5145 - val_accuracy: 0.7429\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7781 - val_loss: 0.5131 - val_accuracy: 0.7286\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7814 - val_loss: 0.5130 - val_accuracy: 0.7286\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7797 - val_loss: 0.5127 - val_accuracy: 0.7429\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7765 - val_loss: 0.5124 - val_accuracy: 0.7429\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7797 - val_loss: 0.5139 - val_accuracy: 0.7429\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7797 - val_loss: 0.5100 - val_accuracy: 0.7429\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7862 - val_loss: 0.5105 - val_accuracy: 0.7429\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7878 - val_loss: 0.5116 - val_accuracy: 0.7429\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7814 - val_loss: 0.5077 - val_accuracy: 0.7429\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7862 - val_loss: 0.5100 - val_accuracy: 0.7429\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7894 - val_loss: 0.5088 - val_accuracy: 0.7429\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7894 - val_loss: 0.5095 - val_accuracy: 0.7429\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7926 - val_loss: 0.5070 - val_accuracy: 0.7429\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7894 - val_loss: 0.5081 - val_accuracy: 0.7429\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7926 - val_loss: 0.5068 - val_accuracy: 0.7429\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7942 - val_loss: 0.5070 - val_accuracy: 0.7571\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7894 - val_loss: 0.5072 - val_accuracy: 0.7571\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7910 - val_loss: 0.5073 - val_accuracy: 0.7571\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7942 - val_loss: 0.5077 - val_accuracy: 0.7571\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7958 - val_loss: 0.5052 - val_accuracy: 0.7429\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7958 - val_loss: 0.5077 - val_accuracy: 0.7571\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7990 - val_loss: 0.5076 - val_accuracy: 0.7429\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7974 - val_loss: 0.5060 - val_accuracy: 0.7429\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7990 - val_loss: 0.5083 - val_accuracy: 0.7429\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7990 - val_loss: 0.5073 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 39ms/step - loss: 0.7240 - accuracy: 0.6399 - val_loss: 0.6496 - val_accuracy: 0.6571\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6640 - val_loss: 0.6406 - val_accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6527 - val_loss: 0.6319 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6736 - val_loss: 0.6181 - val_accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.6817 - val_loss: 0.6063 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.6945 - val_loss: 0.5964 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7026 - val_loss: 0.5857 - val_accuracy: 0.6857\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7186 - val_loss: 0.5768 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7251 - val_loss: 0.5684 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7331 - val_loss: 0.5622 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7428 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7428 - val_loss: 0.5521 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7508 - val_loss: 0.5470 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7395 - val_loss: 0.5434 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7492 - val_loss: 0.5376 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7653 - val_loss: 0.5347 - val_accuracy: 0.7143\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7653 - val_loss: 0.5342 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7685 - val_loss: 0.5301 - val_accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7717 - val_loss: 0.5285 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7781 - val_loss: 0.5252 - val_accuracy: 0.7286\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7797 - val_loss: 0.5236 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7781 - val_loss: 0.5242 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7910 - val_loss: 0.5185 - val_accuracy: 0.7286\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7958 - val_loss: 0.5187 - val_accuracy: 0.7286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7974 - val_loss: 0.5170 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.8006 - val_loss: 0.5177 - val_accuracy: 0.7286\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7942 - val_loss: 0.5184 - val_accuracy: 0.7429\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7974 - val_loss: 0.5151 - val_accuracy: 0.7429\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7958 - val_loss: 0.5164 - val_accuracy: 0.7429\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7990 - val_loss: 0.5184 - val_accuracy: 0.7429\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7974 - val_loss: 0.5200 - val_accuracy: 0.7429\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8039 - val_loss: 0.5158 - val_accuracy: 0.7286\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7974 - val_loss: 0.5172 - val_accuracy: 0.7429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 39ms/step - loss: 0.8782 - accuracy: 0.6093 - val_loss: 0.6537 - val_accuracy: 0.5857\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.5932 - val_loss: 0.6293 - val_accuracy: 0.6143\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5981 - val_loss: 0.6234 - val_accuracy: 0.6286\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6286 - val_loss: 0.6178 - val_accuracy: 0.6286\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6527 - val_loss: 0.6104 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6849 - val_loss: 0.6039 - val_accuracy: 0.6571\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.6865 - val_loss: 0.5951 - val_accuracy: 0.6429\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6961 - val_loss: 0.5884 - val_accuracy: 0.6714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.6977 - val_loss: 0.5811 - val_accuracy: 0.6857\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7058 - val_loss: 0.5749 - val_accuracy: 0.6857\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7106 - val_loss: 0.5704 - val_accuracy: 0.6857\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7203 - val_loss: 0.5674 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7283 - val_loss: 0.5633 - val_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7347 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7428 - val_loss: 0.5572 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7444 - val_loss: 0.5540 - val_accuracy: 0.7286\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7412 - val_loss: 0.5544 - val_accuracy: 0.7286\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7395 - val_loss: 0.5503 - val_accuracy: 0.7286\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7492 - val_loss: 0.5492 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7508 - val_loss: 0.5474 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7508 - val_loss: 0.5456 - val_accuracy: 0.7429\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7508 - val_loss: 0.5479 - val_accuracy: 0.7429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7605 - val_loss: 0.5431 - val_accuracy: 0.7429\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7588 - val_loss: 0.5427 - val_accuracy: 0.7429\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7637 - val_loss: 0.5421 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7653 - val_loss: 0.5416 - val_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7621 - val_loss: 0.5436 - val_accuracy: 0.7000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7685 - val_loss: 0.5405 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7701 - val_loss: 0.5406 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7685 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7717 - val_loss: 0.5432 - val_accuracy: 0.7143\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7733 - val_loss: 0.5408 - val_accuracy: 0.7143\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7749 - val_loss: 0.5420 - val_accuracy: 0.7286\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "\n",
    "model_names = [\"kb_rules\", \"uneducated\", \"educated_train\", \"educated\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}\n",
    "\n",
    "# perform nested cross-validation\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(\"Iteration\",i)\n",
    "    train, test = dataset.iloc[train_idx,:], dataset.iloc[test_idx,:]\n",
    "    X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "    y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "    \n",
    "    # validation for early stopping\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n",
    "    \n",
    "    # val_split = 0.1\n",
    "    # num_val = int(len(X_train) * val_split)\n",
    "    # X_train, X_val = X_train[:-num_val], X_train[-num_val:]\n",
    "    # y_train, y_val = y_train[:-num_val], y_train[-num_val:]\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    cw = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    weights = {0:cw[0], 1:cw[1]}\n",
    "    # inject knowledge\n",
    "    theory = Theory(knowledge, train)\n",
    "    uneducated = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "\n",
    "    # train and score uneducated\n",
    "    model_name = \"uneducated\"\n",
    "    uneducated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "    history_uneducated = uneducated.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                        validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    #_, acc = uneducated.evaluate(X_test, y_test) #print(f'test set accuracy of the uneducated predictor: {acc*100:.2f}%')\n",
    "    y_pred = uneducated.predict(X_test).flatten().round().astype(\"int\")\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "\n",
    "    #train and score educated (trainable weights)\n",
    "    model_name = \"educated_train\"\n",
    "    injector = Injector.kins(uneducated)\n",
    "    educated = injector.inject(theory)\n",
    "    theory.set_all_formulae_trainable()\n",
    "    educated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "    history_educated = educated.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                        validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    #_, acc = educated.evaluate(X_test, y_test) #print(f'test set accuracy of the educated predictor: {acc*100:.2f}%')\n",
    "    y_pred = educated.predict(X_test).flatten().round().astype(\"int\")\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "\n",
    "    # train and score educated (static weights)\n",
    "    model_name = \"educated\"\n",
    "    injector = Injector.kins(uneducated)\n",
    "    educated = injector.inject(theory)\n",
    "    theory.set_all_formulae_static()\n",
    "    educated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "    history_educated = educated.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                        validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    #_, acc = educated.evaluate(X_test, y_test) #print(f'test set accuracy of the educated predictor: {acc*100:.2f}%')\n",
    "    y_pred = educated.predict(X_test).flatten().round().astype(\"int\")\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "\n",
    "    model_name = \"kb_rules\"\n",
    "    y_pred = np.array(dataset_rules.iloc[test_idx][\"Rules\"].fillna(0))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "51d1f382-5e48-4677-820c-029bcce2a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "test_indices = np.concatenate([test_idx for _, test_idx in outer_cv.split(X, y)])\n",
    "res_df = pd.DataFrame(all_pred, index = test_indices).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7a7094e0-30b9-44c6-bf1b-4ec8bd354f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset and results\n",
    "#dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "#df = pd.read_csv(f\"goodit_{exp}_results.csv\", index_col = 0)\n",
    "#res_df = pd.read_csv(f\"goodit_{exp}_predictions.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7fb52303-8af1-4f31-865b-1b63dfa9e215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>educated</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uneducated</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_train</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric          accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                          \n",
       "educated           0.759              0.765  0.694  0.513      0.628   0.783   \n",
       "uneducated         0.752              0.751  0.679  0.493      0.634   0.746   \n",
       "educated_train     0.733              0.732  0.654  0.450      0.599   0.728   \n",
       "kb_rules           0.764              0.719  0.626  0.466      0.707   0.567   \n",
       "\n",
       "metric          relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                           \n",
       "educated                    0.961            0.955    0.486    0.273    0.076   \n",
       "uneducated                  0.954            0.937    0.492    0.260    0.089   \n",
       "educated_train              0.945            0.927    0.479    0.254    0.095   \n",
       "kb_rules                    1.000            1.000    0.566    0.198    0.151   \n",
       "\n",
       "metric          fp_rate  \n",
       "model                    \n",
       "educated          0.165  \n",
       "uneducated        0.159  \n",
       "educated_train    0.172  \n",
       "kb_rules          0.085  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(\n",
    "                                                                by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5391dc-5e59-4c91-9c19-6139d9b7b03e",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "07cc91e2-400a-4ba0-93c8-53751325bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"inj_dt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "4c55b657-4100-4303-aeff-052a0b92bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data according to domain rules\n",
    "def split_data_rules(data):\n",
    "  subset1 = data[(data[\"Glucose\"]<=100) & (data[\"BMI\"]<=25)]\n",
    "  subset2 = data[((data[\"Glucose\"]<=100) & (data[\"BMI\"]> 25)) | ((data[\"Glucose\"]> 100) & (data[\"Glucose\"]<126)) | (data[\"Glucose\"]>=126) & (data[\"BMI\"]< 30)]\n",
    "  subset3 = data[(data[\"Glucose\"]>=126) & (data[\"BMI\"]>=30)]\n",
    "  return subset1, subset2, subset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "359b0297-a475-4f9e-8822-3d5daf21159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_params = {'max_depth': range(2,20,1),\n",
    "#             'min_samples_split': range(1,20,1),\n",
    "#             'min_samples_leaf': range(2,10,1),\n",
    "#             'class_weight': [\"balanced\"]}\n",
    "\n",
    "# set splits (10x10 repeated stratified CV)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "model_names = [\"kb\", \"dt\", \"dt_kb\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                  'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    train, test = dataset.iloc[train_idx,:], dataset.iloc[test_idx,:]\n",
    "    X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "    y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "\n",
    "    depth = 10\n",
    "    # train ML model\n",
    "    model_name = \"dt\"\n",
    "    clf = DecisionTreeClassifier(random_state=123, max_depth = depth, min_samples_leaf = 10, min_samples_split = 5,\n",
    "                                 class_weight =\"balanced\").fit(X_train, y_train)\n",
    "    #clf = GridSearchCV(estimator=DecisionTreeClassifier(random_state=123), param_grid=dt_params, scoring=\"accuracy\", \n",
    "    #                   cv=inner_cv, n_jobs=-1).fit(X_train, y_train, sample_weight=sample_weights)  \n",
    "    y_pred = clf.predict(X_test)\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred)) \n",
    "    \n",
    "    # train KB-ML model\n",
    "    model_name = \"dt_kb\"\n",
    "    subset1, subset2, subset3 = split_data_rules(train)\n",
    "\n",
    "    # first 4 splits are the conditions of the rules\n",
    "    clf2 = DecisionTreeClassifier(random_state=123, max_depth = depth-4, min_samples_split = 5, class_weight =\"balanced\").fit(subset2.values[:,:8], subset2.values[:,8])\n",
    "    clf3 = DecisionTreeClassifier(random_state=123, max_depth = depth-4, min_samples_split = 5, class_weight =\"balanced\").fit(subset3.values[:,:8], subset3.values[:,8])\n",
    "    # predict\n",
    "    subtest1, subtest2, subtest3 = split_data_rules(test)\n",
    "    test[\"Pred\"] = 0\n",
    "    test.loc[subtest2.index, \"Pred\"] = clf2.predict(subtest2.values[:,:8])\n",
    "    test.loc[subtest3.index, \"Pred\"] = clf3.predict(subtest3.values[:,:8])\n",
    "    # save results\n",
    "    y_pred = test[\"Pred\"].values\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))  \n",
    "\n",
    "    # rules\n",
    "    model_name = \"kb\"\n",
    "    y_pred = np.array(dataset_rules.iloc[test_idx][\"Rules\"].fillna(0))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "db03c32d-c39c-412f-a203-de64deadff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "test_indices = np.concatenate([test_idx for _, test_idx in outer_cv.split(X, y)])\n",
    "res_df = pd.DataFrame(all_pred, index = test_indices).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "94f5adf8-b339-4ceb-a5c9-6e9a5531e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset and results\n",
    "#dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "#df = pd.read_csv(f\"goodit_{exp}_results.csv\", index_col = 0)\n",
    "#res_df = pd.read_csv(f\"goodit_{exp}_predictions.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "fc65bb5e-fd3e-4efa-b896-7e5437c55e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt_kb</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                  \n",
       "dt_kb      0.676              0.686  0.607  0.360      0.527   0.723   \n",
       "dt         0.721              0.719  0.638  0.424      0.582   0.711   \n",
       "kb         0.764              0.719  0.626  0.466      0.707   0.567   \n",
       "\n",
       "metric  relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  fp_rate  \n",
       "model                                                                           \n",
       "dt_kb               0.786            0.714    0.423    0.252    0.096    0.228  \n",
       "dt                  0.925            0.901    0.473    0.249    0.100    0.179  \n",
       "kb                  1.000            1.000    0.566    0.198    0.151    0.085  "
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(\n",
    "                                                                by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9642e4-9f98-4559-a6d3-16865a4dc676",
   "metadata": {},
   "source": [
    "## KNOWLEDGE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c295d-bd4f-48cd-b727-ede0a55bb211",
   "metadata": {},
   "source": [
    "### NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "29f1d49c-e61e-4a27-8aba-ba83047db5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"ext_nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "46584065-5241-4757-9e29-3b9eee0c193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "3badc883-a489-4fe8-b030-f63e0cce186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "\n",
    "model_names = [\"ml\", \"kb_rules\", \"ml_rules\", \"kbml_rules\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c787b-ee86-4007-bac3-e72b081a4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform nested cross-validation\n",
    "ml_theories = []\n",
    "all_ml_scores = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(\"Iteration\",i)\n",
    "    train, test = dataset.iloc[train_idx,:], dataset.iloc[test_idx,:]\n",
    "    X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "    y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "    \n",
    "    # validation for early stopping\n",
    "    train, val, X_train, X_val, y_train, y_val = train_test_split(train, X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n",
    "    \n",
    "    # val_split = 0.1\n",
    "    # num_val = int(len(X_train) * val_split)\n",
    "    # X_train, X_val = X_train[:-num_val], X_train[-num_val:]\n",
    "    # y_train, y_val = y_train[:-num_val], y_train[-num_val:]\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    normalization = {key: (m, s) for key, m, s in zip(dataset.columns, scaler.mean_, scaler.scale_)}\n",
    "    \n",
    "    cw = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    weights = {0:cw[0], 1:cw[1]}\n",
    "    # inject knowledge\n",
    "    theory = Theory(knowledge, train)\n",
    "    predictor = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "\n",
    "    # train and score uneducated\n",
    "    model_name = \"ml\"\n",
    "    predictor.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "    history_predictor = predictor.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                        validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    #_, acc = predictor.evaluate(X_test, y_test) #print(f'test set accuracy of the uneducated predictor: {acc*100:.2f}%')\n",
    "    y_pred = predictor.predict(X_test).flatten().round().astype(\"int\")\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "    \n",
    "    # prepare data (for explaining)\n",
    "    train.loc[:,dataset.columns[:-1]] = X_train\n",
    "    #\n",
    "    val.loc[:,dataset.columns[:-1]]= X_val\n",
    "    val[\"Outcome\"].replace({0: 'healthy', 1: 'diabetes'}, inplace = True)\n",
    "    #\n",
    "    test.loc[:,dataset.columns[:-1]] = X_test\n",
    "    test[\"Outcome\"].replace({0: 'healthy', 1: 'diabetes'}, inplace = True)\n",
    "    \n",
    "    predictor = PredictorWrapper(predictor)\n",
    "    # default\n",
    "    dd = 0\n",
    "    best_abb = -1\n",
    "    \n",
    "    # find \n",
    "    for depth in range(5,21):\n",
    "        explainer = Extractor.cart(predictor, max_depth=depth, max_leaves=depth, simplify=False, normalization=normalization)\n",
    "        theory = explainer.extract(train)    \n",
    "        scores, completeness = get_scores(explainer, val, predictor)\n",
    "        abb = list(scores.values())[0][1]\n",
    "        print_scores(scores)\n",
    "        if abb > best_abb:\n",
    "            dd = depth\n",
    "            best_abb = abb\n",
    "\n",
    "    depth = dd\n",
    "    print(\"\\nDepth\",depth)\n",
    "    explainer = Extractor.cart(predictor, max_depth=depth, max_leaves=depth, simplify=False, normalization=normalization)\n",
    "    theory = explainer.extract(train)  \n",
    "    ml_rules_str = pretty_theory(theory)\n",
    "    ml_theories.append(pretty_theory(theory)) \n",
    "    scores, completeness = get_scores(explainer, test, predictor)\n",
    "    ml_scores = [value for sublist in scores.values() for value in sublist]\n",
    "    all_ml_scores.append(ml_scores)\n",
    "    print(f'\\nPerformance ({explainer.n_rules} rules with {completeness * 100:.2f}% coverage):')\n",
    "    print_scores(scores)\n",
    "    print('\\nExtracted rules:\\n\\n' + pretty_theory(theory) + \"\\n\\n\")\n",
    "\n",
    "    #parse rules\n",
    "    ml_rules = parse_rules(pretty_theory(theory))\n",
    "    model_name = \"ml_rules\"\n",
    "    y_pred = np.array(dataset.iloc[test_idx].apply(lambda row: get_outcome(row, ml_rules), axis=1).replace({'diabetes': 1, 'healthy': 0}))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "    #\n",
    "    model_name = \"kbml_rules\"\n",
    "    y_pred = np.array(dataset.iloc[test_idx].apply(lambda row: get_outcome(row, get_kb_rules() + ml_rules), axis=1).replace({'diabetes': 1, 'healthy': 0}))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "    #\n",
    "    model_name = \"kb_rules\"\n",
    "    y_pred = np.array(dataset_rules.iloc[test_idx][\"Rules\"].fillna(0))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468f507-92f2-4f29-8fbe-7553f6954a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "test_indices = np.concatenate([test_idx for _, test_idx in outer_cv.split(X, y)])\n",
    "res_df = pd.DataFrame(all_pred, index = test_indices).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7914cc05-04de-4421-a682-f3c01d6606b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import dataset and results\n",
    "# dataset = pd.read_csv(\"pima_indians_imputed.csv\", index_col = 0)\n",
    "# df = pd.read_csv(f\"goodit_{exp}_results.csv\", index_col = 0)\n",
    "# res_df = pd.read_csv(f\"goodit_{exp}_predictions.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b9b331bf-84fe-4bad-8197-22c2aaa9d89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ml</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbml_rules</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_rules</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric      accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                      \n",
       "ml             0.741              0.749  0.678  0.483      0.609   0.776   \n",
       "kbml_rules     0.725              0.731  0.654  0.449      0.589   0.750   \n",
       "ml_rules       0.722              0.723  0.643  0.435      0.588   0.724   \n",
       "kb_rules       0.764              0.719  0.626  0.466      0.707   0.567   \n",
       "\n",
       "metric      relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                       \n",
       "ml                      0.965            0.959    0.470    0.271    0.078   \n",
       "kbml_rules              1.000            1.000    0.463    0.262    0.087   \n",
       "ml_rules                0.964            0.950    0.470    0.253    0.096   \n",
       "kb_rules                1.000            1.000    0.566    0.198    0.151   \n",
       "\n",
       "metric      fp_rate  \n",
       "model                \n",
       "ml            0.181  \n",
       "kbml_rules    0.188  \n",
       "ml_rules      0.181  \n",
       "kb_rules      0.085  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(\n",
    "                                                                by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff228485-5630-46ff-a0a3-abec066b978a",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "9c24a429-a1ec-48a4-a9ce-7cdeac1990f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"ext_dt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "7f5759d0-1b08-4776-94fb-be0b2758bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set splits (10x10 repeated stratified CV)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "model_names = [\"kb\", \"dt\", \"dt_kb\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                  'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    train, test = dataset.iloc[train_idx,:], dataset.iloc[test_idx,:]\n",
    "    X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "    y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "\n",
    "    depth = 10\n",
    "    # train ML model\n",
    "    model_name = \"dt\"\n",
    "    clf = DecisionTreeClassifier(random_state=123, max_depth = depth, min_samples_leaf = 10, min_samples_split = 5,\n",
    "                                 class_weight =\"balanced\").fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred)) \n",
    "    \n",
    "    model_name = \"dt_kb\"\n",
    "    y_pred = np.where(~np.isnan(y_rule), y_rule, y_pred)\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))\n",
    "    \n",
    "    model_name = \"kb\"\n",
    "    y_pred = np.array(dataset_rules.iloc[test_idx][\"Rules\"].fillna(0))\n",
    "    results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "    all_pred[model_name].extend(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "b2190c37-507e-41e5-a611-476388972a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "test_indices = np.concatenate([test_idx for _, test_idx in outer_cv.split(X, y)])\n",
    "res_df = pd.DataFrame(all_pred, index = test_indices).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "44ef4e2c-e1f1-4dd4-b51c-8feb92c7facf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt_kb</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.768</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                  \n",
       "dt_kb      0.726              0.736  0.661  0.454      0.583   0.768   \n",
       "dt         0.721              0.719  0.638  0.424      0.582   0.711   \n",
       "kb         0.764              0.719  0.626  0.466      0.707   0.567   \n",
       "\n",
       "metric  relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  fp_rate  \n",
       "model                                                                           \n",
       "dt_kb               1.000            1.000    0.458    0.268    0.081    0.193  \n",
       "dt                  0.925            0.901    0.473    0.249    0.100    0.179  \n",
       "kb                  1.000            1.000    0.566    0.198    0.151    0.085  "
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(\n",
    "                                                                by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10fe03-5770-48e7-8bd5-e28b3be16a5e",
   "metadata": {},
   "source": [
    "## KNOWLEDGE INJECTION - EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df2534-c476-4e8a-a67f-2628e3783298",
   "metadata": {},
   "source": [
    "### NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a74a33b-4c6f-4058-a1d9-22052d4869cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"inj_ext_nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51f94042-2933-4e7a-935d-f840c75fc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ae1fab5-189d-480b-9044-7304f458b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6bd4c36-6695-4286-9b2c-d01fb92d8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"kb_rules\", \"uneducated\", \"educated\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}\n",
    "all_all_pred = {model: [] for model in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44f24165-a1dc-4765-bb96-e97669377f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 13:20:27.020450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-29 13:20:27.020467: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-29 13:20:27.020483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (christelsirocchi-ThinkPad-T470p): /proc/driver/nvidia/version does not exist\n",
      "2024-05-29 13:20:27.020629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 1s - loss: 0.7363 - accuracy: 0.6232 - val_loss: 0.6904 - val_accuracy: 0.5854 - 905ms/epoch - 57ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.7010 - accuracy: 0.5927 - val_loss: 0.6653 - val_accuracy: 0.6016 - 48ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6754 - accuracy: 0.6232 - val_loss: 0.6465 - val_accuracy: 0.6016 - 52ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6571 - accuracy: 0.6640 - val_loss: 0.6277 - val_accuracy: 0.6504 - 48ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6393 - accuracy: 0.6864 - val_loss: 0.6069 - val_accuracy: 0.6748 - 50ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.6228 - accuracy: 0.6965 - val_loss: 0.5911 - val_accuracy: 0.6667 - 48ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.6076 - accuracy: 0.6986 - val_loss: 0.5740 - val_accuracy: 0.6829 - 47ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5931 - accuracy: 0.7251 - val_loss: 0.5575 - val_accuracy: 0.6992 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5797 - accuracy: 0.7352 - val_loss: 0.5427 - val_accuracy: 0.7154 - 53ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5678 - accuracy: 0.7352 - val_loss: 0.5285 - val_accuracy: 0.7236 - 53ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5569 - accuracy: 0.7373 - val_loss: 0.5147 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5471 - accuracy: 0.7352 - val_loss: 0.5080 - val_accuracy: 0.7317 - 50ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5381 - accuracy: 0.7352 - val_loss: 0.5015 - val_accuracy: 0.7154 - 48ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5295 - accuracy: 0.7332 - val_loss: 0.4932 - val_accuracy: 0.7154 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5224 - accuracy: 0.7393 - val_loss: 0.4873 - val_accuracy: 0.7154 - 44ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.5152 - accuracy: 0.7393 - val_loss: 0.4806 - val_accuracy: 0.7317 - 53ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.5090 - accuracy: 0.7475 - val_loss: 0.4758 - val_accuracy: 0.7480 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.5041 - accuracy: 0.7536 - val_loss: 0.4708 - val_accuracy: 0.7480 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4989 - accuracy: 0.7556 - val_loss: 0.4702 - val_accuracy: 0.7480 - 52ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4946 - accuracy: 0.7617 - val_loss: 0.4667 - val_accuracy: 0.7480 - 50ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4913 - accuracy: 0.7617 - val_loss: 0.4659 - val_accuracy: 0.7480 - 49ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4879 - accuracy: 0.7678 - val_loss: 0.4633 - val_accuracy: 0.7480 - 49ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4852 - accuracy: 0.7678 - val_loss: 0.4612 - val_accuracy: 0.7480 - 51ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4824 - accuracy: 0.7637 - val_loss: 0.4593 - val_accuracy: 0.7480 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4804 - accuracy: 0.7637 - val_loss: 0.4577 - val_accuracy: 0.7480 - 50ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4774 - accuracy: 0.7678 - val_loss: 0.4581 - val_accuracy: 0.7480 - 49ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4748 - accuracy: 0.7617 - val_loss: 0.4575 - val_accuracy: 0.7480 - 55ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4728 - accuracy: 0.7617 - val_loss: 0.4572 - val_accuracy: 0.7480 - 48ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4703 - accuracy: 0.7678 - val_loss: 0.4555 - val_accuracy: 0.7561 - 51ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4687 - accuracy: 0.7637 - val_loss: 0.4564 - val_accuracy: 0.7480 - 55ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4667 - accuracy: 0.7699 - val_loss: 0.4531 - val_accuracy: 0.7398 - 51ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4648 - accuracy: 0.7658 - val_loss: 0.4569 - val_accuracy: 0.7398 - 48ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4624 - accuracy: 0.7678 - val_loss: 0.4548 - val_accuracy: 0.7398 - 48ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4613 - accuracy: 0.7739 - val_loss: 0.4517 - val_accuracy: 0.7480 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4586 - accuracy: 0.7719 - val_loss: 0.4513 - val_accuracy: 0.7480 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4571 - accuracy: 0.7780 - val_loss: 0.4553 - val_accuracy: 0.7398 - 47ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.4547 - accuracy: 0.7739 - val_loss: 0.4545 - val_accuracy: 0.7480 - 52ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.4532 - accuracy: 0.7780 - val_loss: 0.4531 - val_accuracy: 0.7480 - 57ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 0.4517 - accuracy: 0.7821 - val_loss: 0.4535 - val_accuracy: 0.7480 - 50ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 0.4499 - accuracy: 0.7821 - val_loss: 0.4508 - val_accuracy: 0.7561 - 50ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 0.4485 - accuracy: 0.7821 - val_loss: 0.4502 - val_accuracy: 0.7561 - 50ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 0.4465 - accuracy: 0.7821 - val_loss: 0.4511 - val_accuracy: 0.7561 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 0.4457 - accuracy: 0.7841 - val_loss: 0.4544 - val_accuracy: 0.7561 - 49ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 0.4437 - accuracy: 0.7862 - val_loss: 0.4544 - val_accuracy: 0.7561 - 54ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.4555 - val_accuracy: 0.7561 - 51ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 0.4409 - accuracy: 0.7862 - val_loss: 0.4554 - val_accuracy: 0.7561 - 61ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "16/16 - 1s - loss: 0.7392 - accuracy: 0.4705 - val_loss: 0.7869 - val_accuracy: 0.4309 - 1s/epoch - 69ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.6958 - accuracy: 0.5316 - val_loss: 0.7251 - val_accuracy: 0.5122 - 59ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6610 - accuracy: 0.5927 - val_loss: 0.6756 - val_accuracy: 0.5610 - 57ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6348 - accuracy: 0.6334 - val_loss: 0.6383 - val_accuracy: 0.6260 - 55ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6147 - accuracy: 0.6456 - val_loss: 0.6067 - val_accuracy: 0.6585 - 53ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.5981 - accuracy: 0.6701 - val_loss: 0.5870 - val_accuracy: 0.6911 - 56ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.5857 - accuracy: 0.6782 - val_loss: 0.5728 - val_accuracy: 0.6911 - 52ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5756 - accuracy: 0.6925 - val_loss: 0.5576 - val_accuracy: 0.6911 - 51ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5668 - accuracy: 0.6965 - val_loss: 0.5494 - val_accuracy: 0.6992 - 51ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5587 - accuracy: 0.7026 - val_loss: 0.5401 - val_accuracy: 0.6992 - 52ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5524 - accuracy: 0.7088 - val_loss: 0.5311 - val_accuracy: 0.7154 - 53ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5467 - accuracy: 0.7210 - val_loss: 0.5285 - val_accuracy: 0.7236 - 53ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5406 - accuracy: 0.7271 - val_loss: 0.5247 - val_accuracy: 0.7236 - 52ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5348 - accuracy: 0.7393 - val_loss: 0.5177 - val_accuracy: 0.7236 - 52ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5303 - accuracy: 0.7373 - val_loss: 0.5145 - val_accuracy: 0.7480 - 53ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.5255 - accuracy: 0.7413 - val_loss: 0.5086 - val_accuracy: 0.7480 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.5217 - accuracy: 0.7393 - val_loss: 0.5064 - val_accuracy: 0.7480 - 54ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.5177 - accuracy: 0.7413 - val_loss: 0.5038 - val_accuracy: 0.7480 - 56ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.5141 - accuracy: 0.7454 - val_loss: 0.5033 - val_accuracy: 0.7480 - 53ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.5111 - accuracy: 0.7434 - val_loss: 0.4999 - val_accuracy: 0.7398 - 70ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.5083 - accuracy: 0.7434 - val_loss: 0.5027 - val_accuracy: 0.7561 - 52ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.5056 - accuracy: 0.7413 - val_loss: 0.4995 - val_accuracy: 0.7398 - 56ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.5030 - accuracy: 0.7434 - val_loss: 0.4989 - val_accuracy: 0.7398 - 57ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.5004 - accuracy: 0.7495 - val_loss: 0.4964 - val_accuracy: 0.7398 - 55ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4983 - accuracy: 0.7515 - val_loss: 0.4951 - val_accuracy: 0.7398 - 55ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4949 - accuracy: 0.7576 - val_loss: 0.4964 - val_accuracy: 0.7480 - 51ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4925 - accuracy: 0.7536 - val_loss: 0.4956 - val_accuracy: 0.7480 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4901 - accuracy: 0.7536 - val_loss: 0.4917 - val_accuracy: 0.7398 - 61ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4878 - accuracy: 0.7597 - val_loss: 0.4907 - val_accuracy: 0.7398 - 53ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4863 - accuracy: 0.7678 - val_loss: 0.4934 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4839 - accuracy: 0.7637 - val_loss: 0.4868 - val_accuracy: 0.7317 - 56ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4819 - accuracy: 0.7678 - val_loss: 0.4931 - val_accuracy: 0.7480 - 55ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4803 - accuracy: 0.7699 - val_loss: 0.4908 - val_accuracy: 0.7398 - 52ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4788 - accuracy: 0.7719 - val_loss: 0.4890 - val_accuracy: 0.7317 - 51ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4769 - accuracy: 0.7719 - val_loss: 0.4868 - val_accuracy: 0.7317 - 49ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4751 - accuracy: 0.7658 - val_loss: 0.4902 - val_accuracy: 0.7317 - 55ms/epoch - 3ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.70 (data), 0.85 (BB)\n",
      "F1 = 0.71 (data), 0.85 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.70 (data), 0.85 (BB)\n",
      "F1 = 0.71 (data), 0.85 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.71 (data), 0.86 (BB)\n",
      "F1 = 0.71 (data), 0.86 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.83 (BB)\n",
      "F1 = 0.68 (data), 0.83 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.83 (BB)\n",
      "F1 = 0.68 (data), 0.83 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Classification accuracy = 0.66 (data), 0.81 (BB)\n",
      "F1 = 0.67 (data), 0.81 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.66 (data), 0.81 (BB)\n",
      "F1 = 0.67 (data), 0.81 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.67 (data), 0.82 (BB)\n",
      "F1 = 0.67 (data), 0.82 (BB)\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Classification accuracy = 0.69 (data), 0.85 (BB)\n",
      "F1 = 0.70 (data), 0.85 (BB)\n",
      "\n",
      "Depth 7\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "\n",
      "Extracted rules:\n",
      "\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose =< 121.5, BMI > 40.75.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose > 121.5, BMI > 29.1.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose > 121.5, BMI =< 29.1, Age =< 30.5.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose > 121.5, BMI =< 29.1, Age > 30.5.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction =< 0.65.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age =< 4E+1.0.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age > 4E+1.0.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes.pl\")\n",
    "theory = Theory(knowledge, dataset)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_names = [\"kb_rules\", \"uneducated\", \"educated\"]\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'balanced_accuracy', 'mcc', 'tn_rate', 'fp_rate', 'fn_rate', 'tp_rate']\n",
    "results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_results = {model: {**{metric: [] for metric in scorers}, \n",
    "                   'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                   'relative_accuracy': [], 'relative_recall': []} for model in model_names}\n",
    "all_pred = {model: [] for model in model_names}\n",
    "all_all_pred = {model: [] for model in model_names}\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, train, test = train_test_split(X, y, dataset, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val, train, val = train_test_split(X_train, y_train, train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "train_idx, val_idx, test_idx = train.index, val.index, test.index\n",
    "all_idx = np.array(list(train_idx) + list(val_idx) + list(test_idx))\n",
    "y_rule = dataset_rules.loc[test_idx,\"Rules\"].values\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X = np.vstack([X_train,X_val,X_test])\n",
    "y = np.concatenate([y_train,y_val,y_test])\n",
    "all_rule = np.array(dataset_rules.iloc[all_idx][\"Rules\"].fillna(0))\n",
    "normalization = {key: (m, s) for key, m, s in zip(dataset.columns, scaler.mean_, scaler.scale_)}\n",
    "\n",
    "cw = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "weights = {0:cw[0], 1:cw[1]}\n",
    "# inject knowledge\n",
    "theory = Theory(knowledge, train)\n",
    "uneducated = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "\n",
    "# usual protocol rules\n",
    "model_name = \"kb_rules\"\n",
    "y_pred = np.array(dataset_rules.iloc[test_idx][\"Rules\"].fillna(0))\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = all_rule\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "# train and score uneducated\n",
    "model_name = \"uneducated\"\n",
    "uneducated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_uneducated = uneducated.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = uneducated.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(uneducated.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "uneducated.save(f\"uneducated_{exp}.keras\")\n",
    "\n",
    "#train and score educated (static weights)\n",
    "model_name = \"educated\"\n",
    "injector = Injector.kins(uneducated)\n",
    "educated = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "educated.save(f\"educated_{exp}.keras\")\n",
    "\n",
    "# prepare data (for explaining)\n",
    "train.loc[:,dataset.columns[:-1]] = X_train\n",
    "test.loc[:,dataset.columns[:-1]] = X_test\n",
    "val.loc[:,dataset.columns[:-1]]= X_val\n",
    "test[\"Outcome\"].replace({0: 'healthy', 1: 'diabetes'}, inplace = True)\n",
    "val[\"Outcome\"].replace({0: 'healthy', 1: 'diabetes'}, inplace = True)\n",
    "\n",
    "predictor = PredictorWrapper(educated)\n",
    "# default\n",
    "dd = 0\n",
    "best_abb = -1\n",
    "for depth in range(5,21):\n",
    "    explainer = Extractor.cart(predictor, max_depth=depth, max_leaves=depth, simplify=False, normalization=normalization)\n",
    "    theory = explainer.extract(train)    \n",
    "    scores, completeness = get_scores(explainer, val, predictor)\n",
    "    abb = list(scores.values())[0][1]\n",
    "    print_scores(scores)\n",
    "    if abb > best_abb:\n",
    "        dd = depth\n",
    "        best_abb = abb\n",
    "\n",
    "# extract rules\n",
    "depth = dd\n",
    "print(\"\\nDepth\",depth)\n",
    "explainer = Extractor.cart(predictor, max_depth=depth, max_leaves=depth, simplify=False, normalization=normalization)\n",
    "extheory = explainer.extract(train)  \n",
    "ml_rules_str = pretty_theory(extheory)\n",
    "ml_rules = parse_rules(ml_rules_str)\n",
    "print('\\nExtracted rules:\\n\\n' + pretty_theory(extheory) + \"\\n\\n\")\n",
    "\n",
    "eval = dataset.iloc[val_idx]\n",
    "eval[\"Pred\"] = np.nan\n",
    "eval[\"Rule\"] = np.nan\n",
    "\n",
    "for index, row in eval.iterrows():\n",
    "    ruleid, outcome = get_rule(ml_rules, row)\n",
    "    eval.loc[index,\"Rule\"] = ruleid\n",
    "    eval.loc[index,\"Pred\"] = outcome\n",
    "\n",
    "eval[\"Pred\"] = eval[\"Pred\"].map({'healthy': 0, 'diabetes': 1})\n",
    "eval['Correct'] = (eval['Outcome'] == eval['Pred']).astype(int)\n",
    "eval['TP'] = ((eval['Outcome'] == 1) & (eval['Pred'] == 1)).astype(int)\n",
    "eval['TN'] = ((eval['Outcome'] == 0) & (eval['Pred'] == 0)).astype(int)\n",
    "eval['FN'] = ((eval['Outcome'] == 1) & (eval['Pred'] == 0)).astype(int)\n",
    "eval['FP'] = ((eval['Outcome'] == 0) & (eval['Pred'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cc5c416-c6b8-47ba-961d-6eef606e184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uneducated</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric      accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                      \n",
       "uneducated     0.734              0.731  0.655  0.447      0.600   0.722   \n",
       "educated       0.675              0.678  0.597  0.340      0.529   0.685   \n",
       "kb_rules       0.740              0.698  0.600  0.412      0.652   0.556   \n",
       "\n",
       "metric      relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                       \n",
       "uneducated              0.947            0.933    0.481    0.253    0.097   \n",
       "educated                0.974            0.967    0.435    0.240    0.110   \n",
       "kb_rules                1.000            1.000    0.545    0.195    0.156   \n",
       "\n",
       "metric      fp_rate  \n",
       "model                \n",
       "uneducated    0.169  \n",
       "educated      0.214  \n",
       "kb_rules      0.104  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions\n",
    "res_df = pd.DataFrame(all_pred, index = test_idx).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")\n",
    "\n",
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21ce0b9f-74ee-469c-9673-11f46a8ac008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>educated</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uneducated</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric      accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                      \n",
       "educated       0.741              0.752  0.680  0.481      0.598   0.787   \n",
       "uneducated     0.770              0.768  0.698  0.519      0.643   0.765   \n",
       "kb_rules       0.764              0.719  0.627  0.463      0.700   0.567   \n",
       "\n",
       "metric      relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                       \n",
       "educated                0.850            0.974    0.466    0.275    0.074   \n",
       "uneducated              0.886            0.974    0.503    0.267    0.082   \n",
       "kb_rules                1.000            1.000    0.566    0.198    0.151   \n",
       "\n",
       "metric      fp_rate  \n",
       "model                \n",
       "educated      0.185  \n",
       "uneducated    0.148  \n",
       "kb_rules      0.085  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions\n",
    "res_df = pd.DataFrame(all_all_pred, index = all_idx).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in all_results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")\n",
    "\n",
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ac2ed1c6-dce9-49cc-9ccb-4d56790c35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval.to_csv(f\"eval_{exp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6ac2b572-b2c7-4a61-87e1-69977ba4ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = dataset.copy()\n",
    "eval[\"Pred\"] = np.nan\n",
    "eval[\"Rule\"] = np.nan\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    ruleid, outcome = get_rule(ml_rules, row)\n",
    "    eval.loc[index,\"Rule\"] = ruleid\n",
    "    eval.loc[index,\"Pred\"] = outcome\n",
    "\n",
    "eval[\"Pred\"] = eval[\"Pred\"].map({'healthy': 0, 'diabetes': 1})\n",
    "eval['Correct'] = (eval['Outcome'] == eval['Pred']).astype(int)\n",
    "eval['TP'] = ((eval['Outcome'] == 1) & (eval['Pred'] == 1)).astype(int)\n",
    "eval['TN'] = ((eval['Outcome'] == 0) & (eval['Pred'] == 0)).astype(int)\n",
    "eval['FN'] = ((eval['Outcome'] == 1) & (eval['Pred'] == 0)).astype(int)\n",
    "eval['FP'] = ((eval['Outcome'] == 0) & (eval['Pred'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "37a80963-32b2-4fb6-94a2-089a850bb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "\n",
    "grouped = eval.groupby('Rule').agg(\n",
    "    total_predictions=('Correct', 'count'),\n",
    "    correct_predictions=('Correct', 'sum'),\n",
    "    total_positives=('Outcome', 'sum'),\n",
    "    true_pos=('TP', 'sum'),\n",
    "    true_neg=('TN', 'sum'),\n",
    "    false_neg=('FN', 'sum'),\n",
    "    false_pos=('FP', 'sum'))\n",
    "\n",
    "grouped = grouped.reindex(range(len(ml_rules)))\n",
    "grouped.index = range(1, len(ml_rules)+1)\n",
    "grouped[\"outcome\"] = [rule[\"outcome\"] for rule in ml_rules]\n",
    "grouped[\"n_conditions\"] = [len(rule[\"conditions\"]) for rule in ml_rules]\n",
    "grouped['accuracy'] = round(grouped['correct_predictions'] / grouped['total_predictions'],3)\n",
    "grouped['coverage'] = round(grouped['total_predictions'] / len(eval),3)\n",
    "\n",
    "grouped['goodness'] = (1 + beta**2)*(grouped['accuracy']*grouped['coverage'])/((beta**2 * grouped['accuracy'])+grouped['coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a331377d-a4f6-494d-a706-ddea8bf27db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted rules:\n",
      "\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose =< 121.5, BMI > 40.75.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose > 121.5, BMI > 29.1.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose > 121.5, BMI =< 29.1, Age =< 30.5.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose > 121.5, BMI =< 29.1, Age > 30.5.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction =< 0.65.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, healthy) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age =< 4E+1.0.\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, diabetes) :-\n",
      "    Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age > 4E+1.0.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nExtracted rules:\\n\\n' + pretty_theory(extheory) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dfdaf8ef-3cc3-4d8b-bdf7-0bccc9cf7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>correct_predictions</th>\n",
       "      <th>total_positives</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>true_neg</th>\n",
       "      <th>false_neg</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>outcome</th>\n",
       "      <th>n_conditions</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>goodness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.635465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.385433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.338948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.300652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>317.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>healthy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.864446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>healthy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.700718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_predictions  correct_predictions  total_positives  true_pos  \\\n",
       "2              262.0                168.0            168.0     168.0   \n",
       "4               44.0                 18.0             18.0      18.0   \n",
       "1               33.0                 12.0             12.0      12.0   \n",
       "7               75.0                 23.0             23.0      23.0   \n",
       "5              317.0                277.0             40.0       0.0   \n",
       "3               37.0                 30.0              7.0       0.0   \n",
       "6                NaN                  NaN              NaN       NaN   \n",
       "\n",
       "   true_neg  false_neg  false_pos   outcome  n_conditions  accuracy  coverage  \\\n",
       "2       0.0        0.0       94.0  diabetes             2     0.641     0.341   \n",
       "4       0.0        0.0       26.0  diabetes             3     0.409     0.057   \n",
       "1       0.0        0.0       21.0  diabetes             2     0.364     0.043   \n",
       "7       0.0        0.0       52.0  diabetes             4     0.307     0.098   \n",
       "5     277.0       40.0        0.0   healthy             3     0.874     0.413   \n",
       "3      30.0        7.0        0.0   healthy             3     0.811     0.048   \n",
       "6       NaN        NaN        NaN   healthy             4       NaN       NaN   \n",
       "\n",
       "   goodness  \n",
       "2  0.635465  \n",
       "4  0.385433  \n",
       "1  0.338948  \n",
       "7  0.300652  \n",
       "5  0.864446  \n",
       "3  0.700718  \n",
       "6       NaN  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped#.sort_values(by = \"goodness\", ascending = False)\n",
    "grouped.sort_values(by = [\"outcome\",\"goodness\"], ascending = [True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "69f0e0fe-e106-4764-8634-1a9bec8991fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 5\n",
      "'Outcome'(Age, BMI, BloodPressure, DiabetesPedigreeFunction, Glucose, Insulin, Pregnancies, SkinThickness, 0) :-\n",
      "\tGlucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction =< 0.65.\n"
     ]
    }
   ],
   "source": [
    "rule_idx = 5\n",
    "print(\"Rule\", rule_idx)\n",
    "rules_str = [rule.strip() for rule in ml_rules_str.strip().split('\\n') if rule.strip()]\n",
    "selected_rule = [rules_str[rl] for rl in [2*rule_idx-2,2*rule_idx-1]]\n",
    "output_rule = '\\n\\t'.join(selected_rule)\n",
    "output_rule = output_rule.replace(\"diabetes\",\"1\")\n",
    "output_rule = output_rule.replace(\"healthy\",\"0\")\n",
    "output_rule = output_rule.replace(\"E+1.0\",\"0\")\n",
    "output_rule = output_rule.replace(\"E+2.0\",\"00\")\n",
    "output_rule = transform_in_condition(output_rule)\n",
    "print(output_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "befc3a7d-87ea-4243-b7fc-7ffbd60662e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 4\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ff22e52-ea9a-437e-b60b-a82eafb7f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Glucose =< 121.5, BMI > 40.75 -> 1.0\n",
      "Epoch 1/100\n",
      "16/16 - 1s - loss: 0.8186 - accuracy: 0.6660 - val_loss: 0.6371 - val_accuracy: 0.7154 - 1s/epoch - 81ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.7581 - accuracy: 0.6660 - val_loss: 0.6071 - val_accuracy: 0.7317 - 60ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.7122 - accuracy: 0.6802 - val_loss: 0.5805 - val_accuracy: 0.7398 - 65ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6730 - accuracy: 0.7088 - val_loss: 0.5609 - val_accuracy: 0.7724 - 62ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6462 - accuracy: 0.7047 - val_loss: 0.5458 - val_accuracy: 0.7886 - 62ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.6233 - accuracy: 0.7210 - val_loss: 0.5309 - val_accuracy: 0.8293 - 60ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.6038 - accuracy: 0.7393 - val_loss: 0.5155 - val_accuracy: 0.8374 - 60ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5878 - accuracy: 0.7556 - val_loss: 0.5020 - val_accuracy: 0.8455 - 55ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5740 - accuracy: 0.7658 - val_loss: 0.4909 - val_accuracy: 0.8455 - 58ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5613 - accuracy: 0.7637 - val_loss: 0.4830 - val_accuracy: 0.8293 - 60ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5517 - accuracy: 0.7617 - val_loss: 0.4760 - val_accuracy: 0.8130 - 61ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5436 - accuracy: 0.7556 - val_loss: 0.4699 - val_accuracy: 0.8130 - 58ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5361 - accuracy: 0.7556 - val_loss: 0.4652 - val_accuracy: 0.8130 - 65ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5293 - accuracy: 0.7556 - val_loss: 0.4605 - val_accuracy: 0.8130 - 60ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5236 - accuracy: 0.7495 - val_loss: 0.4587 - val_accuracy: 0.7886 - 54ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.5183 - accuracy: 0.7475 - val_loss: 0.4555 - val_accuracy: 0.7886 - 59ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.5138 - accuracy: 0.7434 - val_loss: 0.4538 - val_accuracy: 0.7724 - 56ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.5098 - accuracy: 0.7434 - val_loss: 0.4545 - val_accuracy: 0.7805 - 52ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.5060 - accuracy: 0.7393 - val_loss: 0.4522 - val_accuracy: 0.7805 - 57ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.5026 - accuracy: 0.7352 - val_loss: 0.4521 - val_accuracy: 0.7724 - 56ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4990 - accuracy: 0.7393 - val_loss: 0.4503 - val_accuracy: 0.7805 - 55ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4963 - accuracy: 0.7413 - val_loss: 0.4497 - val_accuracy: 0.7642 - 58ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4935 - accuracy: 0.7434 - val_loss: 0.4486 - val_accuracy: 0.7724 - 56ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4907 - accuracy: 0.7454 - val_loss: 0.4501 - val_accuracy: 0.7724 - 56ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4889 - accuracy: 0.7495 - val_loss: 0.4469 - val_accuracy: 0.7805 - 58ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4857 - accuracy: 0.7515 - val_loss: 0.4484 - val_accuracy: 0.7724 - 57ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4839 - accuracy: 0.7495 - val_loss: 0.4537 - val_accuracy: 0.7805 - 54ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4814 - accuracy: 0.7515 - val_loss: 0.4527 - val_accuracy: 0.7805 - 56ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4797 - accuracy: 0.7536 - val_loss: 0.4486 - val_accuracy: 0.7724 - 51ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4775 - accuracy: 0.7495 - val_loss: 0.4464 - val_accuracy: 0.7724 - 58ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4755 - accuracy: 0.7536 - val_loss: 0.4468 - val_accuracy: 0.7805 - 52ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4733 - accuracy: 0.7617 - val_loss: 0.4476 - val_accuracy: 0.7886 - 52ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4716 - accuracy: 0.7617 - val_loss: 0.4464 - val_accuracy: 0.7805 - 56ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4694 - accuracy: 0.7556 - val_loss: 0.4487 - val_accuracy: 0.7886 - 59ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4677 - accuracy: 0.7556 - val_loss: 0.4458 - val_accuracy: 0.7886 - 60ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4658 - accuracy: 0.7576 - val_loss: 0.4522 - val_accuracy: 0.7886 - 60ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.4641 - accuracy: 0.7576 - val_loss: 0.4501 - val_accuracy: 0.7805 - 53ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.4622 - accuracy: 0.7617 - val_loss: 0.4475 - val_accuracy: 0.7724 - 55ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 0.4606 - accuracy: 0.7617 - val_loss: 0.4488 - val_accuracy: 0.7724 - 54ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 0.4587 - accuracy: 0.7658 - val_loss: 0.4464 - val_accuracy: 0.7724 - 64ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes_update_1.pl\")\n",
    "theory = Theory(knowledge, train)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_name = \"educated_up1\"\n",
    "results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_pred[model_name] = [] \n",
    "all_all_pred[model_name] = []\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# train and score uneducated\n",
    "uneducated_up = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "#train and score educated (static weights)\n",
    "injector = Injector.kins(uneducated_up)\n",
    "educated_up1 = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated_up1.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated_up1.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated_up1.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated_up1.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "educated_up1.save(f\"educated_up1_{exp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8212d75b-2cd3-4e11-ad88-a0689393efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Glucose > 121.5, BMI =< 29.1, Age > 30.5 -> 1.0\n",
      "Epoch 1/100\n",
      "16/16 - 1s - loss: 0.7195 - accuracy: 0.3931 - val_loss: 0.7483 - val_accuracy: 0.3089 - 1s/epoch - 82ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.6945 - accuracy: 0.4766 - val_loss: 0.7209 - val_accuracy: 0.4878 - 58ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6715 - accuracy: 0.5540 - val_loss: 0.6911 - val_accuracy: 0.5691 - 58ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6478 - accuracy: 0.6029 - val_loss: 0.6635 - val_accuracy: 0.6260 - 55ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6270 - accuracy: 0.6354 - val_loss: 0.6350 - val_accuracy: 0.6667 - 63ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.6059 - accuracy: 0.6680 - val_loss: 0.6087 - val_accuracy: 0.6992 - 61ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.5859 - accuracy: 0.6762 - val_loss: 0.5827 - val_accuracy: 0.7154 - 57ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5690 - accuracy: 0.7006 - val_loss: 0.5610 - val_accuracy: 0.7236 - 60ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5546 - accuracy: 0.7149 - val_loss: 0.5402 - val_accuracy: 0.7317 - 57ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.5236 - val_accuracy: 0.7317 - 55ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5301 - accuracy: 0.7373 - val_loss: 0.5084 - val_accuracy: 0.7642 - 55ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5208 - accuracy: 0.7373 - val_loss: 0.4942 - val_accuracy: 0.7805 - 55ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5133 - accuracy: 0.7413 - val_loss: 0.4839 - val_accuracy: 0.7805 - 204ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5074 - accuracy: 0.7475 - val_loss: 0.4725 - val_accuracy: 0.7886 - 57ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5017 - accuracy: 0.7454 - val_loss: 0.4715 - val_accuracy: 0.7805 - 57ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.4966 - accuracy: 0.7515 - val_loss: 0.4646 - val_accuracy: 0.7724 - 58ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.4924 - accuracy: 0.7515 - val_loss: 0.4567 - val_accuracy: 0.7967 - 58ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.4885 - accuracy: 0.7576 - val_loss: 0.4529 - val_accuracy: 0.7886 - 53ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4852 - accuracy: 0.7576 - val_loss: 0.4473 - val_accuracy: 0.7886 - 54ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4820 - accuracy: 0.7576 - val_loss: 0.4463 - val_accuracy: 0.7886 - 59ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4787 - accuracy: 0.7597 - val_loss: 0.4441 - val_accuracy: 0.7724 - 59ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4773 - accuracy: 0.7658 - val_loss: 0.4413 - val_accuracy: 0.7805 - 54ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4746 - accuracy: 0.7658 - val_loss: 0.4393 - val_accuracy: 0.7805 - 60ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4729 - accuracy: 0.7678 - val_loss: 0.4363 - val_accuracy: 0.7886 - 62ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4720 - accuracy: 0.7617 - val_loss: 0.4330 - val_accuracy: 0.8049 - 57ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4690 - accuracy: 0.7637 - val_loss: 0.4340 - val_accuracy: 0.7886 - 58ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4679 - accuracy: 0.7658 - val_loss: 0.4366 - val_accuracy: 0.7886 - 60ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4662 - accuracy: 0.7658 - val_loss: 0.4328 - val_accuracy: 0.8049 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4652 - accuracy: 0.7617 - val_loss: 0.4299 - val_accuracy: 0.7967 - 56ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4638 - accuracy: 0.7597 - val_loss: 0.4265 - val_accuracy: 0.8211 - 58ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4621 - accuracy: 0.7637 - val_loss: 0.4281 - val_accuracy: 0.8211 - 51ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4613 - accuracy: 0.7658 - val_loss: 0.4277 - val_accuracy: 0.8049 - 52ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4601 - accuracy: 0.7658 - val_loss: 0.4265 - val_accuracy: 0.8049 - 62ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4591 - accuracy: 0.7699 - val_loss: 0.4302 - val_accuracy: 0.7967 - 58ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4582 - accuracy: 0.7699 - val_loss: 0.4265 - val_accuracy: 0.8049 - 52ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4571 - accuracy: 0.7699 - val_loss: 0.4323 - val_accuracy: 0.8049 - 55ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.4560 - accuracy: 0.7719 - val_loss: 0.4278 - val_accuracy: 0.8049 - 56ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.4552 - accuracy: 0.7678 - val_loss: 0.4256 - val_accuracy: 0.8130 - 59ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 0.4549 - accuracy: 0.7719 - val_loss: 0.4288 - val_accuracy: 0.8049 - 55ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 0.4532 - accuracy: 0.7699 - val_loss: 0.4260 - val_accuracy: 0.8049 - 54ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 0.4526 - accuracy: 0.7719 - val_loss: 0.4255 - val_accuracy: 0.8211 - 60ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 0.4521 - accuracy: 0.7678 - val_loss: 0.4232 - val_accuracy: 0.8130 - 58ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 0.4514 - accuracy: 0.7739 - val_loss: 0.4247 - val_accuracy: 0.8049 - 52ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 0.4508 - accuracy: 0.7719 - val_loss: 0.4242 - val_accuracy: 0.8049 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4277 - val_accuracy: 0.8049 - 50ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 0.4489 - accuracy: 0.7739 - val_loss: 0.4258 - val_accuracy: 0.8049 - 60ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 0.4485 - accuracy: 0.7719 - val_loss: 0.4248 - val_accuracy: 0.8049 - 64ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes_update_2.pl\")\n",
    "theory = Theory(knowledge, train)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_name = \"educated_up2\"\n",
    "results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_pred[model_name] = [] \n",
    "all_all_pred[model_name] = []\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# train and score uneducated\n",
    "uneducated_up = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "#train and score educated (static weights)\n",
    "injector = Injector.kins(uneducated_up)\n",
    "educated_up2 = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated_up2.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated_up2.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated_up2.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated_up2.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "educated_up2.save(f\"educated_up2_{exp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "23ae8446-ae52-4b3b-aa08-010cba967522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Glucose > 121.5, BMI > 29.1 -> 1.0\n",
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 0.6895 - accuracy: 0.5703 - val_loss: 0.6594 - val_accuracy: 0.7073 - 2s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.6656 - accuracy: 0.6619 - val_loss: 0.6329 - val_accuracy: 0.7561 - 58ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6457 - accuracy: 0.7169 - val_loss: 0.6094 - val_accuracy: 0.7805 - 60ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6276 - accuracy: 0.7393 - val_loss: 0.5893 - val_accuracy: 0.7561 - 243ms/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6100 - accuracy: 0.7637 - val_loss: 0.5711 - val_accuracy: 0.7724 - 60ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.5933 - accuracy: 0.7597 - val_loss: 0.5556 - val_accuracy: 0.7805 - 61ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.5758 - accuracy: 0.7515 - val_loss: 0.5396 - val_accuracy: 0.7642 - 55ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5608 - accuracy: 0.7495 - val_loss: 0.5252 - val_accuracy: 0.7480 - 52ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5474 - accuracy: 0.7495 - val_loss: 0.5120 - val_accuracy: 0.7561 - 57ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5358 - accuracy: 0.7475 - val_loss: 0.5006 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5257 - accuracy: 0.7454 - val_loss: 0.4893 - val_accuracy: 0.7724 - 59ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5171 - accuracy: 0.7393 - val_loss: 0.4810 - val_accuracy: 0.7642 - 61ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5097 - accuracy: 0.7454 - val_loss: 0.4758 - val_accuracy: 0.7642 - 56ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5037 - accuracy: 0.7454 - val_loss: 0.4654 - val_accuracy: 0.7480 - 54ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.4982 - accuracy: 0.7495 - val_loss: 0.4636 - val_accuracy: 0.7480 - 56ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.4937 - accuracy: 0.7475 - val_loss: 0.4610 - val_accuracy: 0.7480 - 54ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.4897 - accuracy: 0.7475 - val_loss: 0.4583 - val_accuracy: 0.7561 - 64ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.4863 - accuracy: 0.7475 - val_loss: 0.4584 - val_accuracy: 0.7398 - 55ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4835 - accuracy: 0.7515 - val_loss: 0.4548 - val_accuracy: 0.7398 - 53ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4804 - accuracy: 0.7536 - val_loss: 0.4562 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4776 - accuracy: 0.7536 - val_loss: 0.4544 - val_accuracy: 0.7317 - 58ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4757 - accuracy: 0.7576 - val_loss: 0.4532 - val_accuracy: 0.7398 - 56ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4733 - accuracy: 0.7556 - val_loss: 0.4533 - val_accuracy: 0.7317 - 52ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4716 - accuracy: 0.7658 - val_loss: 0.4519 - val_accuracy: 0.7480 - 61ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4698 - accuracy: 0.7699 - val_loss: 0.4516 - val_accuracy: 0.7480 - 62ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4677 - accuracy: 0.7637 - val_loss: 0.4536 - val_accuracy: 0.7398 - 56ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4666 - accuracy: 0.7515 - val_loss: 0.4591 - val_accuracy: 0.7398 - 57ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4650 - accuracy: 0.7597 - val_loss: 0.4568 - val_accuracy: 0.7398 - 57ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4638 - accuracy: 0.7637 - val_loss: 0.4533 - val_accuracy: 0.7398 - 53ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4497 - val_accuracy: 0.7398 - 56ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4609 - accuracy: 0.7699 - val_loss: 0.4533 - val_accuracy: 0.7398 - 59ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4596 - accuracy: 0.7678 - val_loss: 0.4546 - val_accuracy: 0.7480 - 63ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4592 - accuracy: 0.7678 - val_loss: 0.4537 - val_accuracy: 0.7398 - 53ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4579 - accuracy: 0.7658 - val_loss: 0.4574 - val_accuracy: 0.7480 - 51ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4570 - accuracy: 0.7678 - val_loss: 0.4551 - val_accuracy: 0.7398 - 59ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes_update_3.pl\")\n",
    "theory = Theory(knowledge, train)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_name = \"educated_up3\"\n",
    "results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_pred[model_name] = [] \n",
    "all_all_pred[model_name] = []\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# train and score uneducated\n",
    "uneducated_up = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "#train and score educated (static weights)\n",
    "injector = Injector.kins(uneducated_up)\n",
    "educated_up3 = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated_up3.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated_up3.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated_up3.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated_up3.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "educated_up3.save(f\"educated_up3_{exp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d86a8525-e56b-4630-a228-a3a195d4e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age > 40.0 -> 1.0\n",
      "Epoch 1/100\n",
      "16/16 - 1s - loss: 0.7451 - accuracy: 0.3564 - val_loss: 0.7800 - val_accuracy: 0.3821 - 1s/epoch - 92ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.7047 - accuracy: 0.4012 - val_loss: 0.7266 - val_accuracy: 0.4715 - 60ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6735 - accuracy: 0.4725 - val_loss: 0.6856 - val_accuracy: 0.5285 - 60ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6494 - accuracy: 0.5519 - val_loss: 0.6531 - val_accuracy: 0.6098 - 58ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6307 - accuracy: 0.5866 - val_loss: 0.6284 - val_accuracy: 0.6504 - 61ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.6149 - accuracy: 0.6110 - val_loss: 0.6065 - val_accuracy: 0.6667 - 63ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.6001 - accuracy: 0.6293 - val_loss: 0.5841 - val_accuracy: 0.6829 - 56ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5849 - accuracy: 0.6497 - val_loss: 0.5632 - val_accuracy: 0.7154 - 54ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5698 - accuracy: 0.6802 - val_loss: 0.5451 - val_accuracy: 0.7236 - 54ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5558 - accuracy: 0.7047 - val_loss: 0.5290 - val_accuracy: 0.7398 - 60ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5425 - accuracy: 0.7169 - val_loss: 0.5129 - val_accuracy: 0.7561 - 58ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5311 - accuracy: 0.7189 - val_loss: 0.4988 - val_accuracy: 0.7642 - 55ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5207 - accuracy: 0.7230 - val_loss: 0.4897 - val_accuracy: 0.7561 - 55ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5126 - accuracy: 0.7332 - val_loss: 0.4774 - val_accuracy: 0.7724 - 57ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5054 - accuracy: 0.7373 - val_loss: 0.4737 - val_accuracy: 0.7724 - 57ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.4993 - accuracy: 0.7434 - val_loss: 0.4671 - val_accuracy: 0.7805 - 58ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.4942 - accuracy: 0.7434 - val_loss: 0.4615 - val_accuracy: 0.7886 - 57ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.4895 - accuracy: 0.7434 - val_loss: 0.4620 - val_accuracy: 0.7724 - 51ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4855 - accuracy: 0.7475 - val_loss: 0.4582 - val_accuracy: 0.7724 - 61ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4820 - accuracy: 0.7515 - val_loss: 0.4610 - val_accuracy: 0.7642 - 52ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4789 - accuracy: 0.7495 - val_loss: 0.4577 - val_accuracy: 0.7561 - 54ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4767 - accuracy: 0.7515 - val_loss: 0.4597 - val_accuracy: 0.7561 - 56ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4738 - accuracy: 0.7515 - val_loss: 0.4592 - val_accuracy: 0.7480 - 53ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4717 - accuracy: 0.7576 - val_loss: 0.4578 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4702 - accuracy: 0.7637 - val_loss: 0.4570 - val_accuracy: 0.7317 - 57ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4674 - accuracy: 0.7637 - val_loss: 0.4608 - val_accuracy: 0.7317 - 51ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4665 - accuracy: 0.7617 - val_loss: 0.4649 - val_accuracy: 0.7236 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4649 - accuracy: 0.7637 - val_loss: 0.4609 - val_accuracy: 0.7317 - 53ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4640 - accuracy: 0.7658 - val_loss: 0.4575 - val_accuracy: 0.7317 - 50ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4563 - val_accuracy: 0.7317 - 54ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4596 - val_accuracy: 0.7236 - 53ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.4599 - val_accuracy: 0.7236 - 54ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4594 - accuracy: 0.7699 - val_loss: 0.4591 - val_accuracy: 0.7398 - 52ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4581 - accuracy: 0.7658 - val_loss: 0.4649 - val_accuracy: 0.7154 - 53ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4571 - accuracy: 0.7658 - val_loss: 0.4639 - val_accuracy: 0.7236 - 58ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes_update_4.pl\")\n",
    "theory = Theory(knowledge, train)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_name = \"educated_up4\"\n",
    "results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_pred[model_name] = [] \n",
    "all_all_pred[model_name] = []\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# train and score uneducated\n",
    "uneducated_up = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "#train and score educated (static weights)\n",
    "injector = Injector.kins(uneducated_up)\n",
    "educated_up4 = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated_up4.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated_up4.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated_up4.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated_up4.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "educated_up4.save(f\"educated_up4_{exp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "656fb8c5-126f-4eff-8b60-a26c9d5d8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose > 126.0, BMI > 30.0 -> 1.0\n",
      "Glucose =< 100.0, BMI =< 25.0 -> 0.0\n",
      "Glucose =< 121.5, BMI > 40.75 -> 1.0\n",
      "Glucose > 121.5, BMI =< 29.1, Age > 30.5 -> 1.0\n",
      "Glucose > 121.5, BMI > 29.1 -> 1.0\n",
      "Glucose =< 121.5, BMI =< 40.75, DiabetesPedigreeFunction > 0.65, Age > 40.0 -> 1.0\n",
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 0.6724 - accuracy: 0.5377 - val_loss: 0.6723 - val_accuracy: 0.5935 - 2s/epoch - 116ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.6455 - accuracy: 0.6212 - val_loss: 0.6378 - val_accuracy: 0.7073 - 85ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6249 - accuracy: 0.6864 - val_loss: 0.6080 - val_accuracy: 0.7561 - 90ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6079 - accuracy: 0.7026 - val_loss: 0.5836 - val_accuracy: 0.7886 - 72ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.5927 - accuracy: 0.7251 - val_loss: 0.5627 - val_accuracy: 0.7886 - 75ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.5791 - accuracy: 0.7332 - val_loss: 0.5440 - val_accuracy: 0.7886 - 81ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.5671 - accuracy: 0.7413 - val_loss: 0.5259 - val_accuracy: 0.7886 - 75ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.5560 - accuracy: 0.7413 - val_loss: 0.5120 - val_accuracy: 0.7886 - 68ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.5469 - accuracy: 0.7475 - val_loss: 0.4989 - val_accuracy: 0.7886 - 77ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.5387 - accuracy: 0.7495 - val_loss: 0.4883 - val_accuracy: 0.7886 - 70ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.5313 - accuracy: 0.7515 - val_loss: 0.4790 - val_accuracy: 0.7967 - 62ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.5249 - accuracy: 0.7556 - val_loss: 0.4698 - val_accuracy: 0.7967 - 70ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5191 - accuracy: 0.7556 - val_loss: 0.4628 - val_accuracy: 0.7886 - 73ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5140 - accuracy: 0.7576 - val_loss: 0.4554 - val_accuracy: 0.7967 - 69ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5092 - accuracy: 0.7515 - val_loss: 0.4514 - val_accuracy: 0.7967 - 64ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.5053 - accuracy: 0.7576 - val_loss: 0.4469 - val_accuracy: 0.8049 - 63ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.5016 - accuracy: 0.7597 - val_loss: 0.4437 - val_accuracy: 0.8049 - 63ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.4984 - accuracy: 0.7597 - val_loss: 0.4421 - val_accuracy: 0.8049 - 63ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4951 - accuracy: 0.7597 - val_loss: 0.4380 - val_accuracy: 0.8130 - 61ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4920 - accuracy: 0.7658 - val_loss: 0.4374 - val_accuracy: 0.8049 - 63ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4887 - accuracy: 0.7678 - val_loss: 0.4355 - val_accuracy: 0.7805 - 65ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4866 - accuracy: 0.7719 - val_loss: 0.4348 - val_accuracy: 0.7886 - 62ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.4830 - accuracy: 0.7739 - val_loss: 0.4340 - val_accuracy: 0.7886 - 65ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.4804 - accuracy: 0.7760 - val_loss: 0.4324 - val_accuracy: 0.7886 - 64ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.4790 - accuracy: 0.7780 - val_loss: 0.4298 - val_accuracy: 0.7886 - 64ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.4756 - accuracy: 0.7780 - val_loss: 0.4301 - val_accuracy: 0.7886 - 57ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.4740 - accuracy: 0.7760 - val_loss: 0.4334 - val_accuracy: 0.7886 - 55ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4310 - val_accuracy: 0.7886 - 51ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4277 - val_accuracy: 0.7886 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.4249 - val_accuracy: 0.7967 - 68ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.4664 - accuracy: 0.7780 - val_loss: 0.4269 - val_accuracy: 0.7967 - 55ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4651 - accuracy: 0.7780 - val_loss: 0.4270 - val_accuracy: 0.7886 - 50ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4639 - accuracy: 0.7821 - val_loss: 0.4245 - val_accuracy: 0.7886 - 62ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4622 - accuracy: 0.7821 - val_loss: 0.4275 - val_accuracy: 0.7886 - 58ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4609 - accuracy: 0.7841 - val_loss: 0.4258 - val_accuracy: 0.7886 - 53ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4598 - accuracy: 0.7821 - val_loss: 0.4283 - val_accuracy: 0.7886 - 55ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.4588 - accuracy: 0.7841 - val_loss: 0.4264 - val_accuracy: 0.7886 - 53ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.4578 - accuracy: 0.7841 - val_loss: 0.4250 - val_accuracy: 0.7886 - 66ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "knowledge = TuProlog.from_file(\"diabetes_update_5.pl\")\n",
    "theory = Theory(knowledge, train)\n",
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")\n",
    "\n",
    "model_name = \"educated_up5\"\n",
    "results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_results[model_name] = {**{metric: [] for metric in scorers}, 'tn_rate': [], 'fp_rate': [], 'fn_rate': [], 'tp_rate': [],\n",
    "                       'relative_accuracy': [], 'relative_recall': []}\n",
    "all_pred[model_name] = [] \n",
    "all_all_pred[model_name] = []\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# train and score uneducated\n",
    "uneducated_up = create_uneducated_predictor(train.shape[1]-1, 1, [12,8], \"relu\", \"sigmoid\")\n",
    "#train and score educated (static weights)\n",
    "injector = Injector.kins(uneducated_up)\n",
    "educated_up5 = injector.inject(theory)\n",
    "theory.set_all_formulae_static()\n",
    "educated_up5.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated_up5.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, class_weight=weights,\n",
    "                                    validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "y_pred = educated_up5.predict(X_test).flatten().round().astype(\"int\")\n",
    "results = compute_scores(results, model_name, y_test, y_pred, y_rule)\n",
    "all_pred[model_name].extend(list(y_pred))\n",
    "y_pred_all = np.array(educated_up5.predict(X).flatten().round().astype(\"int\"))\n",
    "all_results = compute_scores(all_results, model_name, y, y_pred_all, all_rule)\n",
    "all_all_pred[model_name].extend(list(y_pred_all))\n",
    "\n",
    "educated_up5.save(f\"educated_up5_{exp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "483e2a88-4948-495c-a413-56ee84eb0dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>educated_up1</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uneducated</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up2</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up3</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric        accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                        \n",
       "educated_up1     0.714              0.729  0.656  0.437      0.568   0.778   \n",
       "uneducated       0.734              0.731  0.655  0.447      0.600   0.722   \n",
       "educated_up2     0.721              0.717  0.639  0.419      0.585   0.704   \n",
       "educated         0.675              0.678  0.597  0.340      0.529   0.685   \n",
       "educated_up3     0.727              0.718  0.638  0.423      0.597   0.685   \n",
       "kb_rules         0.740              0.698  0.600  0.412      0.652   0.556   \n",
       "\n",
       "metric        relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                         \n",
       "educated_up1              0.974            0.967    0.442    0.273    0.078   \n",
       "uneducated                0.947            0.933    0.481    0.253    0.097   \n",
       "educated_up2              0.947            0.933    0.474    0.247    0.104   \n",
       "educated                  0.974            0.967    0.435    0.240    0.110   \n",
       "educated_up3              0.895            0.867    0.487    0.240    0.110   \n",
       "kb_rules                  1.000            1.000    0.545    0.195    0.156   \n",
       "\n",
       "metric        fp_rate  \n",
       "model                  \n",
       "educated_up1    0.208  \n",
       "uneducated      0.169  \n",
       "educated_up2    0.175  \n",
       "educated        0.214  \n",
       "educated_up3    0.162  \n",
       "kb_rules        0.104  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions\n",
    "res_df = pd.DataFrame(all_pred, index = test_idx).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")\n",
    "\n",
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "ba34470f-412a-4978-8598-ea5a53eb82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('all_all_pred.pickle', 'wb') as handle:\n",
    "#    pickle.dump(all_all_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "bd6ee73a-d69d-4374-aede-8c3bf21f8af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>relative_accuracy</th>\n",
       "      <th>relative_recall</th>\n",
       "      <th>tn_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>fn_rate</th>\n",
       "      <th>fp_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>educated_up1</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up3</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up2</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up4</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educated_up5</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uneducated</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kb_rules</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric        accuracy  balanced_accuracy     f1    mcc  precision  recall  \\\n",
       "model                                                                        \n",
       "educated_up1     0.754              0.770  0.700  0.516      0.609   0.825   \n",
       "educated_up3     0.760              0.769  0.699  0.516      0.622   0.799   \n",
       "educated         0.741              0.752  0.680  0.481      0.598   0.787   \n",
       "educated_up2     0.768              0.772  0.702  0.523      0.636   0.784   \n",
       "educated_up4     0.758              0.761  0.690  0.503      0.623   0.772   \n",
       "educated_up5     0.771              0.770  0.701  0.523      0.644   0.769   \n",
       "uneducated       0.770              0.768  0.698  0.519      0.643   0.765   \n",
       "kb_rules         0.764              0.719  0.627  0.463      0.700   0.567   \n",
       "\n",
       "metric        relative_accuracy  relative_recall  tn_rate  tp_rate  fn_rate  \\\n",
       "model                                                                         \n",
       "educated_up1              0.852            0.980    0.466    0.288    0.061   \n",
       "educated_up3              0.874            0.993    0.482    0.279    0.070   \n",
       "educated                  0.850            0.974    0.466    0.275    0.074   \n",
       "educated_up2              0.888            0.967    0.495    0.273    0.076   \n",
       "educated_up4              0.872            0.954    0.488    0.270    0.079   \n",
       "educated_up5              0.889            0.967    0.503    0.268    0.081   \n",
       "uneducated                0.886            0.974    0.503    0.267    0.082   \n",
       "kb_rules                  1.000            1.000    0.566    0.198    0.151   \n",
       "\n",
       "metric        fp_rate  \n",
       "model                  \n",
       "educated_up1    0.185  \n",
       "educated_up3    0.169  \n",
       "educated        0.185  \n",
       "educated_up2    0.156  \n",
       "educated_up4    0.163  \n",
       "educated_up5    0.148  \n",
       "uneducated      0.148  \n",
       "kb_rules        0.085  "
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions\n",
    "res_df = pd.DataFrame(all_all_pred, index = all_idx).sort_index()\n",
    "#res_df.to_csv(f\"goodit_{exp}_predictions.csv\")\n",
    "\n",
    "# flatten the dictionary structure\n",
    "data = []\n",
    "for model, metrics in all_results.items():\n",
    "    for metric, values in metrics.items():\n",
    "        for i, value in enumerate(values):\n",
    "            data.append((model, metric, i, value))\n",
    "# save performance scores\n",
    "df = pd.DataFrame(data, columns=['model', 'metric', 'fold','value'])\n",
    "#df.to_csv(f\"goodit_{exp}_results.csv\")\n",
    "\n",
    "means_df = df.groupby([\"model\",\"metric\"])[\"value\"].mean().unstack(level=1).round(3).sort_values(by = \"recall\", ascending = False)\n",
    "means_df[['accuracy', 'balanced_accuracy', 'f1', 'mcc', 'precision', 'recall', \n",
    "          'relative_accuracy', 'relative_recall', 'tn_rate', 'tp_rate', 'fn_rate', 'fp_rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "74a0d5e1-680a-4576-ab1c-5257de68e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise dataset\n",
    "res_df = pd.DataFrame()\n",
    "res_df[\"Outcome\"] = dataset_rules[\"Outcome\"]\n",
    "res_df[\"ClinicalProtocol\"] = dataset_rules[\"Rules\"]\n",
    "res_df[\"EQ\"] = res_df[\"Outcome\"]==res_df[\"ClinicalProtocol\"]\n",
    "res_df = res_df.fillna(-1)\n",
    "\n",
    "kb_rules = get_kb_rules()\n",
    "res_df['KB update #1'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[1]]), axis=1)\n",
    "res_df['KB update #2'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[3]]), axis=1)\n",
    "res_df['KB update #3'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[0]]), axis=1)\n",
    "res_df['KB update #4'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[6]]), axis=1)\n",
    "res_df['KB update #5'] = dataset.apply(lambda row: get_outcome(row, kb_rules + list(np.array(ml_rules)[[1,3,0,6]])), axis=1)\n",
    "res_df.replace({'diabetes': 1, 'healthy': 0, np.nan: -1}, inplace = True)\n",
    "res_df[\"NN-I rules\"] = [get_rule(list(np.array(ml_rules)[[1,3,0,6,4,2,5]]), row)[0]+2 for _, row in dataset.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "41ef51c7-758e-4aba-9f8b-c1fa96109d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df2 = pd.DataFrame(all_all_pred, index = all_idx).sort_index()\n",
    "res_df2 = res_df2[['uneducated', 'educated','educated_up3', 'educated_up2','educated_up1', 'educated_up4', 'educated_up5']]\n",
    "res_df2.columns = ['NN', 'NN-I', 'NN-I update #1','NN-I update #2','NN-I update #3', 'NN-I update #4', 'NN-I update #5'] \n",
    "res_df = pd.concat([res_df, res_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "ac3782a1-81a1-49a7-a611-c823080bf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order and rename\n",
    "res_df = res_df.sort_values(['Outcome','ClinicalProtocol','EQ', 'NN-I rules', 'KB update #1','KB update #2','KB update #3',\n",
    "                             'KB update #4', 'KB update #5', 'NN-I', 'NN-I update #1','NN-I update #2','NN-I update #3', \n",
    "                             'NN-I update #4', 'NN-I update #5'], ascending=[False]*15)\n",
    "res_df = res_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "efcdde34-6bce-4337-8c96-dd204eda328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[['Outcome', 'ClinicalProtocol', 'NN', 'NN-I', 'EQ', 'KB update #1', 'NN-I update #1', 'KB update #2', 'NN-I update #2',\n",
    "       'KB update #3', 'NN-I update #3', 'KB update #4', 'NN-I update #4', 'KB update #5', 'NN-I update #5', 'NN-I rules']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "f75c648d-38d7-4947-bc49-f04b8d41992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_col = \"navy\"\n",
    "healthy_col = \"hotpink\"#\"steelblue\"\n",
    "#diabetes_col = \"crimson\"#\"gold\"\n",
    "#healthy_col = \"mediumturquoise\"#\"deepskyblue\"#\"lightseagreen\"#\"steelblue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "5633b7de-2556-4460-95f3-7a43a2e08584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise dataset\n",
    "res_df = pd.DataFrame()\n",
    "res_df[\"Outcome\"] = dataset_rules[\"Outcome\"]\n",
    "res_df[\"ClinicalProtocol\"] = dataset_rules[\"Rules\"]\n",
    "res_df[\"EQ\"] = res_df[\"Outcome\"]==res_df[\"ClinicalProtocol\"]\n",
    "res_df = res_df.fillna(-1)\n",
    "\n",
    "kb_rules = get_kb_rules()\n",
    "res_df['KB update #1'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[1]]), axis=1)\n",
    "res_df['KB update #2'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[3]]), axis=1)\n",
    "res_df['KB update #3'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[0]]), axis=1)\n",
    "res_df['KB update #4'] = dataset.apply(lambda row: get_outcome(row, kb_rules + [ml_rules[6]]), axis=1)\n",
    "res_df['KB update #5'] = dataset.apply(lambda row: get_outcome(row, kb_rules + list(np.array(ml_rules)[[1,3,0,6]])), axis=1)\n",
    "res_df.replace({'diabetes': 1, 'healthy': 0, np.nan: -1}, inplace = True)\n",
    "res_df[\"NN-I rules\"] = [get_rule(list(np.array(ml_rules)[[1,3,0,6,4,2,5]]), row)[0]+2 for _, row in dataset.iterrows()]\n",
    "\n",
    "# order and rename\n",
    "res_df = res_df.sort_values(['Outcome','ClinicalProtocol','EQ', 'NN-I rules', 'KB update #1','KB update #2','KB update #3',\n",
    "                             'KB update #4', 'KB update #5'], ascending=[False]*9)\n",
    "res_df = res_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "5e05d866-3daf-4d05-b764-adee58364a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x340 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['patch.edgecolor'] = 'none'\n",
    "n = len(res_df.columns)-1\n",
    "nr = 6\n",
    "fig, axes = plt.subplots(figsize=(9, 3.4))\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('rg', [ \"lightgray\", healthy_col, diabetes_col] + list(sns.color_palette(\"hls\", nr)), N=256) \n",
    "sns.heatmap(res_df.drop(columns = \"EQ\").T, cmap=cmap, cbar=False, alpha=0.7, xticklabels = 100,\n",
    "            linewidths=0.0, ax=axes, rasterized=True)\n",
    "#axes.set_yticklabels(['Outcome', 'Clinical Protocol', 'GB-CART', 'GB-CART + KB', 'DT', 'DT + KB'])\n",
    "axes.tick_params(axis='both', which='major', labelsize=11)\n",
    "colors = axes.collections[0].get_facecolors()\n",
    "axes.collections[0].set_edgecolors(colors)\n",
    "\n",
    "for r in range(1,len(res_df.columns)-1):\n",
    "    axes.add_patch(Rectangle((0, 0),  len(res_df), r, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), len(res_df), 8, fill=False, edgecolor=\"black\", lw=1, clip_on=False))\n",
    "\n",
    "n1 = len(res_df[(res_df[\"Outcome\"]==1) & (res_df[\"ClinicalProtocol\"]==1)])\n",
    "n2 = len(res_df[(res_df[\"Outcome\"]==1)])\n",
    "n3 = len(res_df[(res_df[\"Outcome\"]==1)]) + len(res_df[(res_df[\"Outcome\"]==0) & (res_df[\"ClinicalProtocol\"]==1)])\n",
    "n4 = len(res_df) - len(res_df[(res_df[\"Outcome\"]==0) & (res_df[\"ClinicalProtocol\"]==-1)])\n",
    "n5 = len(res_df)\n",
    "\n",
    "axes.add_patch(Rectangle((0, 0), n1, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n2, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n3, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((0, 0), n4, 8, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "axes.add_patch(Rectangle((n1, 1), n2-n1, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 1), n2-n1, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 1), n5-n4, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 1), n5-n4, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "w11=len(res_df[(res_df[\"Outcome\"]==1)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #1\"]==1)])\n",
    "w12=len(res_df[(res_df[\"Outcome\"]==0)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #1\"]==1)])\n",
    "w21=len(res_df[(res_df[\"Outcome\"]==1)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #2\"]==1)])\n",
    "w22=len(res_df[(res_df[\"Outcome\"]==0)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #2\"]==1)])\n",
    "w31=len(res_df[(res_df[\"Outcome\"]==1)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #3\"]==1)])\n",
    "w32=len(res_df[(res_df[\"Outcome\"]==0)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #3\"]==1)])\n",
    "w41=len(res_df[(res_df[\"Outcome\"]==1)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #4\"]==1)])\n",
    "w42=len(res_df[(res_df[\"Outcome\"]==0)&(res_df[\"ClinicalProtocol\"]==-1)&(res_df[\"KB update #4\"]==1)])\n",
    "\n",
    "axes.add_patch(Rectangle((n1, 2), n2-n1-w11, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 3), n2-n1-w11-w21, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 4), n2-n1-w11-w21-w31, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 5), n2-n1-w11-w21-w31-w41, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 6), n2-n1-w11-w21-w31-w41, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n1, 2), n2-n1-w11, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n1, 3), n2-n1-w11-w21, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n1, 4), n2-n1-w11-w21-w31, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n1, 5), n2-n1-w11-w21-w31-w41, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n1, 6), n2-n1-w11-w21-w31-w41, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "axes.add_patch(Rectangle((n2-w11, 3), w11, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n2-w11-w21, 4), w11+w21, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n2-w11-w21-w31, 5), w11+w21+w31, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n2-w11, 3), w11, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n2-w11-w21, 4), w11+w21, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n2-w11-w21-w31, 5), w11+w21+w31, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axes.add_patch(Rectangle((n4, 2), n5-n4-w12, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 3), n5-n4-w12-w22, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 4), n5-n4-w12-w22-w32, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 5), n5-n4-w12-w22-w32-w42, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 6), n5-n4-w12-w22-w32-w42, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n4, 2), n5-n4-w12, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 3), n5-n4-w12-w22, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 4), n5-n4-w12-w22-w32, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 5), n5-n4-w12-w22-w32-w42, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n4, 6), n5-n4-w12-w22-w32-w42, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "axes.add_patch(Rectangle((n5-w12, 3), w12, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n5-w12-w22, 4), w12+w22, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n5-w12-w22-w32, 5), w12+w22+w32, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((n5-w12, 3), w12, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n5-w12-w22, 4), w12+w22, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "axes.add_patch(Rectangle((n5-w12-w22-w32, 5), w12+w22+w32, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "\n",
    "#axes.add_patch(Rectangle((n1, 2), n2-n1-w11-w21, 1, fill=False, edgecolor=\"black\", lw=0.5, clip_on=False))\n",
    "#axes.add_patch(Rectangle((n1, 3), n2, 1, fill=False, edgecolor=\"silver\", lw=0.5, clip_on=False, hatch = \"xx\"))\n",
    "axes.add_patch(Rectangle((0, 0), n5, 8, fill=False, edgecolor=\"black\", lw=1, clip_on=False))\n",
    "\n",
    "plt.text(n1/2,     -0.2, \"1\", size=11)\n",
    "plt.text((n1+n2)/2,-0.2, \"2\", size=11)\n",
    "plt.text((n2+n3)/2,-0.2, \"3\", size=11)\n",
    "plt.text((n3+n4)/2,-0.2, \"4\", size=11)\n",
    "plt.text((n4+n5)/2,-0.2, \"5\", size=11)\n",
    "#plt.text(n+1,19, \"here\", size=11)\n",
    "\n",
    "rule_legend_elements = [\n",
    "    Patch(facecolor=color, edgecolor=\"black\", label=f\"Rule {i+1}\", alpha = 0.7)\n",
    "    for i, color in enumerate(sns.color_palette(\"hls\", nr))\n",
    "]\n",
    "\n",
    "rule_legend = axes.legend(handles=rule_legend_elements, loc=\"upper center\", bbox_to_anchor=(0.42, -0.1), ncol=8, fontsize=11)\n",
    "rule_legend.get_frame().set_linewidth(0.0)\n",
    "rule_legend.get_frame().set_facecolor('none')\n",
    "rule_legend.get_frame().set_edgecolor('none')\n",
    "\n",
    "# Add the second legend to the plot\n",
    "axes.add_artist(rule_legend)\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=diabetes_col, edgecolor=\"dimgray\", label=\"Diabetic\", alpha= 0.7),\n",
    "    Patch(facecolor=\"lightgray\", edgecolor=\"dimgray\", label=\"N/A\", hatch=\"xx\"),\n",
    "    Patch(facecolor=healthy_col, edgecolor=\"dimgray\", label=\"Healthy\", alpha= 0.7)\n",
    "]\n",
    "\n",
    "legend = axes.legend(handles=legend_elements, loc=\"upper center\", bbox_to_anchor=(0.5, 1.25), ncol=3, fontsize=11)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "legend.get_frame().set_facecolor('none')\n",
    "legend.get_frame().set_edgecolor('none')\n",
    "\n",
    "plt.tight_layout(pad=0.4)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "#plt.savefig(f\"ml_{exp}_hatch.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79abbb-8bf6-4111-bbbd-06c0c0eb8607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1f46b-d51c-49c7-87f1-f4166842a471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47d24c-429c-4bd4-914a-e70761191f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2335c2c-f78b-4f25-b48f-cfa671144e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
